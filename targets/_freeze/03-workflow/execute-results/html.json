{
  "hash": "e843183e74434fbd22fc966b955f52a8",
  "result": {
    "markdown": "---\neditor_options: \n  markdown: \n    wrap: sentence\n---\n\n\n# Getting started with targets\n\n::: callout-note\n## In this chapter, you will\n\n- learn the basic targets workflow\n- build your own targets pipeline\n\n:::\n\n## Introduction to targets\n\nTargets is a **pipeline tool**, which coordinates the different steps in data science in R.\nIt manages the workflow, takes care of dependencies in the code and keeps track of outdated objects.\nTargets takes care of the cash.\n\nA targets **pipeline** consists of different steps, such as importing data, running an analysis or making a figure (@fig-targets-pipeline) (1).\nEach step in the pipeline is a **target** and can for example be a data frame, a model or a figure.\nA target is basically an R object and is created by a **function**.\nA pipeline has a main script that puts all the pieces of code together and takes care of dependencies and keeping track of changes.\n\nThis concept should sound familiar to you after reading the previous chapter on abstraction.\n\n::: callout-tip\n## Definitions\n\n-   **pipeline tool** - coordinates different steps of data science\n-   **target** - an R object in memory\n-   **function** - self contained code that accomplish a specific task\n:::\n\nWhen updating and rerunning one part of the code, targets will skip parts where the upstream code has not changed and are therefore still up to date (@fig-targets-pipeline) (2).\nTargets will only rerun the code that is outdated and ensures that your results always match the underlying code and maintains a  **reproducible workflow** (3). \nIt avoids unnecessary repetition and can saves costly running time.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Reproducible targets pipeline.](Pics/reproducible_pipeline.png){#fig-targets-pipeline fig-alt='Reproducible targets pipeline.' width=421}\n:::\n:::\n\n\n\n::: callout-tip\n## When is targets useful?\n\n- When the code has a long runtime because it is slow or complex. Targets avoids running code that up to date and allows for parallel processing.\n\n- When the workflow has interconnected tasks with dependencies\n:::\n\n\n\n## The targets pipeline\n\n### The file structure\n\nA target workflow has a specific file structure including R code, functions, qmd files, data and a `_targets.R` file (@fig-file-structure).\nThe `_targets.R` file is mandatory and the most important file defining the targets pipeline.\nThis file lives at the root of the R project folder.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![File structure of an R Studio project with a target pipeline.](Pics/file_structure.png){#fig-file-structure fig-alt='The file structure of an R Studio project with a target pipeline.' width=383}\n:::\n:::\n\n\nAn R project has many other files and it is recommended to keep code and data files in separate folders to keep the repository tidy.\nIt is common to have one or several scripts that contain custom user-defined functions.\nThese scripts should be stored in one folder. \nIn this example we will call the folder `R`: `R/functions.R`.\n\nTo set up this file structure in an RStudio project, use the `use_targets()` function, which creates an initial `_targets.R` script with comments to help you populate the script.\nNote that it also creates a couple of other files, one of which is called `run.R`.\nThis is a helper script to run the pipeline and will be explained later.\n\n::: callout-note\n## Exercise\n\nGo to the targets-workflow-svalbard Rstudio project and load the targets library `library(targets)`.\nThen start to set up a targets pipeline by using the `use_targets()` function.\n \n:::\n\n\n### The _target.R file\n\nThe `_targets.R` file is the **main script** and configures and defines the pipeline.\nThis file is mandatory and without it the targets pipeline will not work.\nWhen using the `use_targets()` function, it sets up the basic structure and comments to help fill out the rest (see below ðŸ‘‡) .\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Created by use_targets().\n# Follow the comments below to fill in this target script.\n# Then follow the manual to check and run the pipeline:\n#   https://books.ropensci.org/targets/walkthrough.html#inspect-the-pipeline\n\n# Load packages required to define the pipeline:\nlibrary(targets)\n# library(tarchetypes) # Load other packages as needed.\n\n# Set target options:\ntar_option_set(\n  packages = c(\"tibble\") # packages that your targets need to run\n  # format = \"qs\", # Optionally set the default storage format. qs is fast.\n  #\n  # For distributed computing in tar_make(), supply a {crew} controller\n  # as discussed at https://books.ropensci.org/targets/crew.html.\n  # Choose a controller that suits your needs. For example, the following\n  # sets a controller with 2 workers which will run as local R processes:\n  #\n  #   controller = crew::crew_controller_local(workers = 2)\n  #\n  # Alternatively, if you want workers to run on a high-performance computing\n  # cluster, select a controller from the {crew.cluster} package. The following\n  # example is a controller for Sun Grid Engine (SGE).\n  # \n  #   controller = crew.cluster::crew_controller_sge(\n  #     workers = 50,\n  #     # Many clusters install R as an environment module, and you can load it\n  #     # with the script_lines argument. To select a specific verison of R,\n  #     # you may need to include a version string, e.g. \"module load R/4.3.0\".\n  #     # Check with your system administrator if you are unsure.\n  #     script_lines = \"module load R\"\n  #   )\n  #\n  # Set other options as needed.\n)\n\n# tar_make_clustermq() is an older (pre-{crew}) way to do distributed computing\n# in {targets}, and its configuration for your machine is below.\noptions(clustermq.scheduler = \"multicore\")\n\n# tar_make_future() is an older (pre-{crew}) way to do distributed computing\n# in {targets}, and its configuration for your machine is below.\n# Install packages {{future}}, {{future.callr}}, and {{future.batchtools}} to allow use_targets() to configure tar_make_future() options.\n\n# Run the R scripts in the R/ folder with your custom functions:\ntar_source()\n# source(\"other_functions.R\") # Source other scripts as needed.\n\n# Replace the target list below with your own:\nlist(\n  tar_target(\n    name = data,\n    command = tibble(x = rnorm(100), y = rnorm(100))\n    # format = \"feather\" # efficient storage for large data frames\n  ),\n  tar_target(\n    name = model,\n    command = coefficients(lm(y ~ x, data = data))\n  )\n)\n```\n:::\n\n\n\n::: callout-note\n## Exercise\n\nOpen the `_targets.R` in your repo and have a look at your `_targets.R` file.\n \n:::\n\n\nThe `_targets.R` file has three main components.\nNote that the file also contains other options which are optional.\nWe will discuss the three main component step-by-step.\n\n1. `tar_option_set()` **sets all options** such as load necessary packages or defining the output format.\nThe argument `package` should have a list of all the required packages that are needed to run the pipeline.\nNote that `targets` needs to be loaded first and outside this function, otherwise the pipeline will not work.\n\nThe `tarchetypes` package contains helper functions and needs to be loaded if your pipeline contains a quarto file (see next chapter).\nPackages that are only used in a quarto file can be loaded directly in there and do not need to be loaded in the `_targets.R` file.\n\nThe argument `format` let's you define default storage format. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Load packages required to define the pipeline:\nlibrary(targets)\n# library(tarchetypes) # Load other packages as needed.\n\n# Set target options:\ntar_option_set(\n  packages = c(\"tibble\"), # packages that your targets need to run\n  format = \"rds\" # default storage format\n  # Set other options as needed.\n)\n```\n:::\n\n\n\n2. The function `tar_source()` will **source all the R scripts** in the `R/` folder.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Run the R scripts in the R/ folder with your custom functions:\ntar_source()\n```\n:::\n\n\n\n3. The last section makes **a list of targets** which is the pipeline.\nEach target is a step in the pipeline, for example importing data, run an analysis or make a figure and looks like a normal R object (e.g. tibble, vector, figure).\nEach target is declared by the `tar_target()` function and separated by a comma.\nThe `tar_target()` needs two arguments:\n`name` defines the target name and `command` the code to produce the target.\nUsually the command is calling a custom function.\n\nHere is a target that uses the function `fit_model()` that was created in the previous chapter to run a linear regression.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# fit model for plant height\nlist(\n  tar_target(name = model,\n             command = fit_model(data))\n  )\n```\n:::\n\n\n\nEach target should have a unique name that can be called downstream in the pipeline.\nThe order of the targets does not matter.\nThe pipeline will figure out which targets depends on each other and run them in the right order.\n\nOnce the pipeline has run, the targets are stored.\n\n::: callout-important\n## Targets names\nTargets names must be unique (no duplicates), should not start with a dot and the name should be meaningful (do not use my_variable).\n:::\n\n**Data files** are special targets, because they also need the argument `format` to declare that this target is a file.\nEach time the pipeline is run, targetes will check if the file has been changed and if this is the case automatically import the data again the next time the pipeline is run.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(name = file,\n             command = \"data/PFTC4_Svalbard_2018_Gradient_Traits.csv\",\n             format = \"file\")\n  )\n```\n:::\n\n\n::: callout-tip\n## How many targets should I make?\nA target should do one thing only (e.g. make a figure) and if a functions gets too long, it can be split into nested sub-functions to make the code readable and easier to maintain.\nKeep the number of targets manageable, which means keep a balance between the amount of code that goes in one target and the number of targets.\n:::\n\n\n### Populate the _target.R file\n\nNow we can populate the `_targets.R` file.\nWe need to set the options, source the custom functions, and define the pipeline.\n\nFirst, we need to add all R packages to the `tar_option_set()` function in the `_targets.R` file that are needed to run the pipeline.\n\n::: callout-note\n## Exercise\n\nAdd all the necessary R packages in `tar_option_set()` in the `_targets.R` file that are needed to run the pipeline.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Set target options:\ntar_option_set(\n  packages = c(\"tidyverse\") # packages that your targets need to run\n)\n```\n:::\n\n\n:::\n\nThe next step is to source all the functions.\nThe `tar_source()` function in the `_targets.R` file already does this.\nBut we are missing one last function to make the figure.\n\n::: callout-note\n## Exercise\n\nWrite a function that makes a figure showing leaf area in both gradients.\n\n:::\n\n\nThe last step is to set up the targets pipeline.\n\n::: callout-note\n## Exercise\n\n**Define the data file**\n\nAdd the dataset as data file in the `_targets.R` file.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  tar_target(name = file,\n             command = path,\n             format = \"file\")\n  )\n```\n:::\n\n\n:::\n\n\n::: callout-note\n## Exercise\n\n**Add other targets to the pipeline**\n\nAdd four more targets to the pipeline that\n\n- import the data\n\n- clean the data\n\n- run a linear regression\n\n- and make a figure\n\nThe last three targets are calling custom functions from the `functions.R` file.\nThe targets are separated by a comma.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlist(\n  # data file\n  tar_target(name = file,\n             command = path,\n             format = \"file\"),\n  \n  # import data\n  tar_target(name = target1,\n             command = function1),\n  \n  # clean data\n  tar_target(name = target2,\n             command = function2),\n  \n  ...\n  \n  )\n```\n:::\n\n\n:::\n\n\nWell done, you have just set up your first target pipeline.\nHave a treat ðŸ¥•!\n\n\n\n### Run the pipeline\n\nNow we are ready to run the pipeline.\nFor this open the `run.R` script and run the `tar_make()` function.\nThis function looks for the `_targets.R` in the working directory and runs the pipeline.\n\nWhen running the pipeline for the first time you will see a list of all the targets that are built (@fig-run-pipeline).\nThis is indicated by start target and build target.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![R output after running the pipeline for the first time.](Pics/pipeline.png){#fig-run-pipeline fig-alt='R output after running the pipeline for the first time.' width=361}\n:::\n:::\n\n\n\n::: callout-note\n## Exercise\n\nOpen the `run.R` script and run the pipeline.\nHopefully, everything will run smoothly ðŸ¤ž!\nIf not check out the Trouble shooting section below.\n\n:::\n\n\nWell done you have run your first targets pipeline.\nThe `tar_visnetwork()` function shows the dependency graph of the pipeline and is a nice way of vizualizing the pipeline.\nCircles are targets, triangles functions, and the colour indicates if the targets are up to date or not.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Vizualise the targets pipeline.](Pics/viz_workflow.png){#fig-vizualise fig-alt='Dependency graph that vizualises the target pipeline.' width=528}\n:::\n:::\n\n\n\n::: callout-note\n## Exercise\n\nRun `tar_visnetwork()` to visualize your pipeline.\n\n:::\n\n\nOnce the pipeline has run, it will always skip the targets that have not changed and are up to date and only run the once that need updating.\nIn the long run this will save a lot of computational time and is one of the big advantages of using targets pipelines.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![R output after running the pipeline.](Pics/pipeline2.png){#fig-run-pipeline2 fig-alt='R output after running the pipeline.' width=331}\n:::\n:::\n\n\n\n::: callout-note\n## Exercise\n\nChange something in your pipeline.\nFor example filter for a different species: bistorta vivipara.\nSave the script and run `tar_visnetwork()` to visualize which object are not up to date now.\n\nRerun the pipeline using `tar_make()`.\n\nAnd run `tar_visnetwork()` again to check if everything is up to date again.\n\n:::\n\n\n### Load targets\n\nEach target can be loaded using `tar_load()` and the pipeline does not need rerunning each time before accessing the targets.\nThis is a huge advantage of the targets pipeline and can save a lot of time. \n\n\n::: {.cell}\n\n```{.r .cell-code}\ntar_load(model)\n```\n:::\n\n\nTo access all the targets at once use `tar_load_everything()`.\nIn `tar_load()` you can also use tidy select commands to load specific targets, e.g. `tar_load(starts_with(\"y\"))`\n\n\n::: callout-note\n## Exercise\n\nUse `tar_load()` to load the target *traits*.\n\nRun `str(traits)` to display the structure of the object traits.\n\n:::\n\n\n::: callout-tip\n## Do it step-by-step\n\nTargets plans can become huge and complex.\nStart small, create a few targets and functions and make the plan running.\nThen add new code in small steps and check regularly if the plan is still working\nThis will help to understand and solve errors (see trouble shooting section).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Vizualisation of complex target pipeline.](Pics/complex_network.png){#fig-complex-network fig-alt='Dependency graph that vizualises a complex target pipeline.' width=541}\n:::\n:::\n\n:::\n\n\n## Trouble shooting\n\n### Locate problem\n\nError messages in targets can be hard to understand and will look something like this:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Error in the pipeline.](Pics/error.png){#fig-error fig-alt='Error in the pipeline.' width=802}\n:::\n:::\n\n\nYou can see that the pipeline broke when running the target *model*.\nTo learn more about the problem run the command `targets::tar_meta(fields = error, complete_only = TRUE)`.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Find out more about a problem in the pipeline.](Pics/solve_error.png){#fig-error2 fig-alt='Find out more about a problem in the pipeline.' width=459}\n:::\n:::\n\n\nThe R output now gives some more information about the problem.\nHere the argument response is missing.\n\nIf an error is difficult to understand use `tar_load()` to load one specific target or `tar_load_everything()` to load all targets.\nThen you can try to run different parts of the script to test where the code breaks.\n\nBest practice is to run the pipeline regularly, which makes it easier locate where the error occurred.\n\n\n### Object not found\n\nA common error is to call a target that does not exist.\nWhen running the pipeline this error will appear (@fig-error-not-found).\nThis is usually if the name is spelled wrong or when using an old name.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Error message for missing object](Pics/error_not_found.png){#fig-error-not-found fig-alt='Error message for missing object.' width=546}\n:::\n:::\n\n\n### Duplicate target\n\nAnother common mistake is to use the same name for two different targets (@fig-error-duplicate).\nThis is common when copy pasting code.\nRename one of the objects and the problem is solved.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Error message for duplicate target.](Pics/error_duplicate.png){#fig-error-duplicate fig-alt='Error message for duplicate target.' width=579}\n:::\n:::\n\n\n\n## Resources\n\n- The [target manual](https://books.ropensci.org/targets/) contains everything you need to know\n<!-- did not find it on github -->\n- Here is a large and working [target plan]()\n- A paper about pipelines: Brousil, M. R., Filazzola, A., Meyer, M. F., Sharma, S., & Hampton, S. E. (2023). Improving ecological data science with workflow management software. Methods in Ecology and Evolution. [https://doi.org/10.1111/2041-210X.14113](https://besjournals.onlinelibrary.wiley.com/doi/full/10.1111/2041-210X.14113?utm_source=pocket_saves)\n- Here is a short introduction video {{< video https://vimeo.com/700982360 >}}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}