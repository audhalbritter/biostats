[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data life cycle",
    "section": "",
    "text": "1 Introduction\nData often lives longer than a specific project. The life cycle of data includes several steps from creating data, curation to archiving, find and re-use. Researchers typically focus more on some of these stages than others. An important part of the data life cycle is to plan each step from the start.\nIn this book, we discuss what a data management plan is and then go through each of the steps of the data life cycle.\nFigure 1.1: The data life cycle."
  },
  {
    "objectID": "02_design-spreadsheets.html#paper-or-digital-data-entry",
    "href": "02_design-spreadsheets.html#paper-or-digital-data-entry",
    "title": "3  Design spreadsheets",
    "section": "\n3.1 Paper or digital data entry",
    "text": "3.1 Paper or digital data entry\nThere are two ways data is collected. Data that is recorded from a machine and automatically stored. If you have the possibility for that, it is always recommended to make use of digital data collection. It can reduce errors. Alternatively, data is collected manually. There are multiple ways of collecting data by hand such as, on paper, digital on a notepad/phone, or recordings.\nEach of these methods have their advantages and disadvantages. If you are collecting data in remote place with harsh weather conditions, paper might be your only solution. Note that there exists rite in the rain paper. Digital data entry saves you the step of digitizing the data and therefore sources of errors. In addition, you can build in data validation for example drop down menus or a function that checks for the right range of values. This can be very useful for avoiding errors."
  },
  {
    "objectID": "02_design-spreadsheets.html#content",
    "href": "02_design-spreadsheets.html#content",
    "title": "3  Design spreadsheets",
    "section": "\n3.2 Content",
    "text": "3.2 Content\nWhat information should your spreadsheet contain? This is not en exhaustive list, but gives guidance on useful information to record:\n\nID (unique ID for each observation, individual)\nDate, time, observation number\nLocation: region/site\nExperimental design: block, plot, replicate, number of observation, treatments\nOrganism: species/population/genet\nresponse variable(s)\npredictors\nrecorder/scribe\nother observations: weather\nnotes"
  },
  {
    "objectID": "02_design-spreadsheets.html#data-validation-tools",
    "href": "02_design-spreadsheets.html#data-validation-tools",
    "title": "3  Design spreadsheets",
    "section": "\n3.3 Data validation tools",
    "text": "3.3 Data validation tools\nData validation is a way to reduce errors in the data and can be built in when collecting or digitizing data.\nFor example you can:\n\nset ranges for valid numbers (e.g. only positive, range between two numbers)\nonly allow whole numbers or decimals\nadd a drop down menus for categorical data\ndefine the length of text (e.g. only 8 characters)\ndefine data types (e.g. to avoid conversion to dates)\n\n\n\n\n\nFigure 3.2: Video"
  },
  {
    "objectID": "02_design-spreadsheets.html#rectangular-spreadsheet",
    "href": "02_design-spreadsheets.html#rectangular-spreadsheet",
    "title": "3  Design spreadsheets",
    "section": "\n3.4 Rectangular spreadsheet",
    "text": "3.4 Rectangular spreadsheet\nSpreadsheets should be rectangular. Best practice is to make spreadsheets completely rectangular. They should not have empty cells, rows or columns, titles or double headers.\nIt is however common to leave some rows/columns and cells empty (Figure 3.3). Also adding a title to a spreadsheet is often done. It is not best practice, but also not a big problem for the downstream processing. Contrary, having two headers with different information is more difficult to process later.\n\n\n\n\nFigure 3.3: An almost rectangular and tidy dataset. The note column has empty cells.\n\n\n\nSometimes, two datasets are combined in one spreadsheet. For example, table Figure 3.4 shows an example of pollinator observation data, which includes observations about wind. The spreadsheet also contains a separate table on the right side, showing the scale for wind. It can be useful to have the two tables in the same file, for example when entering the data. But this will be far more complicated than needed when importing the data. Here we recommend to keep these two tables in separate spreadsheets.\n\n\n\n\nFigure 3.4: Bad examples of spreadsheets. A) Shows two different datasets merged into one. B) Shows a series of small tables belonging to the same dataset."
  },
  {
    "objectID": "02_design-spreadsheets.html#long-or-wide-format",
    "href": "02_design-spreadsheets.html#long-or-wide-format",
    "title": "3  Design spreadsheets",
    "section": "\n3.5 Long or wide format",
    "text": "3.5 Long or wide format\nDatasets can be long or wide and there is often a debate which of these formats are better (Figure 3.5). We do not have a strong opinion on this. As long as the general rules (see above and below) are followed, this does not matter very much. Many analysis require a long format, but for others (e.g. ordinations) a wide format is needed. This means that data often needs to be reshaped from long to wide and vice versa. And this is not very difficult (see reshape section).\n\n\n\n\nFigure 3.5: Wide (A) and long (B) data table."
  },
  {
    "objectID": "02_design-spreadsheets.html#single-value-per-cell",
    "href": "02_design-spreadsheets.html#single-value-per-cell",
    "title": "3  Design spreadsheets",
    "section": "\n3.6 Single value per cell",
    "text": "3.6 Single value per cell\nTidy spreadsheets follow the following rules:\n\neach variable should be one specific column,\neach observation should be one specific row,\neach cell at the intersection of a row and a column contains a single value.\n\nImportantly, put only one value per cell (Figure 3.3).\nSometimes values are entered with their units, such as 42 g in one cell (Figure 3.6). It is better to separate the value and the unit into two columns.\nAnother common mistake is to add notes to a column (Figure 3.6). For example if a value is 0 because it is below the detection value, you could write 0 (below threshold). We recommend to only write the number in the first column and add notes on the value in a separate column called notes.\n\n\n\n\nFigure 3.6: Wide (A) and long (B) data table."
  },
  {
    "objectID": "02_design-spreadsheets.html#consistency",
    "href": "02_design-spreadsheets.html#consistency",
    "title": "3  Design spreadsheets",
    "section": "\n3.7 Consistency",
    "text": "3.7 Consistency\nConsistency is key. There are many ways of designing a spreadsheet, and there is not always a right or a wrong. Find what works for you and stick to it.\nBe consistent for categorical variables, for example use the same spelling and not variations like: female, Female, F. Latin species names is a common problem and where typos happen very easily (Figure 3.7).\n\n\n\n\nFigure 3.7: Inconsistency in species names\n\n\n\nIf you have multiple files or datasets from the same experiment, be consistent with variable names and do not use variations like: site, location, siteID. This will make it more difficult to join datasets downstream.\nBe consistent with missing values. Do not use a mix of leaving the cell blank, NA and making notes like value missing. Also see section below for more details on missing values.\nBe consistent with file names.\nBe consistent with dates. Dates are particularly tricky and get some special attention here (see below). Preferably, use the ISO standard yyyy-mm-dd, for example 2024-11-07.\nBe consistent in notes. We recommend to have a column with notes, which can be used to write down notes about the data or a specific value. For example, why a observation is missing, or something that was unusual during data collection etc. But again, be consistent when making these notes, because it will be easier to make use of the notes downstream. Using different versions for the same information like gone, missing, vanished will make it difficult to quantify how many times a specific problem occured.\nAvoid space in cells before ” female” or after “female ”."
  },
  {
    "objectID": "02_design-spreadsheets.html#meaningful-naming",
    "href": "02_design-spreadsheets.html#meaningful-naming",
    "title": "3  Design spreadsheets",
    "section": "\n3.8 Meaningful naming",
    "text": "3.8 Meaningful naming\nUse good and meaningful names. What do we mean by this? Variable names should be easy to use in downstream data analysis. In addition, variable names should be meaningful which means that the name should explain the variable to some extent.\nAvoid spaces in names, and rather use underscore (_) or hyphen (-). There are different styles (see Figure 3.8) and there are debates about which one is preferable. The truth is, it does not really matter, choose one and stick with it. On a second thought, do not use the kebab-case.\n\n\n\n\nFigure 3.8: Different styles for naming objects. Credit: Allison Horst.\n\n\n\nDo not use special characters other than underscore and hyphen in names. For example: +, %, &, /, ?, !, $, ,, #, @. Note that letters that might be common for you, for example å, æ and ø, are not so common in other countries and R does not deal very well with them. Instead of nedbør use nedbor. This will make you life a lot easier.\nUse concise and meaningful names (Figure 3.9). The name should be short, but long enough to give a meaning. For example community_composition_2022.csv.\n\n\n\n\nFigure 3.9: Final doc by PhDcomics.com\n\n\n\nIf you want to know more about this, we have created a tutorial on naming conventions.\n\n3.8.1 janitor\nOne way to deal with inconsistent variable names is to use the janitor package. The function clean_names() will convert all variables names to a consistent format with snake_case (default). Other formats are also available. In addition it will turn % sign into percent and # to number.\nLet’s look at a dataframe with ugly variable names. And then clean the names.\n\nlibrary(janitor)\n\n\nAttaching package: 'janitor'\n\n\nThe following objects are masked from 'package:stats':\n\n    chisq.test, fisher.test\n\ndat\n\n# A tibble: 1 × 3\n  siteID `measurment 2022` `cover%`\n  &lt;chr&gt;              &lt;dbl&gt;    &lt;dbl&gt;\n1 A                      1       32\n\ndat |&gt; \n  clean_names()\n\n# A tibble: 1 × 3\n  site_id measurment_2022 cover_percent\n  &lt;chr&gt;             &lt;dbl&gt;         &lt;dbl&gt;\n1 A                     1            32"
  },
  {
    "objectID": "02_design-spreadsheets.html#standards",
    "href": "02_design-spreadsheets.html#standards",
    "title": "3  Design spreadsheets",
    "section": "\n3.9 Standards",
    "text": "3.9 Standards\nUse global data standards when available.\ngeographic locations\nOne example are geographic locations such as coordinates. They can be written in many different ways:\n\nDecimal degrees: 60.39299 5.32415\nDMS: 60°23’34.76” N 5°19’26.94” E\nUTM: 32V 297477 6700830\n\nWe recommend to use decimal degree (ISO 6709). For example the coordinates for Bergen (Norway) are 60.39299 °N and 5.32415 °E. There are some important rules to follow:\n\nLatitude comes before longitude.\nNorth latitude is positive and south latitude is negative.\nEast longitude is positive and west longitude is negative.\n\nIf your coordinates are UTM that is also fine, but do not forget to report the zone (e.g. 32V).\nWhen entering dates into spreadsheets, add each part in a separate column, meaning separate the degree north and east in two columns. For UTM use three columns.\ndates\nAnother example are dates, that can also be written in many different ways:\n\n3.1.2022\n03/01/2200\n01-03-2022\n\nThis can lead to confusion, especially when the placement of the month and day are switched (Figure 3.10).\nWe therefore strongly recommend to use the global standard ISO 8601 (Houston 1993) for dates, YYYY-MM-DD, such as 2024-11-07.\n\n\n\n\nFigure 3.10: Missunderstandings when not using date standards. Credit: https://xkcd.com\n\n\n\nAnother issue with dates is, that programs like Excel can turn names into dates. For example names like “Oct-4”, which is a name of a gene, will be turned into a date. Be aware of such problems and check your dataset for dates that are not supposed to be dates. This is a widely ackowledged problem and there are tools to deal with it, such as the web tool that autocorrects and updates misidentified gene names (Koh et al. 2022).\nTry to avoid names that are turned into dates, or actively prevent it by adding a underscore or another character in front of such names. This can later be removed. Another way is to force a column in excel to be a date or to be text."
  },
  {
    "objectID": "02_design-spreadsheets.html#missing-data",
    "href": "02_design-spreadsheets.html#missing-data",
    "title": "3  Design spreadsheets",
    "section": "\n3.10 Missing data",
    "text": "3.10 Missing data\nWe recommend to use NA for missing data and not to leave cells blank. R will automatically fill in NAs in blank cells. The problem with leaving missing data blank, is that there is no way of distinguishing between actual missing data and data that was forgotten to enter."
  },
  {
    "objectID": "02_design-spreadsheets.html#point-or-comma-as-decimal-separator",
    "href": "02_design-spreadsheets.html#point-or-comma-as-decimal-separator",
    "title": "3  Design spreadsheets",
    "section": "\n3.11 Point or comma as decimal separator",
    "text": "3.11 Point or comma as decimal separator\nFor the decimal separator it is common to use a point or a comma. There is no general agreement on which one to use, and there are different practises in different countries. For example in Norway, the comma is the standard setting in Excel.\nAgain, it does not matter what you use, but use it consistently. We have guidelines for how to import datasets with different formats (see import chapter).\nImportantly, do not use a point, when Excel is expecting a comma, which can cause problems when importing the data to R. You can change the settings in Excel."
  },
  {
    "objectID": "02_design-spreadsheets.html#no-manipulation-or-calculations",
    "href": "02_design-spreadsheets.html#no-manipulation-or-calculations",
    "title": "3  Design spreadsheets",
    "section": "\n3.12 No manipulation or calculations",
    "text": "3.12 No manipulation or calculations\nWe strongly recommend to use datasheets only for data entry and storage. During data entry, the content of the spreadsheet can still be changed to reflect the paper version of the data or to make it consistent. But at some point we suggest to stop data manipulation by hand. From that point, data manipulation is done by code.\nThis is because any manipulation done by hand in Excel, cannot be reversed (at least once the document is saved and closed). Also, if you do a lot of manipulation in Excel, you won’t remember what has been done. Standard excel does not have track change to allow you to go back to older versions. In contrast, if data manipulation is done code-based, all manipulation can be changed and reversed.\nFor example, if you delete a column in Excel, save the document and leave the program. And the next day you realize that this was a mistake, it is not possible to retrieve this column. However if you leave the data file untouched, and do the manipulation in R, you can import the data again, run the code and just delete the command that was wrong.\nWe also do not recommend that you make calculations or summaries in your spreadsheet. Better practice is to use R for this, because it is reproducible."
  },
  {
    "objectID": "02_design-spreadsheets.html#no-formatting",
    "href": "02_design-spreadsheets.html#no-formatting",
    "title": "3  Design spreadsheets",
    "section": "\n3.13 No formatting",
    "text": "3.13 No formatting\nIt’s common to format tables, by for example using colours, or bold font. That is fine, as long as the formatting is not containing any information. For example colouring missing data (Figure 3.11). For that make a new column with notes that data is missing.\nData analysis programs do not understand highlighted cells or bold text and such information will simply be ignored and is therefore lost.\n\n\n\n\nFigure 3.11: A spreadsheet with formatting."
  },
  {
    "objectID": "02_design-spreadsheets.html#references",
    "href": "02_design-spreadsheets.html#references",
    "title": "3  Design spreadsheets",
    "section": "\n3.14 References",
    "text": "3.14 References\n\n\n\n\n\n\nBroman, Karl W, and Kara H Woo. 2018. “Data Organization in Spreadsheets.” The American Statistician 72 (1): 2–10.\n\n\nHouston, Gary. 1993. “ISO 8601: 1988 Date/Time Representations.”\n\n\nKoh, Clara WT, Justin SG Ooi, Gabrielle LC Joly, and Kuan Rong Chan. 2022. “Gene Updater: A Web Tool That Autocorrects and Updates for Excel Misidentified Gene Names.” Scientific Reports 12 (1): 1–7."
  },
  {
    "objectID": "03_data_collection.html",
    "href": "03_data_collection.html",
    "title": "4  Data collection",
    "section": "",
    "text": "Data collection is the systematic gathering of data for a specific reason and the data is usually used for downstream processing in statistical analysis."
  },
  {
    "objectID": "04_digitizing_import_data.html#digitizing-data",
    "href": "04_digitizing_import_data.html#digitizing-data",
    "title": "5  Digitize and import data",
    "section": "\n5.1 Digitizing data",
    "text": "5.1 Digitizing data\nThe first step after data collection is to digitize the data, unless the data was collected digitally. When digitizing the data, the digital version should reflect the paper version, to avoid having to flip to different sections of the spreadsheet. Do not change the format, just to have a long table. This can easily be changed later."
  },
  {
    "objectID": "04_digitizing_import_data.html#proof-reading",
    "href": "04_digitizing_import_data.html#proof-reading",
    "title": "5  Digitize and import data",
    "section": "\n5.2 Proof reading",
    "text": "5.2 Proof reading\nAfter digitizing your data, the next step is to proof read. Proof reading basically means that you make the digital copy of your data reflect the paper copy. At this stage, the digital spreadsheet can still be edited by hand, if you are correcting for typos and similar issues.\nNote that if you discover consistent error (e.g. entering the wrong date for multiple days), it is safer to make these changes using code.\nAfter proof reading we recommend to save your data as raw data, a non-manipulated version of your data. Indicate in file name, that this is the raw version of the data. This will later make the process of data cleaning fully transparent. For example, if you want to share your data later, anybody can see what was done to the data, and if somebody ever wants to clean your data differently for another purpose, this is still possible."
  },
  {
    "objectID": "05_data_cleaning.html",
    "href": "05_data_cleaning.html",
    "title": "6  Data cleaning, vizualizing and analysis",
    "section": "",
    "text": "Data cleaning is the process of detecting and correcting or removing, incomplete, incorrect, irrelevant, duplicated or improperly formatted data from a dataset. Errors and problems in the data can be a problem or limit the downstream data analysis and affect the results. Therefore, data cleaning can solve some of the problems and improve the data, analysis and their outcome.\nThe data cleaning should be done fully code-based, meaning that from now on, there should be no more changing things in the data by hand. Make sure your code is openly available (e.g. on GitHub) to make the data cleaning workflow transparent and reproducible. For more details see section on data cleaning (Chapter 6).\nAfter data cleaning, we recommend to save a clean version of your data and indicate again in the file name that this is the clean version."
  },
  {
    "objectID": "07_death.html#backup",
    "href": "07_death.html#backup",
    "title": "8  Data death",
    "section": "\n8.1 Backup",
    "text": "8.1 Backup\nBack up your data in an data repository that is not connected to your computer to avoid data loss. There are many options for this and they often have private or closed repositories, which means that you do not automatically need to share the data.\nTake pictures of paper versions of your data and store them in a save place. Pictures can be useful for proof reading.\nKeep raw data Multiple places Physical and cloud services Be paranoid!"
  },
  {
    "objectID": "08_data_archiving.html#storage",
    "href": "08_data_archiving.html#storage",
    "title": "9  Data archiving",
    "section": "\n9.1 Storage",
    "text": "9.1 Storage\nSave your data as plain text formats, with comma or tab deliminator. We recommend csv files, which is a nonproprietary format. This means that accessing the file does not require any special software and can be opened in any spreadsheet program."
  },
  {
    "objectID": "08_data_archiving.html#data-dictionary-and-documentation",
    "href": "08_data_archiving.html#data-dictionary-and-documentation",
    "title": "9  Data archiving",
    "section": "\n9.2 Data dictionary and documentation",
    "text": "9.2 Data dictionary and documentation\nA dataset on its own is often useless, because it can be difficult to understand what data each column contains. Therefore, it is best practise to create a data dictionary that goes with a dataset (Figure 9.1). A data dictionary is a separate file or table that describes the data and explains what each variable means.\nThis is useful if you want to share your data with collaborators, if somebody else is doing the data analysis for you, or even for your future self in a few years time. You might not remember exactly what each column means, the units, and how it was measured.\nA data dictionary should contain:\n\nVariable names\nExplanation of the variable\nUnit\nRange/expected min/max\n\n\n\n\n\nFigure 9.1: Example of a data dictionary\n\n\n\nAnother important part of a dataset is the documentation or metadata of how the data was collected. This can be a protocol, a method section in a paper or even a data paper. What option you choose is up to you. It is however important that when sharing the data, the user has access to this information."
  },
  {
    "objectID": "index.html#further-reading-and-resources",
    "href": "index.html#further-reading-and-resources",
    "title": "Data life cycle",
    "section": "\n1.1 Further reading and resources",
    "text": "1.1 Further reading and resources\nThe British Ecological Society has a guide for Data management that gives an useful overview of good data management practice and all steps of the data life cycle."
  }
]