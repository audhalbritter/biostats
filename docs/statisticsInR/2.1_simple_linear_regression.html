<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.592">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Statistics in R - 5&nbsp; Simple linear Regression</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./2.2_anova.html" rel="next">
<link href="./1.0_descriptive_statistics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">
<span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Simple linear Regression</span>
</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics in R</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/biostats-r/biostats" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
<li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
    </ul>
<a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistics in R</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Introduction</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0.1_introduction_to_stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to statistics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0.2_types_of_data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Types of data</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Descriptive statistics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1.0_descriptive_statistics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Descriptive Statistics</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Regression models</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.1_simple_linear_regression.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Simple linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.2_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Anova</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.X_introduction_to_GLMs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to generalised linear models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.X_binomial_GLM.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Binomial generalized linear models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.X_mle.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Maximum likelihood estimation”</span></a>
  </div>
</li>
    </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"> <span class="header-section-number">5.1</span> Introduction</a></li>
  <li><a href="#which-questions" id="toc-which-questions" class="nav-link" data-scroll-target="#which-questions"> <span class="header-section-number">5.2</span> <i class="far fa-question-circle"></i> Which questions?</a></li>
  <li>
<a href="#type-of-data" id="toc-type-of-data" class="nav-link" data-scroll-target="#type-of-data"> <span class="header-section-number">5.3</span> <i class="fas fa-table"></i> Type of data</a>
  <ul class="collapse">
<li><a href="#theory" id="toc-theory" class="nav-link" data-scroll-target="#theory"> <span class="header-section-number">5.3.1</span> Theory</a></li>
  <li><a href="#worked-example" id="toc-worked-example" class="nav-link" data-scroll-target="#worked-example"> <span class="header-section-number">5.3.2</span> Worked example</a></li>
  </ul>
</li>
  <li>
<a href="#model-details" id="toc-model-details" class="nav-link" data-scroll-target="#model-details"> <span class="header-section-number">5.4</span> <i class="fas fa-project-diagram"></i> Model details</a>
  <ul class="collapse">
<li><a href="#theory-1" id="toc-theory-1" class="nav-link" data-scroll-target="#theory-1"> <span class="header-section-number">5.4.1</span> Theory</a></li>
  <li><a href="#worked-example-1" id="toc-worked-example-1" class="nav-link" data-scroll-target="#worked-example-1"> <span class="header-section-number">5.4.2</span> Worked example</a></li>
  </ul>
</li>
  <li>
<a href="#parameters" id="toc-parameters" class="nav-link" data-scroll-target="#parameters"> <span class="header-section-number">5.5</span> <i class="fas fa-laptop"></i> Parameters</a>
  <ul class="collapse">
<li><a href="#theory-2" id="toc-theory-2" class="nav-link" data-scroll-target="#theory-2"> <span class="header-section-number">5.5.1</span> Theory</a></li>
  <li><a href="#worked-example-2" id="toc-worked-example-2" class="nav-link" data-scroll-target="#worked-example-2"> <span class="header-section-number">5.5.2</span> Worked example</a></li>
  </ul>
</li>
  <li>
<a href="#quantify-uncertainty" id="toc-quantify-uncertainty" class="nav-link" data-scroll-target="#quantify-uncertainty"> <span class="header-section-number">5.6</span> <i class="fas fa-arrows-alt-h"></i> Quantify uncertainty</a>
  <ul class="collapse">
<li><a href="#theory-3" id="toc-theory-3" class="nav-link" data-scroll-target="#theory-3"> <span class="header-section-number">5.6.1</span> Theory</a></li>
  <li><a href="#worked-example-3" id="toc-worked-example-3" class="nav-link" data-scroll-target="#worked-example-3"> <span class="header-section-number">5.6.2</span> Worked example</a></li>
  </ul>
</li>
  <li>
<a href="#model-checking" id="toc-model-checking" class="nav-link" data-scroll-target="#model-checking"> <span class="header-section-number">5.7</span> <i class="fas fa-tasks"></i> Model checking</a>
  <ul class="collapse">
<li><a href="#theory-4" id="toc-theory-4" class="nav-link" data-scroll-target="#theory-4"> <span class="header-section-number">5.7.1</span> Theory</a></li>
  <li><a href="#worked-example-4" id="toc-worked-example-4" class="nav-link" data-scroll-target="#worked-example-4"> <span class="header-section-number">5.7.2</span> Worked example</a></li>
  </ul>
</li>
  <li>
<a href="#draw-conclusions" id="toc-draw-conclusions" class="nav-link" data-scroll-target="#draw-conclusions"> <span class="header-section-number">5.8</span> <i class="far fa-lightbulb"></i> Draw conclusions</a>
  <ul class="collapse">
<li><a href="#theory-5" id="toc-theory-5" class="nav-link" data-scroll-target="#theory-5"> <span class="header-section-number">5.8.1</span> Theory</a></li>
  <li><a href="#worked-example-5" id="toc-worked-example-5" class="nav-link" data-scroll-target="#worked-example-5"> <span class="header-section-number">5.8.2</span> Worked example</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block">
<span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Simple linear Regression</span>
</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i></button></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Before you start
</div>
</div>
<div class="callout-body-container callout-body">
<p>You should be familiar with basic statistical theory, basics of R, continuous and categorical data, hypothesis testing, statistical modeling, and the concept of linear models.</p>
</div>
</div>
<section id="introduction" class="level2" data-number="5.1"><h2 data-number="5.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">5.1</span> Introduction</h2>
<p>In this section, we will look at how we can use simple linear regression to analyze data with a continuous numeric response and a numeric explanatory variable. Linear regression is a type of linear model.</p>
<p></p>
<p>Linear regression has two motivations. The first is called <strong>inference</strong>, which is when you want to say something about a population from a sample. Very often data are only available for a subset of the population (a sample), but we want to generalize our conclusions for the whole population. Therefore, we use statistical models to <strong>infer</strong> effects at the whole population level from what we find at the sample level. The second motivation is <strong>prediction</strong>, where we use a model to predict values of the response for specific values of the explanatory variable. These predictions can either be for observed values of the explanatory (mainly used for plotting), for unobserved values of the explanatory variable within the same range as observations, or for novel values of the explanatory variable outside the range of observations (this is more risky! - more on this later).</p>
<p></p>
<p><strong>Example questions:</strong></p>
<ol type="1">
<li><p><strong>inference:</strong> does the height of plants increase with increasing temperatures?</p></li>
<li><p><strong>prediction:</strong> how tall will a plant be if mean temperatures increase by 2°C?</p></li>
</ol>
<p></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-plant-temp" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./Figures/plant_height_temp.png" class="img-fluid figure-img" width="1516"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.1: Panel A shows an illustration of inferring the effect of temperature on plant height. Panel B shows an illustration of the prediction of a plant height under a 2°C increase in temperature. Created by Emily G. Simmonds</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>In simple terms, we fit a straight line to:</p>
<ol type="1">
<li><p>estimate a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p></li>
<li><p>predict change in <span class="math inline">\(Y\)</span> from change in <span class="math inline">\(X\)</span>.</p></li>
</ol>
<p></p>
<p>Linear regression assumes a causal relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, i.e.&nbsp;it assumes that <span class="math inline">\(X\)</span> influences <span class="math inline">\(Y\)</span>, but not vice versa. It is important to understand that a regression only “quantifies” the pattern between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, but does not actually test for a causal relationship. To test if <span class="math inline">\(X\)</span> causes an effect on <span class="math inline">\(Y\)</span>, you need to conduct a scientific experiment. A linear relationship between two variables does not necessarily mean that <span class="math inline">\(X\)</span> has a causal influence on <span class="math inline">\(Y\)</span>. For example, the number of PhDs awarded in math has nothing to do with the amount of Uranium stored in the USA. However, when plotting the two variables against each other, one could assume a perfect relationship (see <a href="#fig-spurious">Figure&nbsp;<span>5.2</span></a>)). Therefore, before statistically analyzing data it is essential to make sure there is a biological explanation or assumption for a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>. For more examples of wrong assumptions of causality <a href="https://www.tylervigen.com/spurious-correlations">click here</a>.</p>
<p></p>
<div class="cell">

</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-spurious" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-spurious-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.2: Example of a spurious correlation (one that does not make sense causally). Scatterplot of number of maths PhDs awarded in a year against the amount of uranium stored in US power plants annually. Smooth line indicates a regression line for this data with the 95% confidence interval as the shaded area</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
</section><section id="which-questions" class="level2" data-number="5.2"><h2 data-number="5.2" class="anchored" data-anchor-id="which-questions">
<span class="header-section-number">5.2</span> <i class="far fa-question-circle"></i> Which questions?</h2>
<p></p>
<p>Example questions you can answer with a simple linear regression:</p>
<p>Inference</p>
<ul>
<li>How does mean annual temperature change with time?</li>
<li>How does the time of breeding for a bird change with mean spring temperature?</li>
<li>How does relative plant biomass change with mean light intensity?</li>
</ul>
<p>Prediction</p>
<ul>
<li>What will the mean summer temperature be in 2100?</li>
<li>How heavy will a sheep be if it is 100cm long?</li>
</ul>
<p></p>
</section><section id="type-of-data" class="level2 tabset tabset-fade" data-number="5.3"><h2 class="tabset tabset-fade anchored" data-number="5.3" data-anchor-id="type-of-data">
<span class="header-section-number">5.3</span> <i class="fas fa-table"></i> Type of data</h2>
<p></p>
<section id="theory" class="level3" data-number="5.3.1"><h3 data-number="5.3.1" class="anchored" data-anchor-id="theory">
<span class="header-section-number">5.3.1</span> Theory</h3>
<p></p>
<p>A linear regression is used when you have continuous numeric response variable and a continuous numeric explanatory variables. A <strong>simple linear regression</strong> has only one explanatory variable, a <strong>multiple linear regression</strong> has more than one.</p>
<p></p>
<p><strong>Examples of continuous numeric variables</strong>:</p>
<ul>
<li>Mean annual temperature (°C)</li>
<li>Total annual precipitation (mm)</li>
<li>Distance (km)</li>
<li>Height (cm)</li>
<li>Weight (kg)</li>
</ul>
<p></p>
<p><strong>Always remember to check that the way your variables are classified in R is the same as the format you expect.</strong> It is a common mistake for a variable that should be numeric to be classified as a Factor, or a Factor as a character string etc. (This should not be a problem in the latest version of R, so might become a historical problem.)</p>
<p></p>
</section><section id="worked-example" class="level3" data-number="5.3.2"><h3 data-number="5.3.2" class="anchored" data-anchor-id="worked-example">
<span class="header-section-number">5.3.2</span> Worked example</h3>
<p></p>
<p>For this worked example we will be using some data on dive depths of marine mammals. We will be answering the question:</p>
<p><strong>Does body size (kg) influence maximum dive depth (m) in marine mammals?</strong></p>
<p>We might expect that differences in foraging strategies, physiological processes, metabolism, and power of the marine mammals would impact how deep the animals can dive. All of these variables correlate with body size. Therefore, it could be expected that larger species can dive deeper as relative movement compared to body size is lower. Or perhaps it is less energetically demanding for smaller species to dive deeper. The direction and strength of the influence of body size on dive depth can be quantified using a linear regression.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-mammal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="./Figures/marine_mammals.png" class="img-fluid figure-img" width="2565"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.3: Illustration of marine mammals by Emily G. Simmonds</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<section id="introduction-to-the-data" class="level4" data-number="5.3.2.1"><h4 data-number="5.3.2.1" class="anchored" data-anchor-id="introduction-to-the-data">
<span class="header-section-number">5.3.2.1</span> Introduction to the data</h4>
<p></p>
<p>These data have four variables; species, maximum recorded dive depth in metres (m), body weight in kilograms (kg), and taxonomic group.</p>
<p>The data were collected from a variety of sources and cover several taxonomic groups (including polar bear, sea otters, baleen whales, toothed whales, seals, and sea lions). You can find the dataset <a href="https://github.com/emilygsimmonds/biostats/blob/Regression/StatisticsInR/Files/dive_depths.csv">here</a> if you want to try the analysis for yourself.</p>
<p></p>
<details><summary>
Full list of data sources
</summary><p>Sources:</p>
<ul>
<li><a href="http://www.bbc.co.uk/earth/story/20150115-extreme-divers-defy-explanation">British Broadcasting Coorporation (BBC)</a></li>
<li><a href="https://www.researchgate.net/figure/Maximum-depth-and-duration-of-dive-tagged-blue-whales_tbl1_11900120">Croll et al 2001, Comparative Biochemistry and Physiology Part A: Molecular &amp; Integrative Physiology, Volume 129, Issue 4, Pages 797-809</a></li>
<li><a href="http://whitelab.biology.dal.ca/rwb/humpback.htm">Baird et al 2000, Report prepared under Contract #40ABNC050729 from the Hawaiian Islands Humpback Whale National Marine Sanctuary</a></li>
<li><a href="https://books.google.co.uk/books?id=-dXAcVFhkuQC&amp;pg=PA33&amp;lpg=PA33&amp;dq=max+recorded+humpback+dive&amp;source=bl&amp;ots=mJvyxA4e3S&amp;sig=ACfU3U3ZFOnypZ0Rvej3VpK11Fpci-UfAg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiHgq3enNbpAhXFSxUIHfCTD9MQ6AEwDnoECAkQAQ#v=onepage&amp;q=max%20recorded%20humpback%20dive&amp;f=false">Bannister 2008, Great Whales, CSIRO Publishing</a></li>
<li><a href="https://www.npolar.no/en/species/walrus/">Norwegian Polar Institute</a></li>
<li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1748-7692.2005.tb01228.x">Eguchi and Harvey 2005, Marine Mammal Science, 21: 283-295</a></li>
<li><a href="https://teara.govt.nz/en/diagram/6175/ocean-dive-depths">Lloyd Spencer Davis, Te Ara - the Encyclopedia of New Zealand, (accessed 30 September 2020)</a></li>
<li><a href="https://www.researchgate.net/publication/260209989_Advances_in_non-lethal_research_on_Antarctic_minke_whales_biotelemetry_photo-identification_and_biopsy_sampling">Gales et al 2013, Unpubished Report to the IWC</a></li>
<li><a href="https://www.dolphincommunicationproject.org/index.php/the-latest-buzz/field-reports/bahamas-3/bahamas-2000/item/93037-how-deep-can-dolphins-dive">Dolphin Communication Project</a></li>
<li><a href="https://books.google.no/books?id=2rkHQpToi9sC&amp;pg=PA325&amp;lpg=PA325&amp;dq=max+recorded+common+dolphin+dive&amp;source=bl&amp;ots=hFnuNx8dwr&amp;sig=ACfU3U0Og9623-SPJkxROGsodqDcuEeDNQ&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwizoOnNodbpAhWyxaYKHW9hAHMQ6AEwDHoECAkQAQ#v=onepage&amp;q=max%20recorded%20common%20dolphin%20dive&amp;f=false">Encyclopedia of Marine Mammals edited by Würsig, Perrin, Thewissen, 2002, Elsevier Ltd</a></li>
<li><a href="https://polarbearscience.com/2018/10/15/scientific-study-finds-polar-bears-excel-at-diving-contradicting-previous-expert-opinion/">Polar Bear Science</a></li>
<li><a href="https://books.google.no/books?id=kkRKJCofvXMC&amp;pg=PA445&amp;lpg=PA445&amp;dq=max+recorded+sea+otter+dive&amp;source=bl&amp;ots=HX_ypXO6zq&amp;sig=ACfU3U1ugMJRJtd21NLfrpDVirSmCx15kA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjo29WxotbpAhUGy6YKHQzmDHMQ6AEwAHoECAsQAQ#v=onepage&amp;q=max%20recorded%20sea%20otter%20dive&amp;f=false">Marine Biology, compiled by Steele, edited by Steele, Thorpe, Turekian, 2009, Elsevier Ltd</a></li>
<li><a href="https://nammco.no/marinemammals/">North Atlantic Marine Mammal Commission</a></li>
<li><a href="https://www.fisheries.noaa.gov/species/">National Oceanic and Atmospheric Administration, USA</a></li>
<li><a href="https://www.doc.govt.nz/nature/native-animals/marine-mammals/">Department of Conservation, New Zealand</a></li>
</ul></details><p></p>
<p>First, we want to import the data and have a closer look by making a plot.</p>
<p></p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">dive_data</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 30 × 6
   species                 max_depth body_size_kg group    Species         Group
   &lt;chr&gt;                       &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;    &lt;fct&gt;           &lt;fct&gt;
 1 Orca                          264         4500 Twhale   Orca            Twha…
 2 WeddellSeal                   741          500 Pinniped WeddellSeal     Pinn…
 3 LongFinnedPilot               828         1300 Twhale   LongFinnedPilot Twha…
 4 ShortFinnedPilot             1019         2000 Twhale   ShortFinnedPil… Twha…
 5 BlainvillesBeakedWhale       1408          900 Twhale   BlainvillesBea… Twha…
 6 NorthernBottlenoseWhale      1453         8000 Twhale   NorthernBottle… Twha…
 7 SouthernElephantSeal         1653         3000 Pinniped SouthernElepha… Pinn…
 8 BairdsBeakedWhale            1777        12000 Twhale   BairdsBeakedWh… Twha…
 9 SpermWhale                   2035        27000 Twhale   SpermWhale      Twha…
10 CuviersBeakedWhale           2992         2500 Twhale   CuviersBeakedW… Twha…
# … with 20 more rows</code></pre>
</div>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">dive_fig</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">dive_data</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">body_size_kg</span>, y<span class="op">=</span><span class="va">max_depth</span>, color<span class="op">=</span><span class="va">group</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dive" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-dive-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.4: Scatterplot of body size against maximum dive depth for marine mammals. Colours indicate taxonomic group</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>The output shows that two of the variables are factors (species and group), one is continuous numeric (max_depth), and the last one is integer (body_size_kg). We know that body size actually is a continuous variable, scientists probably rounded when they measured this variable, because these are large numbers. We will change this variable to be numeric so it better represents the characteristics of the data.</p>
<div class="cell">
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="co"># format the divedata</span>
<span class="va">dive_data</span> <span class="op">&lt;-</span> <span class="fu">mutate</span><span class="op">(</span><span class="va">dive_data</span>, body_size_kg <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/numeric.html">as.numeric</a></span><span class="op">(</span><span class="va">body_size_kg</span><span class="op">)</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Remember, we are interested in <strong>whether body size (kg) influences maximum dive depth (m) in marine mammals.</strong> To answer this question we will need the variables: <code>body_size_kg</code> and <code>max_depth</code>. We will not consider <code>species</code> or <code>group</code> at the moment, but we might need them later.</p>
<p></p>
<p>Now we have familiarized ourselves with the data, we know our research question, and we have identified which variables we need for the analysis. <strong>We are ready to perform an analysis.</strong></p>
<p></p>
</section></section></section><section id="model-details" class="level2 tabset tabset-fade" data-number="5.4"><h2 class="tabset tabset-fade anchored" data-number="5.4" data-anchor-id="model-details">
<span class="header-section-number">5.4</span> <i class="fas fa-project-diagram"></i> Model details</h2>
<p></p>
<section id="theory-1" class="level3" data-number="5.4.1"><h3 data-number="5.4.1" class="anchored" data-anchor-id="theory-1">
<span class="header-section-number">5.4.1</span> Theory</h3>
<p></p>
<p>When we create a model we aim to represent mathematically the process that generated the data we observed.</p>
<p>When we use a linear regression model (this is also true for other types of linear models), we make an assumption that there is a linear relationship between the explanatory and response variables. Mathematically, we say that we can capture the data generation process with a straight line and some error.</p>
<p>The line component of the linear regression is defined by two parameters:</p>
<ul>
<li>
<span style="color:orange"><strong><span class="math inline">\(\alpha\)</span></strong></span> (Greek letter alpha) = the intercept, defining where the regression line crosses the y-axis.</li>
<li>
<span style="color:blue"><strong><span class="math inline">\(\beta\)</span></strong></span> (Greek letter beta) = the slope (steepness/gradient), which defines the steepness of the regression line, i.e.&nbsp;how much <span class="math inline">\(Y\)</span> changes for every increase of 1 unit of <span class="math inline">\(X\)</span>.</li>
</ul>
<p>We can alter the position and slope of the line by these two parameters. The final part of the model is <span style="color:red"><strong><span class="math inline">\(\varepsilon\)</span></strong></span> (Greek letter epsilon), which is the error around the regression line. This error is estimated with the parameter <strong><span class="math inline">\(\sigma^{2}\)</span></strong> (Greek letter sigma – squared) that is the variance of the error. (Greek letters are used to refer to each part of the model using equations).</p>
<p></p>
<p>We can write a linear regression model as and equation as a function of <span class="math inline">\(Y\)</span>:</p>
<p><span class="math display">\[
Y_i = \color{orange}\alpha + \color{blue}\beta X_i + \color{red}\varepsilon_i
\]</span></p>
<section id="assumptions" class="level4" data-number="5.4.1.1"><h4 data-number="5.4.1.1" class="anchored" data-anchor-id="assumptions">
<span class="header-section-number">5.4.1.1</span> Assumptions</h4>
<p></p>
<p>There are several assumptions that we make when using a linear regression model:</p>
<ul>
<li>The relationship between X and Y is linear</li>
<li>Residuals (this is another word for error) are normally distributed</li>
<li>The residuals have a mean of 0</li>
<li>The variance of the residuals is equal for all fitted values (homoscedasticity)</li>
<li>There are no outliers</li>
<li>Each value of Y is independent</li>
</ul>
<p></p>
<p>All of these assumptions should be met for the model to work properly and they ALWAYS need to be checked. We will check five of them after we have fit the model (see below). The last assumption, independence of <span class="math inline">\(Y\)</span> needs to be assured before or during data collection. For example, if data were collected on leaf length, 20 leaves each from five trees, these would not be independent. It would be better to collect one leaf each from 100 trees.</p>
<p></p>
</section><section id="writing-the-model-in" class="level4" data-number="5.4.1.2"><h4 data-number="5.4.1.2" class="anchored" data-anchor-id="writing-the-model-in">
<span class="header-section-number">5.4.1.2</span> Writing the model in <i class="fab fa-r-project"></i>
</h4>
<p></p>
<p>To fit the simple linear regression in <i class="fab fa-r-project"></i> we will use the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function. </p>
<p><code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> stands for linear model (should seem familiar) and it takes several arguments:</p>
<ul>
<li>formula in form: <code>y ~ x</code>
</li>
<li>data: your data object</li>
</ul>
<p></p>
<p>The function will fit the regression model using maximum likelihood estimation and give us the maximum likelihood estimates of <span style="color:orange"><span class="math inline">\(\alpha\)</span></span> and <span style="color:blue"><span class="math inline">\(\beta\)</span></span> as an output. It does also estimate <span class="math inline">\(\sigma^{2}\)</span> of the error, but it does not report this.</p>
<p></p>
<p>To use the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function you first need to think about the formula argument, the <code>y ~ x</code> part. The same way as in the equation above, the letter <span class="math inline">\(Y\)</span> always corresponds to the response variable (the thing you are trying to explain) and <span class="math inline">\(X\)</span> to an explanatory variable (the thing you assume affects the response).</p>
<p></p>
<p><strong>Does temperature influence wing length of butterflies?</strong></p>
<p></p>
<p>The explanatory variable (<span class="math inline">\(X\)</span>) = temperature, it is the variable that does the influencing. The response variable (<span class="math inline">\(Y\)</span>) = wing length, it is the result.</p>
<p></p>
<p>You can then plug these variables into the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function in the below format using the column names in place of <code>y</code> and <code>x</code> and including your data frame name as the data argument.</p>
<p></p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">model_object</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">response</span> <span class="op">~</span> <span class="va">explanatory</span>, data <span class="op">=</span> <span class="va">your_data</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Running the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> as illustrated above runs the linear regression model and saves the output as a ‘model_object’.</p>
<details><summary>
I saw an <code>lm()</code> written differently, what’s that about?
</summary><p>You can use the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function without the data argument. If you do this, you need to refer to your (<span class="math inline">\(X\)</span>) and (<span class="math inline">\(Y\)</span>) variables in the <code>y ~ x</code> formula using a <code>$</code> between the data name and the column name.</p>
<p><strong>We do not recommend using this approach.</strong> There are several reasons for this but a key one is that when using the <code>$</code> syntax, R sees the variable name as the whole entry <code>your_data$explanatory</code> rather than as the column name <code>explanatory</code>. This makes it difficult to use this model for other things e.g.&nbsp;to predict.</p>
<div class="cell">
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">alternative</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">your_data</span><span class="op">$</span><span class="va">response</span> <span class="op">~</span> <span class="va">your_data</span><span class="op">$</span><span class="va">explanatory</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</details><p></p>
<p>The results of the linear regression can be viewed using the function <code><a href="https://rdrr.io/r/stats/coef.html">coef()</a></code>. This takes the output of <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>, the model object, as its argument and extracts the maximum likelihood estimates of <span style="color:orange"><span class="math inline">\(\alpha\)</span></span> and <span style="color:blue"><span class="math inline">\(\beta\)</span></span>. <span style="color:orange"><span class="math inline">\(\alpha\)</span></span> will always be labelled <code>(Intercept)</code> but <span style="color:blue"><span class="math inline">\(\beta\)</span></span> will be labelled by the name of the <span class="math inline">\(X\)</span> variable.</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept) explanatory 
  2.7720862   0.7969848 </code></pre>
</div>
</div>
<p></p>
</section></section><section id="worked-example-1" class="level3" data-number="5.4.2"><h3 data-number="5.4.2" class="anchored" data-anchor-id="worked-example-1">
<span class="header-section-number">5.4.2</span> Worked example</h3>
<p></p>
<p>This worked example demonstrates how to fit a linear regression model in <i class="fab fa-r-project"></i> using the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function for the dive depths example.</p>
<p></p>
<p>In this example we are asking:</p>
<p><strong>Does body size influence maximum dive depth in marine mammals?</strong></p>
<p></p>
<p>Our question is formulated to suggest a direction of causality, we assume body size has a causal effect on maximum dive depth, therefore maximum depth is our response (<span class="math inline">\(Y\)</span>) and body size as our explanatory variable (<span class="math inline">\(X\)</span>).</p>
<p></p>
<p>We can put these variables into the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function in the below format.</p>
<div class="cell">
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">dive_model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/lm.html">lm</a></span><span class="op">(</span><span class="va">max_depth</span> <span class="op">~</span> <span class="va">body_size_kg</span>, data <span class="op">=</span> <span class="va">dive_data</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p></p>
<p>Great. We have run a model and assigned it to an object name.</p>
<p>We can look at the maximum likelihood estimates of our model parameters (<span style="color:orange"><span class="math inline">\(\alpha\)</span></span> and <span style="color:blue"><span class="math inline">\(\beta\)</span></span>) using the function <code><a href="https://rdrr.io/r/stats/coef.html">coef()</a></code>.</p>
<div class="cell">
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">dive_model</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept)  body_size_kg 
755.977336598  -0.005384027 </code></pre>
</div>
</div>
<p></p>
<p>We will look at interpreting these in the next part of the worked example.</p>
</section></section><section id="parameters" class="level2 tabset tabset-fade" data-number="5.5"><h2 class="tabset tabset-fade anchored" data-number="5.5" data-anchor-id="parameters">
<span class="header-section-number">5.5</span> <i class="fas fa-laptop"></i> Parameters</h2>
<p></p>
<section id="theory-2" class="level3" data-number="5.5.1"><h3 data-number="5.5.1" class="anchored" data-anchor-id="theory-2">
<span class="header-section-number">5.5.1</span> Theory</h3>
<p></p>
<p>We introduced the three model parameters of a simple linear regression in the section above: <span style="color:orange"><strong><span class="math inline">\(\alpha\)</span></strong></span> = the intercept, <span style="color:blue"><strong><span class="math inline">\(\beta\)</span></strong></span> = the slope of the line (steepness/gradient), and <span style="color:red"><strong><span class="math inline">\(\sigma^{2}\)</span></strong></span> the variance of the error.</p>
<p><span class="math display">\[
Y_i = \color{orange}\alpha + \color{blue}\beta X_i + \color{red}\varepsilon_i
\]</span></p>
<p></p>
<p><strong>But what do these parameters really mean?</strong></p>
<p></p>
<p>All regression analyses are fundamentally about using straight lines to represent the relationship between a response (<span class="math inline">\(Y\)</span>) and some explanatory variables (<span class="math inline">\(X\)</span>), called a <strong>regression line</strong>. The parameters of the model determine the placement and gradient of the straight line, as well as representing the distribution of data points around the line.</p>
<p></p>
<div class="cell">

</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-parameter-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-parameter-plot-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.5: Illustration of components of a linear regression. Intercept is in orange, slope is in blue, and the residuals (explained later) are in red</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>In this section we will go through these parameters and their meaning in terms of the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>.</p>
<p></p>
<section id="alpha-the-intercept" class="level4" data-number="5.5.1.1"><h4 data-number="5.5.1.1" class="anchored" data-anchor-id="alpha-the-intercept">
<span class="header-section-number">5.5.1.1</span> <span style="color:orange"><span class="math inline">\(\alpha\)</span></span>, the intercept</h4>
<p>This first parameter gives the value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> = 0, it is the point that the regression line crossed the y-axis. A positive value means that the value of <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> = 0 is above 0, and a negative intercept value means it is below the value of <span class="math inline">\(Y\)</span> is below 0, when <span class="math inline">\(X\)</span> = 0.</p>
</section><section id="beta-the-slope" class="level4" data-number="5.5.1.2"><h4 data-number="5.5.1.2" class="anchored" data-anchor-id="beta-the-slope">
<span class="header-section-number">5.5.1.2</span> <span style="color:blue"><span class="math inline">\(\beta\)</span></span>, the slope</h4>
<p>This second parameter gives the amount of change in <span class="math inline">\(Y\)</span> for every unit change in <span class="math inline">\(X\)</span>, it is the slope of the regression line. Positive values indicate a positive relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> i.e.&nbsp;<span class="math inline">\(Y\)</span> increases as <span class="math inline">\(X\)</span> increases. Negative slope values indicate the opposite, a negative relationship where <span class="math inline">\(Y\)</span> decreases as <span class="math inline">\(X\)</span> increases. The higher the value of the slope, the stronger the regression relationship.</p>
<p></p>
<p><strong>Together <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> control the position and steepness of the regression line.</strong> They are called the <strong>systematic</strong> part of the model, the bit that links <span class="math inline">\(Y\)</span> to the covariate <span class="math inline">\(X\)</span>.</p>
</section><section id="sigma2-the-variance-of-error" class="level4" data-number="5.5.1.3"><h4 data-number="5.5.1.3" class="anchored" data-anchor-id="sigma2-the-variance-of-error">
<span class="header-section-number">5.5.1.3</span> <span class="math inline">\(\sigma^{2}\)</span>, the variance of error</h4>
<p>This is the final parameter you need to estimate for the simple linear regression and it is a bit different from <span style="color:orange"><span class="math inline">\(\alpha\)</span></span> and <span style="color:blue"><span class="math inline">\(\beta\)</span></span>. This parameter does not relate directly to the shape or position of the regression line. Instead, this parameter captures the variance of the data points around that line, i.e.&nbsp;how close or far away each data point is from the regression line. The variance is the <strong>random</strong> part of the model, or in other words the error. Higher error variance values indicate more variation around the model fit. In the case of a simple linear regression, the error is assumed to be normally distributed.</p>
<p></p>
<p>In <a href="#fig-parameter-plot">Figure&nbsp;<span>5.5</span></a>), you can see a plot of a regression line through the data points, but it does not touch all of the points. In other words, it is not capturing all of the variation in the data. The regression line does not explain the exact position of all data points, something else is also going on (this is to be expected for real data).</p>
<p></p>
<p>The regression line is a <strong>fitted line</strong> that represents the best fit line of a relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (based on maximum likelihood estimation). The value of <span class="math inline">\(Y\)</span> for each <span class="math inline">\(X\)</span> on the regression line is called a <strong>fitted value</strong>. The distance between the fitted values and the values of <span class="math inline">\(Y\)</span> that were actually observed are called residuals. You can extract the residuals from your model object using the function <code><a href="https://rdrr.io/r/stats/residuals.html">residuals()</a></code>, which is useful when checking model assumptions (see below). Data points below the regression line have a negative the residual and data points above the line have a positive residual. These are highlighted red in <a href="#fig-parameter-plot">Figure&nbsp;<span>5.5</span></a>).</p>
<p></p>
<p><strong>The regression line must always pass through the point that represents the mean of <span class="math inline">\(X\)</span> and the mean of <span class="math inline">\(Y\)</span>. (<span class="math inline">\(\bar{X}\)</span>, <span class="math inline">\(\bar{Y}\)</span>).</strong> Therefore, if you change the intercept, the slope must change as well to keep the line going through the (<span class="math inline">\(\bar{X}\)</span>, <span class="math inline">\(\bar{Y}\)</span>) point. You can have a go at doing this below.</p>
<p></p>
</section><section id="exercise-finding-a-best-line" class="level4" data-number="5.5.1.4"><h4 data-number="5.5.1.4" class="anchored" data-anchor-id="exercise-finding-a-best-line">
<span class="header-section-number">5.5.1.4</span> Exercise: Finding a ‘best’ line</h4>
<p>Below you will see a window containing an app. The aim of this app is to try and find the straight line that best explains the data, by trying different slope values.</p>
<p>There is a slider on the left hand side that lets you control the <span class="math inline">\(\beta\)</span> value, the <span class="math inline">\(\alpha\)</span> is fixed at 0. On the right you can see the fitted line (one is already plotted for you).</p>
<p>In this example ‘fit’ of the line is measured using something called the <strong>sum of squared residuals</strong>. This is calculated by squaring the values of all of the residuals and then adding them up to get a single number:</p>
<p><span class="math display">\[
\Sigma (y_i - \bar{y_i})^2
\]</span></p>
<p>where, <span class="math inline">\(y_i\)</span> = the observed value of <span class="math inline">\(y\)</span> for <span class="math inline">\(x_i\)</span> and <span class="math inline">\(\bar{y}\)</span> = the fitted y value for <span class="math inline">\(x_i\)</span>, and <span class="math inline">\(i\)</span> is an index of 1 to <span class="math inline">\(n\)</span> (sample size).</p>
<p>The reason the sum of squares is used to estimate the fit of a model line to data is because there are roughly as many positive residuals as negative. If you just sum them, the result will be roughly 0. Therefore, squaring them before adding them means they don’t cancel out. This measure tells you how far away the observations are from the fitted line, <strong>the lower the number, the better the fit</strong>.</p>
<div class="cell">
<iframe src="https://shiny.math.ntnu.no/qmbio/Shiny_apps/Regression/?showcase=0" width="672" height="400px" data-external="1">
</iframe>
</div>
<p></p>
<p>Click <a href="%22https://shiny.math.ntnu.no/qmbio/Shiny_apps/Regression/%22">here</a> to open the app in full scale in a separate window.</p>
<p><strong>What was the best fit you managed to get?</strong></p>
<details><summary>
What was the answer?
</summary><p>A slope of approximately 3 should give the best answer (lowest sum of squares), which is 3423.5956.</p>
</details><p><strong>How confident are you that you found the best line?</strong></p>
<p>It is hard to know by trial and error if you have found the ‘best’ line for the data. It is much easier, repeatable, and reliable to use a simple linear regression instead. The idea is the same as the app, but instead of trying until it looks good, the equation for simple linear regression is used and values for the unknown parameters are found using <strong>maximum likelihood estimation</strong>.</p>
<p></p>
</section><section id="interpreting-the-parameters" class="level4" data-number="5.5.1.5"><h4 data-number="5.5.1.5" class="anchored" data-anchor-id="interpreting-the-parameters">
<span class="header-section-number">5.5.1.5</span> Interpreting the parameters</h4>
<p>Now you know what each of the three parameters in a simple linear regression mean, you can now think about interpreting them.</p>
<p><strong>Which of the three parameters do you think is most important for answering the research question “Does <span class="math inline">\(X\)</span> influence <span class="math inline">\(Y\)</span>?”?</strong></p>
<p></p>
<details><summary>
I had a go, now show me the answer.
</summary><p></p>
<p><strong>The slope (<span class="math inline">\(\beta\)</span>)</strong> tells us the strength and direction the relationship between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> is. While the linear regression model also estimates the intercept and the residual variance, these do not directly answer our question of interest. However, to make predictions, we will need all three parameters.</p>
</details><p></p>
</section></section><section id="worked-example-2" class="level3" data-number="5.5.2"><h3 data-number="5.5.2" class="anchored" data-anchor-id="worked-example-2">
<span class="header-section-number">5.5.2</span> Worked example</h3>
<p></p>
<p>In the previous section of this worked example, we fit a simple linear regression using the <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function and looked at the estimates of some parameters using the <code><a href="https://rdrr.io/r/stats/coef.html">coef()</a></code> function. In this section, we will use model theory to interpret what those parameters mean.</p>
<p></p>
<section id="the-intercept-and-slope" class="level4" data-number="5.5.2.1"><h4 data-number="5.5.2.1" class="anchored" data-anchor-id="the-intercept-and-slope">
<span class="header-section-number">5.5.2.1</span> The intercept and slope</h4>
<p>We already know that the parameters of the intercept and slope control the position and steepness of the regression line. It is the estimates of these two parameters that we get from the <code><a href="https://rdrr.io/r/stats/coef.html">coef()</a></code> function.</p>
<p></p>
<p>For our dive depth model the estimates are:</p>
<div class="cell">
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">dive_model</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  (Intercept)  body_size_kg 
755.977336598  -0.005384027 </code></pre>
</div>
</div>
<p></p>
<p>The intercept is 756 m and the slope of the relationship between body size and dive depth is -0.005.</p>
<p></p>
<p>In this case, the intercept is not that interesting. It tells us the expected value of <span class="math inline">\(Y\)</span> (maximum dive depth) when <span class="math inline">\(X\)</span> (body size) = 0. It does not make a lot of biological sense to know the expected dive depth of a marine mammal that weighs 0 kg. But, sometimes it can make sense to know the value <span class="math inline">\(Y\)</span> when <span class="math inline">\(X\)</span> is 0, for example if <span class="math inline">\(X\)</span> was temperature.</p>
<p></p>
<p>The slope on the other hand is interesting. It tells us the direction and strength of the relationship between body size and maximum dive depth. In this case our model estimates a negative slope. This means that for every increase of 1 kg in body size of marine mammals the maximum dive depth decreases by 0.005 m. In other words, there is a negative relationship between body weight and dive depth and as <span class="math inline">\(X\)</span> increases <span class="math inline">\(Y\)</span> decreases (<span class="quarto-unresolved-ref">?fig-fig-6</span>).</p>
<p></p>
</section><section id="residual-variance" class="level4" data-number="5.5.2.2"><h4 data-number="5.5.2.2" class="anchored" data-anchor-id="residual-variance">
<span class="header-section-number">5.5.2.2</span> Residual variance</h4>
<p>The <code><a href="https://rdrr.io/r/stats/coef.html">coef()</a></code> function can give us the maximum likelihood estimates of the intercept and slope parameters, but it does not give any information on the residual variance, <span class="math inline">\(\sigma^{2}\)</span>. To get an estimation of the residual variance, we use the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function with the model object as an argument. To extract <span class="math inline">\(\sigma\)</span> we use <code>$sigma</code> and square the result to get <span class="math inline">\(\sigma^{2}\)</span>.</p>
<p>You cannot take <code>var(residuals)</code> directly because this uses <code>n-1</code> as the denominator of the variance equation whereas to estimate <span class="math inline">\(\sigma^{2}\)</span> for a linear regression the denominator depends on the number of parameters being estimated. The denominator is the degrees of freedom (<code>n-number of parameters estimated</code>). In a simple linear regression there are two parameters that have been estimated (as well as <span class="math inline">\(\sigma^{2}\)</span>) these are the intercept and the slope. Therefore, the denominator <code>n-2</code>. The more explanatory variables you add to a linear regression, the more parameters you estimate and the fewer degrees of freedom you will have.</p>
<p></p>
<div class="cell">
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">sigma2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">dive_model</span><span class="op">)</span><span class="op">$</span><span class="va">sigma</span><span class="op">^</span><span class="fl">2</span>
<span class="va">sigma2</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 526362.7</code></pre>
</div>
</div>
<p></p>
<p>For this model the <span class="math inline">\(\sigma^{2}\)</span> = 5.263627^{5}. This number is abstract and does not mean anything on its own, but it <em>could</em> be used to compare models (though there are much better ways to do this). It does not help in terms of answering whether body size influences dive depth. But we will use it for prediction later.</p>
<p></p>
</section><section id="plotting-the-results" class="level4" data-number="5.5.2.3"><h4 data-number="5.5.2.3" class="anchored" data-anchor-id="plotting-the-results">
<span class="header-section-number">5.5.2.3</span> Plotting the results</h4>
<p>As well as looking at the maximum likelihood estimates of the parameters from the simple linear regression, we can also plot the estimated regression line.</p>
<p></p>
<p>To do this, we will use <code>ggplot()</code> with <code>geom_line()</code>.</p>
<p>We will also go into the second aim of a regression: <strong>predicting</strong>. Therefore, we need to use a new function called <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code>.</p>
<p></p>
<p>To make this first plot, we only need to use two arguments:</p>
<ul>
<li>
<code>object</code> = your model object</li>
<li>
<code>type</code> = “response”, which means predict on the response scale</li>
</ul>
<p></p>
<div class="cell">
<div class="sourceCode" id="cb16"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">depth_predictions</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">dive_model</span>, type<span class="op">=</span><span class="st">"response"</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p></p>
<p>Once we have created predictions of <span class="math inline">\(Y\)</span> from the model object, we can then plot these using <code>geom_line()</code> as in the code below.</p>
<div class="cell">
<div class="sourceCode" id="cb17"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">dive_model_fig</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">dive_data</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">body_size_kg</span>, y<span class="op">=</span><span class="va">max_depth</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_point</span><span class="op">(</span>colour <span class="op">=</span> <span class="st">'grey70'</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_line</span><span class="op">(</span><span class="fu">aes</span><span class="op">(</span>y<span class="op">=</span><span class="va">depth_predictions</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>y<span class="op">=</span><span class="st">"Maximum Dive Depth (m)"</span>,
  x<span class="op">=</span><span class="st">"Body Size (kg)"</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dive-model" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-dive-model-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.6: Scatter plot of dive depths against body size. The black line is the regression line predicted from the linear model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>In the next section we will look at how to add uncertainty to these plots and our interpretation.</p>
<p></p>
</section></section></section><section id="quantify-uncertainty" class="level2 tabset tabset-fade" data-number="5.6"><h2 class="tabset tabset-fade anchored" data-number="5.6" data-anchor-id="quantify-uncertainty">
<span class="header-section-number">5.6</span> <i class="fas fa-arrows-alt-h"></i> Quantify uncertainty</h2>
<p></p>
<section id="theory-3" class="level3" data-number="5.6.1"><h3 data-number="5.6.1" class="anchored" data-anchor-id="theory-3">
<span class="header-section-number">5.6.1</span> Theory</h3>
<p></p>
<p>You should already know that statistics does not give a single correct answer. When you estimate the values of parameters in our statistical model, there are many different values that could plausibly have produced the observed data. Some of these are more likely than others but several will have very similar likelihoods.</p>
<p></p>
<p>A simple linear regression is no different. And a way to cope with this, is to calculate and present the uncertainty in the parameters you estimate.</p>
<p></p>
<p>The <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> function produces results that are equivalent to maximum likelihood estimation of the parameters. Therefore, our consideration of uncertainty for these models follows the same principles as discussed <a href="link%20to%20ML%20page">here</a>. You can quantify uncertainty using <strong>standard errors</strong>, <strong>confidence intervals</strong>, and <strong>prediction intervals</strong> which should be familiar to you but head to the <a href="">uncertainty</a> pages if you need a recap.</p>
<p></p>
<p>For any regression there are two different types of uncertainty. Here, we cover at the <strong>uncertainty in the parameters of the regression line, <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span></strong> and the <strong>uncertainty in predictions of <span class="math inline">\(Y\)</span></strong>.</p>
<p></p>
<section id="uncertainty-in-the-estimates-of-alpha-and-beta" class="level4" data-number="5.6.1.1"><h4 data-number="5.6.1.1" class="anchored" data-anchor-id="uncertainty-in-the-estimates-of-alpha-and-beta">
<span class="header-section-number">5.6.1.1</span> Uncertainty in the estimates of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>
</h4>
<section id="standard-error" class="level5" data-number="5.6.1.1.1"><h5 data-number="5.6.1.1.1" class="anchored" data-anchor-id="standard-error">
<span class="header-section-number">5.6.1.1.1</span> Standard error</h5>
<p><strong>The standard error of a parameter is the standard deviation of its sampling distribution. It gives a measure of the spread of the sampling distribution i.e.&nbsp;the uncertainty.</strong> To find the standard errors for the estimates of <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> you can use the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> function. The argument that <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> takes is a model object, the output from <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code>. This function gives a big table with lots of information. The first line shows the model formula used for the model object. The second line shows a summary of the residuals of the model and the standard errors are shown as the second column in the third part, <code>Coefficients:</code>.</p>
<div class="cell">
<div class="sourceCode" id="cb18"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = response ~ explanatory, data = your_data)

Residuals:
    Min      1Q  Median      3Q     Max 
-5.1510 -3.0636  0.3854  1.4128  8.1477 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept)  2.77209    1.11970   2.476   0.0196 *  
explanatory  0.79698    0.05925  13.452 9.61e-14 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 3.28 on 28 degrees of freedom
Multiple R-squared:  0.866, Adjusted R-squared:  0.8612 
F-statistic:   181 on 1 and 28 DF,  p-value: 9.611e-14</code></pre>
</div>
</div>
<p></p>
<p>If we take the <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> of the example model, we can see the standard error or the intercept (<span class="math inline">\(\alpha\)</span>) is 0.95825, and the standard error for the slope (<span class="math inline">\(\beta\)</span>) is 0.05483.</p>
<p></p>
</section><section id="confidence-intervals" class="level5" data-number="5.6.1.1.2"><h5 data-number="5.6.1.1.2" class="anchored" data-anchor-id="confidence-intervals">
<span class="header-section-number">5.6.1.1.2</span> Confidence intervals</h5>
<p>For interpretation of the uncertainty, it can be easier to use the standard error to calculate confidence intervals (CI). Confidence intervals indicate the range of plausible values for a parameter. <strong>They represent an interval, that if you were to collect a sample and run the analysis, then repeat that many many times AND each time draw a confidence interval, on average 95% of the time, the true population value of the parameter would be found in within the confidence interval.</strong></p>
<p>If you need a reminder of this click <a href="link%20to%20uncertainty%20page">here</a>.</p>
<p></p>
<p>The confidence interval can be calculated using this formula:</p>
<p><span class="math display">\[
\begin{aligned}
UpperCI = estimate + (1.96 SE) \\
LowerCI = estimate - (1.96 SE) \\
\end{aligned}
\]</span></p>
<p>1.96 is used because in a standard normal distribution 95% of the distribution lies within 1.96 standard deviations of the mean. In this case the distribution is the sampling distribution, which is normal for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> and the standard deviation is the standard error.</p>
<p></p>
<p>Using the formulas above, calculate the confidence intervals for the intercept and slope from the example model.</p>
<p></p>
<details><summary>
I had a go at calculating, what is the correct answer?
</summary><div class="cell">
<div class="sourceCode" id="cb20"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="co"># INTERCEPT</span>

<span class="co"># Upper confidence interval</span>
<span class="va">upper_ci_intercept</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">+</span> 
  <span class="op">(</span><span class="fl">1.96</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span>
<span class="co"># Lower confidence interval</span>
<span class="va">lower_ci_intercept</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">-</span> 
  <span class="op">(</span><span class="fl">1.96</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span>

<span class="co"># Print the interval</span>
<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">upper_ci_intercept</span>, <span class="va">lower_ci_intercept</span><span class="op">)</span> </code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 4.9667025 0.5774699</code></pre>
</div>
<div class="sourceCode" id="cb22"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="co"># SLOPE</span>

<span class="co"># Upper confidence interval</span>
<span class="va">upper_ci_slope</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">+</span> <span class="op">(</span><span class="fl">1.96</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span>
<span class="co"># Lower confidence interval</span>
<span class="va">lower_ci_slope</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">1</span><span class="op">]</span> <span class="op">-</span> <span class="op">(</span><span class="fl">1.96</span><span class="op">*</span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span><span class="op">$</span><span class="va">coefficients</span><span class="op">[</span><span class="fl">2</span>,<span class="fl">2</span><span class="op">]</span><span class="op">)</span>

<span class="co"># Print the interval</span>
<span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">upper_ci_slope</span>, <span class="va">lower_ci_slope</span><span class="op">)</span> </code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9131062 0.6808633</code></pre>
</div>
</div>
</details><p></p>
<p>It is also possible to get R to calculate the confidence intervals for you. To do this you can use the <code><a href="https://rdrr.io/r/stats/confint.html">confint()</a></code> function. The argument is a model object.</p>
<div class="cell">
<div class="sourceCode" id="cb24"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">model_object</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                2.5 %   97.5 %
(Intercept) 0.4784802 5.065692
explanatory 0.6756256 0.918344</code></pre>
</div>
</div>
<p></p>
<p>Hopefully these confidence intervals look the same as those you calculated yourself.</p>
<p></p>
</section></section><section id="uncertainty-in-a-prediction-of-y" class="level4" data-number="5.6.1.2"><h4 data-number="5.6.1.2" class="anchored" data-anchor-id="uncertainty-in-a-prediction-of-y">
<span class="header-section-number">5.6.1.2</span> Uncertainty in a prediction of <span class="math inline">\(Y\)</span>
</h4>
<p>So far, we have covered uncertainty in parameter estimates using standard errors and confidence intervals but linear regression analyses can also be used for prediction. When a linear regression is used for prediction, an interval of confidence in the prediction should also be given. This is a type of confidence interval specific for predictions and can be called a <strong>prediction interval</strong>.</p>
<p></p>
<p><strong>A 95% prediction interval tells you, if you were to collect a sample and run the analysis, then go out an collect a new observation of the response variable (<span class="math inline">\(Y\)</span>) with particular value of the explanatory variable (<span class="math inline">\(X\)</span>) many many times AND each time draw a prediction interval, 95% of the time, the new observation would fall in within the prediction interval.</strong></p>
<p></p>
<p>To find the prediction interval for a prediction you use the <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> function with the <code>interval="prediction"</code> argument. You also set the <code>newdata</code> argument to the value of <span class="math inline">\(X\)</span> you want to predict for.</p>
<div class="cell">
<div class="sourceCode" id="cb26"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">model_object</span>, newdata<span class="op">=</span><span class="va">x_predict</span>, 
                             type<span class="op">=</span><span class="st">"response"</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p></p>
</section></section><section id="worked-example-3" class="level3" data-number="5.6.2"><h3 data-number="5.6.2" class="anchored" data-anchor-id="worked-example-3">
<span class="header-section-number">5.6.2</span> Worked example</h3>
<p></p>
<p>At the end of the last section, we created a plot of our dive depth data and the estimated linear regression line. Now, we will add uncertainty to that plot.</p>
<p></p>
<p>First, we should look at the confidence intervals of our parameter estimates.</p>
<div class="cell">
<div class="sourceCode" id="cb27"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/confint.html">confint</a></span><span class="op">(</span><span class="va">dive_model</span><span class="op">)</span>,<span class="fl">2</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>              2.5 %  97.5 %
(Intercept)  449.03 1062.93
body_size_kg  -0.02    0.01</code></pre>
</div>
</div>
<p></p>
<p>The confidence intervals have been rounded to 2 decimal places to make them easier to read. The intercept interval spans from approx 450 to 1060. The slope interval crosses 0, going from -0.02 to +0.01.</p>
<p></p>
<p>To add these intervals to the plot, we need to make new predictions including the confidence interval. In this case we are using confidence intervals even though we are predicting, because we want to show the uncertainty in <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> rather than in a novel prediction. We have to make predictions in order to plot rather than because we are interested in them.</p>
<div class="cell">
<div class="sourceCode" id="cb29"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">depth_predictions</span> <span class="op">&lt;-</span> <span class="fu">as_tibble</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">dive_model</span>, type<span class="op">=</span><span class="st">"response"</span>, interval<span class="op">=</span><span class="st">"confidence"</span><span class="op">)</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p></p>
<p>Once we have created predictions of <span class="math inline">\(Y\)</span> from the model object, we can then plot these using <code>geom_line()</code> and <code>geom_ribbon()</code> for the confidence interval as in the code below.</p>
<div class="cell">
<div class="sourceCode" id="cb30"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">depth_predictions</span> <span class="op">&lt;-</span> <span class="va">depth_predictions</span> <span class="op">%&gt;%</span>
                      <span class="fu">mutate</span><span class="op">(</span>x<span class="op">=</span><span class="va">dive_data</span><span class="op">$</span><span class="va">body_size_kg</span><span class="op">)</span>

<span class="va">fig_7</span> <span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_ribbon</span><span class="op">(</span>data<span class="op">=</span><span class="va">depth_predictions</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">x</span>, ymin<span class="op">=</span><span class="va">lwr</span>, ymax<span class="op">=</span><span class="va">upr</span><span class="op">)</span>, fill<span class="op">=</span><span class="st">'grey50'</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_point</span><span class="op">(</span>data<span class="op">=</span><span class="va">dive_data</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">body_size_kg</span>, y<span class="op">=</span><span class="va">max_depth</span><span class="op">)</span>,colour <span class="op">=</span> <span class="st">'grey70'</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_line</span><span class="op">(</span>data<span class="op">=</span><span class="va">depth_predictions</span>, <span class="fu">aes</span><span class="op">(</span>y<span class="op">=</span><span class="va">fit</span>, x<span class="op">=</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">labs</span><span class="op">(</span>y<span class="op">=</span><span class="st">"Maximum Dive Depth (m)"</span>,
  x<span class="op">=</span><span class="st">"Body Size (kg)"</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-dive-predictions-plot" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-dive-predictions-plot-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.7: Scatter plot of dive depths against body size. Line is the regression line from a linear model. Shaded area is 95% confidence interval</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>You will notice that the confidence interval is narrower in the middle and wider at the ends. This is partly to do with the constraint that the regression line must go through the (<span class="math inline">\(\bar{X}\)</span>, <span class="math inline">\(\bar{Y}\)</span>) point so the intercept and slope are not independent. Therefore, the confidence interval will be narrowest close to that point.</p>
<p></p>
<p>The plot shows that the uncertainty in the estimated relationship gets increasingly uncertain as you get to higher body sizes.</p>
<p></p>
<section id="predicting-dive-depths-for-a-body-size-of-75000kg" class="level4" data-number="5.6.2.1"><h4 data-number="5.6.2.1" class="anchored" data-anchor-id="predicting-dive-depths-for-a-body-size-of-75000kg">
<span class="header-section-number">5.6.2.1</span> Predicting dive depths for a body size of 75000kg</h4>
<p>A colleague as just found a new species of whale (fictional). The whale washed up on shore in Tromsø, it weighed 75000kg. Based on our linear regression analysis, how deep would we expect it to dive?</p>
<div class="cell">
<div class="sourceCode" id="cb31"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">dive_model</span>, newdata<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>body_size_kg<span class="op">=</span><span class="fl">75000</span><span class="op">)</span>, 
                             type<span class="op">=</span><span class="st">"response"</span>, interval <span class="op">=</span> <span class="st">"prediction"</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>       fit       lwr      upr
1 352.1753 -1328.376 2032.727</code></pre>
</div>
</div>
<p></p>
<p>The mean prediction is 352m deep. This seems ok. But when we look at the prediction interval, we see that when we include uncertainty, we are not even sure if they whale will dive below the surface by 2km or jump into the air by 1.3km. When we include uncertainty, it is clear that based on the current data and model, we cannot say anything about the possible dive depth of the new whale. We even get biologically unrealistic predictions.</p>
<p></p>
<p>This is something we will look at in the next section.</p>
<p></p>
</section></section></section><section id="model-checking" class="level2 tabset tabset-fade" data-number="5.7"><h2 class="tabset tabset-fade anchored" data-number="5.7" data-anchor-id="model-checking">
<span class="header-section-number">5.7</span> <i class="fas fa-tasks"></i> Model checking</h2>
<p>You have now have a model, estimates of parameters, and have calculated the uncertainty of the parameters. <strong>But how can we know if a model is any good?</strong></p>
<p></p>
<section id="theory-4" class="level3" data-number="5.7.1"><h3 data-number="5.7.1" class="anchored" data-anchor-id="theory-4">
<span class="header-section-number">5.7.1</span> Theory</h3>
<p></p>
<p>To find out if the model is any good from a theoretical perspective, you need to check if the model meets the five assumptions of the linear regression that are stated in the <strong>Model details</strong> section above.</p>
<p></p>
<p>For this, you can use graphs called <strong>diagnostic plots</strong>. There are four key diagnostic plots that we use for simple linear regression and each plot tests whether a different assumption has been met. To make the diagnostic plots, you use the <code><a href="https://rdrr.io/r/graphics/plot.default.html">plot()</a></code> function with our linear model object as the first argument and <code>which = number</code> as the second. The number should be replaced by the number corresponding to the plot you want.</p>
<p></p>
<p>For more on what each plot means, go here: <a href="">Model checking</a>. On this page, you can find some example plots for a simple linear regression.</p>
<p><strong>Note:</strong> for all of these plots, we do not expect perfection, especially for biological data.</p>
<section id="residuals-vs-fitted-plot" class="level4" data-number="5.7.1.1"><h4 data-number="5.7.1.1" class="anchored" data-anchor-id="residuals-vs-fitted-plot">
<span class="header-section-number">5.7.1.1</span> 1. Residuals vs fitted plot</h4>
<p></p>
<p>There are two examples of residuals vs fitted plots shown below. If the assumptions are met, you can expect a few characteristics of the plot:</p>
<ul>
<li>The red line should be roughly horizontally straight and at 0</li>
<li>There should be no structure in the residuals</li>
<li>The residuals should not curve</li>
</ul>
<p></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-residuals-vs-fitted-fig" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-residuals-vs-fitted-fig-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.8: Example of a good (left) and a bad (right) residuals vs fitted plot for a simple linear regression</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><strong>In reality, it will not be as clear cut as the examples above. You will need to use your own judgment to decide if the assumption is sufficiently met. Do not expect perfection.</strong></p>
<p></p>
</section><section id="normal-qq-plot" class="level4" data-number="5.7.1.2"><h4 data-number="5.7.1.2" class="anchored" data-anchor-id="normal-qq-plot">
<span class="header-section-number">5.7.1.2</span> Normal QQ plot</h4>
<p>There are two examples of normal QQ plots shown below. If the assumptions are met, you can expect:</p>
<ul>
<li>The points to lie along the line</li>
</ul>
<p></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-normal-qq" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-normal-qq-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.9: Example of a good (left) and a bad (right) normal QQ diagnostic plot</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p><strong>Notice that the y-axes have different values.</strong></p>
<p><br></p>
</section><section id="scale-location" class="level4" data-number="5.7.1.3"><h4 data-number="5.7.1.3" class="anchored" data-anchor-id="scale-location">
<span class="header-section-number">5.7.1.3</span> Scale-location</h4>
<p>There are two examples of scale-leverage plots shown below. If the assumptions are met, you can expect:</p>
<ul>
<li>The red line to be horizontal</li>
<li>There is no structure in the points</li>
</ul>
<p></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-scale-location" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-scale-location-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.10: Example of a good (left) and a bad (right) scale-location plot</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
</section><section id="cooks-distance" class="level4" data-number="5.7.1.4"><h4 data-number="5.7.1.4" class="anchored" data-anchor-id="cooks-distance">
<span class="header-section-number">5.7.1.4</span> Cook’s Distance</h4>
<p>There are two examples of Cook’s Distance plots shown below. If the assumptions are met, you can expect:</p>
<ul>
<li>Low values of Cook’s Distance (y-axis) and no points standing out on their own</li>
</ul>
<p></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-cook-d" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-cook-d-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.11: Example of a good (left) and a bad (right) Cook’s Distance plot</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p><strong>Notice that the y-axes have different values.</strong></p>
<p></p>
</section></section><section id="worked-example-4" class="level3" data-number="5.7.2"><h3 data-number="5.7.2" class="anchored" data-anchor-id="worked-example-4">
<span class="header-section-number">5.7.2</span> Worked example</h3>
<p></p>
<p>Using the theory covered in the previous section, we can now check our dive_model to ensure that it meets the assumptions of a simple linear regression.</p>
<p></p>
<p>We will use one plot at a time to test specific assumptions.</p>
<p></p>
<section id="residuals-vs-fitted" class="level4" data-number="5.7.2.1"><h4 data-number="5.7.2.1" class="anchored" data-anchor-id="residuals-vs-fitted">
<span class="header-section-number">5.7.2.1</span> Residuals vs fitted</h4>
<div class="cell">
<div class="sourceCode" id="cb33"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dive_model</span>, which <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-dive-residual" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-dive-residual-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.12: Residuals vs fitted plot for dive depths model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p><a href="#fig-dive-residual">Figure&nbsp;<span>5.12</span></a> looks quite unusual.</p>
<p>There are a few assumptions we are checking with this plot:</p>
<ul>
<li>
<strong>Is the relationship between X and Y linear?</strong> It does seem to be. While the red line is not straight, it does not show a clear pattern until the very end. At the very end, there is a strong negative trend. We might need to come back to this! It seems like there might be one pattern for shallow diving species and another for the deep divers.</li>
<li>
<strong>Do the residuals have a mean of 0?</strong> There is a deviation at fitted values of &gt; 700, otherwise yes, the mean of the residuals is approximately 0.</li>
<li>
<strong>Is the variance of the residuals is equal for all fitted values (homoscedasticity)?</strong> It is not the nice cloud of random points that we expect. <strong>But is it a problem?</strong> To answer this, we need to look at bit closer. The strange shape comes from the residuals at low fitted values, these are the shallow diving marine mammals. You might notice that there are very few of these values. The majority of the data have fitted values &gt; 700. Where we have more data, the residuals vs fitted plot looks better.</li>
</ul>
<p>At this point, it might be hard to say how problematic the low variance caused by the lack of data for low fitted values is. But, we can have a look at the points causing the pattern (those with a maximum dive depth &lt; 600m).</p>
<div class="cell">
<div class="sourceCode" id="cb34"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/filter.html">filter</a></span><span class="op">(</span><span class="va">dive_data</span>, <span class="va">max_depth</span> <span class="op">&lt;</span> <span class="fl">600</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 19 × 6
   species            max_depth body_size_kg group    Species            Group  
   &lt;chr&gt;                  &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;    &lt;fct&gt;              &lt;fct&gt;  
 1 Orca                     264         4500 Twhale   Orca               Twhale 
 2 HomoSapien               112           85 Other    HomoSapien         Other  
 3 BlueWhale                172       100000 Bwhale   BlueWhale          Bwhale 
 4 FinWhale                 128        60000 Bwhale   FinWhale           Bwhale 
 5 HumpbackWhale            240        36000 Bwhale   HumpbackWhale      Bwhale 
 6 SouthernRightWhale       180        54000 Bwhale   SouthernRightWhale Bwhale 
 7 BrydesWhale              300        41000 Bwhale   BrydesWhale        Bwhale 
 8 Walrus                   450         1500 Pinniped Walrus             Pinnip…
 9 LeopardSeal               16          400 Pinniped LeopardSeal        Pinnip…
10 HarbourSeal              481           85 Pinniped HarbourSeal        Pinnip…
11 CaliforniaSeaLion        536          226 Pinniped CaliforniaSeaLion  Pinnip…
12 NZFurSeal                238          100 Pinniped NZFurSeal          Pinnip…
13 NZSeaLion                550          110 Pinniped NZSeaLion          Pinnip…
14 MinkeWhale               106         8000 Bwhale   MinkeWhale         Bwhale 
15 CommonDolphin            260           80 Twhale   CommonDolphin      Twhale 
16 HarbourPorpoise          100           55 Twhale   HarbourPorpoise    Twhale 
17 PolarBear                 13          500 Other    PolarBear          Other  
18 SeaOtter                 101           30 Other    SeaOtter           Other  
19 BottlenoseDolphin        300          450 Twhale   BottlenoseDolphin  Twhale </code></pre>
</div>
</div>
<p></p>
<p>From these data, we can see that five of the six baleen whales (Group = Bwhale) are included in this subset. This is quite interesting. It could be biologically reasonable that these whales follow a different pattern to the other species because their physiology is very different.</p>
<p><strong>Keep that last point in mind when we get on to interpreting the results.</strong></p>
</section><section id="normal-qq" class="level4" data-number="5.7.2.2"><h4 data-number="5.7.2.2" class="anchored" data-anchor-id="normal-qq">
<span class="header-section-number">5.7.2.2</span> Normal QQ</h4>
<div class="cell">
<div class="sourceCode" id="cb36"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dive_model</span>, which <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-dive-qq" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-dive-qq-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.13: Normal QQ plot for dive depth model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>The assumption we are checking with this plot is: <strong>are the residuals are normally distributed?</strong></p>
<p>As expected, there is not a perfect match between the theoretical normal distribution and the distribution of the residuals. There is some deviation at both tails of the distribution. At lower quantiles, this seems ok. At higher values, points 9 and 10 deviate quite a lot. These points also stood out in <a href="#fig-dive-residual">Figure&nbsp;<span>5.12</span></a>. We will need to look into them more in <a href="#fig-dive-cook-d">Figure&nbsp;<span>5.15</span></a>.</p>
<p></p>
</section><section id="scale-location-1" class="level4" data-number="5.7.2.3"><h4 data-number="5.7.2.3" class="anchored" data-anchor-id="scale-location-1">
<span class="header-section-number">5.7.2.3</span> Scale-location</h4>
<div class="cell">
<div class="sourceCode" id="cb37"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dive_model</span>, which <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-dive-scale" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-dive-scale-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.14: Scale-location plot for dive depth model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>The assumption we are checking with this plot is: <strong>Do the residuals have equal variance across fitted values?</strong></p>
<p><span class="quarto-unresolved-ref">?fig-fig-14</span> shows a very similar picture to <span class="quarto-unresolved-ref">?fig-fig-12</span>. While there is a slight increase in variance as the amount of data increases, the amount of change is &lt; 0.5 and there is not much structure in the points. So, this looks like things are ok.</p>
<p></p>
</section><section id="cooks-distance-1" class="level4" data-number="5.7.2.4"><h4 data-number="5.7.2.4" class="anchored" data-anchor-id="cooks-distance-1">
<span class="header-section-number">5.7.2.4</span> Cook’s distance</h4>
<div class="cell">
<div class="sourceCode" id="cb38"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">dive_model</span>, which <span class="op">=</span> <span class="fl">4</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-dive-cook-d" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-dive-cook-d-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.15: Cook’s distance plot for the dive depth model</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>The assumption we are checking with this plot is: <strong>Are there any outliers?</strong></p>
<p><a href="#fig-dive-cook-d">Figure&nbsp;<span>5.15</span></a> shows that the Cook’s distances of this model are not very high (max = 0.2). So, it does not seem that any points have that large an influence on the fitted values. However, point 10 does seem to be quite different from the others. This might be worth looking into.</p>
<p></p>
<p>We can find point 10 by looking at the 10th row of our data frame. It is the entry for the Cuvier’s beaked whale. While this is a rare and unusual whale, it is not the only beaked whale in our dataset and we have no reason to believe this data is a typo. <strong>Therefore, we would not consider this an outlier and would not remove from the data.</strong></p>
<div class="cell">
<div class="sourceCode" id="cb39"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">dive_data</span> <span class="op">%&gt;%</span> <span class="fu">slice</span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 1 × 6
  species            max_depth body_size_kg group  Species            Group 
  &lt;chr&gt;                  &lt;int&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;fct&gt;              &lt;fct&gt; 
1 CuviersBeakedWhale      2992         2500 Twhale CuviersBeakedWhale Twhale</code></pre>
</div>
</div>
<p></p>
</section><section id="summary" class="level4" data-number="5.7.2.5"><h4 data-number="5.7.2.5" class="anchored" data-anchor-id="summary">
<span class="header-section-number">5.7.2.5</span> Summary</h4>
<p>Overall, it seems that most of the model assumptions are met well. The only red flag is in the equal variance assumption. However, this seems to be caused in part by a lower amount of data available at the extremes of dive depths. Therefore, we think it is ok to proceed with this model.</p>
<p></p>
<p>In the next section we will interpret our results.</p>
<p></p>
</section></section></section><section id="draw-conclusions" class="level2 tabset tabset-fade page-columns page-full" data-number="5.8"><h2 class="tabset tabset-fade anchored" data-number="5.8" data-anchor-id="draw-conclusions">
<span class="header-section-number">5.8</span> <i class="far fa-lightbulb"></i> Draw conclusions</h2>
<section id="theory-5" class="level3" data-number="5.8.1"><h3 data-number="5.8.1" class="anchored" data-anchor-id="theory-5">
<span class="header-section-number">5.8.1</span> Theory</h3>
<p>In the previous sections you learned how to run a simple linear regression models, what the parameters of the model mean, how to quantify uncertainty in the parameters, and how to check the assumptions of the model. Now, you can bring everything together to draw some conclusions.</p>
<p></p>
<p>There are several components required in drawing a conclusion:</p>
<ul>
<li>statement of the maximum likelihood estimate of the parameters of interest (including strength and direction)</li>
<li>statement of the uncertainty in the estimate</li>
<li>statement of how good the model is i.e.&nbsp; how well the model meets assumptions and the amount of variance explained (using <span class="math inline">\(R^2\)</span> - explained below)</li>
<li>link the results to biology and the question asked</li>
<li>Discussion of next directions</li>
</ul>
<p></p>
<p>One measure that can be useful for conclusions is to know <strong>how much of the variation in <span class="math inline">\(Y\)</span> is explained by <span class="math inline">\(X\)</span></strong>. To answer this you can use a measure called the <span class="math inline">\(R^2\)</span>. It is calculated using the following equation:</p>
<p><span class="math display">\[
R^2 = 1 - \frac{\color{darkblue}{\text{Residual Variance}} }{\text{Total Variance}}
\]</span></p>
<p>and can be found in R using <code>summary(your_model)$r.squared</code>. The value is a proportion, so between 0 (no variance explained) and 1 (all variance explained). A good value is subjective, but &gt; 0.5 is usually considered good, &gt; 0.7 is very good and a value of 1 is suspicious. For biological data, achieving an <span class="math inline">\(R^{2}\)</span> of 0.5 or higher can be challenging because in the real world there are lots of variables influencing each response, more than we could measure and include in an analysis. In these cases, <span class="math inline">\(R^{2}\)</span> could be as low as e.g.&nbsp;0.3 or 0.1, but this does not mean the model is not valid. It only means that other processes are causing variation in the response on top of those included in the model.</p>
<p></p>
</section><section id="worked-example-5" class="level3" data-number="5.8.2"><h3 data-number="5.8.2" class="anchored" data-anchor-id="worked-example-5">
<span class="header-section-number">5.8.2</span> Worked example</h3>
<p>This is the final section of our analysis of the data on marine mammal maximum dive depths. We will now bring together all of the results we have obtained and draw a conclusion following the same format as in the theory section.</p>
<p>A reminder, we were asking: <strong>Does body size influence maximum dive depth in marine mammals?</strong></p>
<p></p>
<p>The maximum likelihood estimate of the relationship between body size and maximum dive depth in marine mammals was -0.005. In other words, for every 1 kg increase in body weight, marine mammals dived 0.005 m less deep. Given that some marine mammals can dive 1000s of metres, this increase per kg is very low.</p>
<p></p>
<p>When we look at the uncertainty in this estimate, we see the 95% confidence interval is -0.017 to 0.006. The confidence interval limits are different signs, meaning that 0 is included as a plausible value for the strength of the relationship. Therefore, we cannot conclude that body size has any impact on maximum dive depth in marine mammals. This is supported by the <span class="math inline">\(R^2\)</span> value, which is 0.03, suggesting only 3% of the variation in maximum dive depth is explained by body size. This is a good example of the lower <span class="math inline">\(R^2\)</span> we often get in biology.</p>
<p></p>
<p>We should remember here, that when we predicted a dive depth for the fictional whale, it gave us a negative result. Linear models fit a straight line, which can extend beyond the realistic values for some variables. This should be noted and predictions should not be made outside of values that are plausible. This is one reason why predicting outside of the range of your data can be problematic. We can also fit models that are not linear, there is more on those <a href="link%20to%20GLMs">here</a>.</p>
<p></p>
<p>In model checking, there was an interesting pattern shown, of little data at the lowest maximum dive depths and a disproportionate representation of baleen whales. If we plot the data by group and allow ggplot to fit a regression line per group, we can see that there seems to be a different pattern for different taxonomic groups. This would make sense based on physiology and might explain why the variance assumption was not met well AND why the estimated relationship was so weak.</p>
<div class="cell">
<div class="sourceCode" id="cb41"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">final_dive_fig</span><span class="op">&lt;-</span> <span class="fu">ggplot</span><span class="op">(</span><span class="va">dive_data</span>, <span class="fu">aes</span><span class="op">(</span>x<span class="op">=</span><span class="va">body_size_kg</span>, y<span class="op">=</span><span class="va">max_depth</span>, color<span class="op">=</span><span class="va">group</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_point</span><span class="op">(</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">facet_wrap</span><span class="op">(</span><span class="va">.</span><span class="op">~</span><span class="va">group</span><span class="op">)</span><span class="op">+</span>
  <span class="fu">geom_smooth</span><span class="op">(</span>method<span class="op">=</span><span class="st">'lm'</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="cell-output-display">
<div id="fig-final-dive" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="2.1_simple_linear_regression_files/figure-html/fig-final-dive-1.png" class="img-fluid figure-img" width="672"></p>
<p></p><figcaption aria-hidden="true" class="figure-caption">Figure 5.16: Plot of the relationship between dive depth and body size faceted by taxonomic group</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p>
<p>While the baleen whales show no relationship between dive depth and body size, both the pinnipeds (seals and sea lions) and the toothed whales (orca, dolphins, porpoises) show quite strong positive relationships between dive depth and body size. By treating all groups as the same in one analysis, we might have been masking the true effects.</p>
<p>It might be more appropriate to consider an effect of Group as well as body size. We can do this using <strong>Linear models for categorical explanatory variables</strong>/<strong>ANOVA</strong>, check out these pages to continue the analysis of this data.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What’s next
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>
<strong>Linear models for categorical explanatory variables</strong>/<strong>ANOVA</strong> for analyses when your explanatory variable is not numeric</li>
<li>
<strong>Multiple regression</strong> for analyses with more than one numeric explanatory variable</li>
<li>
<strong>Generalised linear models</strong> for analyses when your response variable is not normally distributed</li>
</ul>
</div>
</div>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Further reading
</div>
</div>
<div class="callout-body-container callout-body">

</div>
</div>
</section>

<!-- -->

<div class="no-row-height column-margin column-container"><section id="contributors" class="level3 unlisted unnumbered"><h3 class="unlisted unnumbered anchored" data-anchor-id="contributors">Contributors</h3>
<ul>
<li>Emily G Simmonds</li>
</ul></section></div></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
    } else {
      disableStylesheet(alternateStylesheets);
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./1.0_descriptive_statistics.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Descriptive Statistics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./2.2_anova.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Anova</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb42" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Simple linear Regression</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, eval=TRUE, include=FALSE}</span></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a><span class="co"># add all packages that need loading</span></span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(knitr)</span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a><span class="co"># source figure settings</span></span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a><span class="fu">source</span>(<span class="st">"../StatisticsInR/Files/biostats_theme.R"</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup-data, include=FALSE, echo=FALSE}</span></span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a><span class="co"># import data for the example</span></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>dive_data <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"../StatisticsInR/Files/dive_depths.csv"</span>)</span>
<span id="cb42-19"><a href="#cb42-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-20"><a href="#cb42-20" aria-hidden="true" tabindex="-1"></a><span class="co"># set the data type for each column</span></span>
<span id="cb42-21"><a href="#cb42-21" aria-hidden="true" tabindex="-1"></a>dive_data <span class="ot">&lt;-</span> dive_data <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">max_depth =</span> <span class="fu">as.integer</span>(max_depth), <span class="at">Species =</span> </span>
<span id="cb42-22"><a href="#cb42-22" aria-hidden="true" tabindex="-1"></a>                                  <span class="fu">as.factor</span>(species), <span class="at">Group =</span> <span class="fu">as.factor</span>(group))</span>
<span id="cb42-23"><a href="#cb42-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-24"><a href="#cb42-24" aria-hidden="true" tabindex="-1"></a><span class="co"># load data for spurious correlation figure</span></span>
<span id="cb42-25"><a href="#cb42-25" aria-hidden="true" tabindex="-1"></a>Spurious <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"./Files/Spurious.csv"</span>)</span>
<span id="cb42-26"><a href="#cb42-26" aria-hidden="true" tabindex="-1"></a><span class="co"># convert pounds to kg</span></span>
<span id="cb42-27"><a href="#cb42-27" aria-hidden="true" tabindex="-1"></a>Spurious <span class="ot">&lt;-</span> Spurious <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">uranium_us =</span> <span class="fu">round</span>(uranium_us<span class="sc">/</span><span class="fl">2.205</span>, <span class="dv">2</span>))</span>
<span id="cb42-28"><a href="#cb42-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-29"><a href="#cb42-29" aria-hidden="true" tabindex="-1"></a><span class="co"># create an example dataset for illustrative purposes</span></span>
<span id="cb42-30"><a href="#cb42-30" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>) <span class="co"># make sure it is the same each time you run code</span></span>
<span id="cb42-31"><a href="#cb42-31" aria-hidden="true" tabindex="-1"></a>your_data <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">data.frame</span>(<span class="at">response =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>,</span>
<span id="cb42-32"><a href="#cb42-32" aria-hidden="true" tabindex="-1"></a>                                 <span class="at">explanatory =</span> <span class="fu">rnorm</span>(<span class="dv">30</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">30</span>,<span class="dv">3</span>)))</span>
<span id="cb42-33"><a href="#cb42-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-34"><a href="#cb42-34" aria-hidden="true" tabindex="-1"></a><span class="co"># create an example dataset for plotting</span></span>
<span id="cb42-35"><a href="#cb42-35" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>) <span class="co"># make sure it is the same each time you run code</span></span>
<span id="cb42-36"><a href="#cb42-36" aria-hidden="true" tabindex="-1"></a>example_data <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">100</span>,<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>,<span class="dv">10</span>),<span class="dv">2</span>),</span>
<span id="cb42-37"><a href="#cb42-37" aria-hidden="true" tabindex="-1"></a>                          <span class="at">y =</span> <span class="fu">seq</span>(<span class="dv">1</span>,<span class="dv">50</span>,<span class="at">length.out=</span><span class="dv">100</span>),</span>
<span id="cb42-38"><a href="#cb42-38" aria-hidden="true" tabindex="-1"></a>                          <span class="at">z =</span> <span class="fu">as.factor</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">100</span>)))</span>
<span id="cb42-39"><a href="#cb42-39" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-40"><a href="#cb42-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-41"><a href="#cb42-41" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-42"><a href="#cb42-42" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb42-43"><a href="#cb42-43" aria-hidden="true" tabindex="-1"></a><span class="fu">## Before you start</span></span>
<span id="cb42-44"><a href="#cb42-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-45"><a href="#cb42-45" aria-hidden="true" tabindex="-1"></a>You should be familiar with basic statistical theory, basics of R, continuous </span>
<span id="cb42-46"><a href="#cb42-46" aria-hidden="true" tabindex="-1"></a>and categorical data, hypothesis testing, statistical modeling, </span>
<span id="cb42-47"><a href="#cb42-47" aria-hidden="true" tabindex="-1"></a>and the concept of linear models.</span>
<span id="cb42-48"><a href="#cb42-48" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-49"><a href="#cb42-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-50"><a href="#cb42-50" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb42-51"><a href="#cb42-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-52"><a href="#cb42-52" aria-hidden="true" tabindex="-1"></a>In this section, we will look at how we can use simple linear regression </span>
<span id="cb42-53"><a href="#cb42-53" aria-hidden="true" tabindex="-1"></a>to analyze data with a continuous numeric response </span>
<span id="cb42-54"><a href="#cb42-54" aria-hidden="true" tabindex="-1"></a>and a numeric explanatory variable. </span>
<span id="cb42-55"><a href="#cb42-55" aria-hidden="true" tabindex="-1"></a>Linear regression is a type of linear model.</span>
<span id="cb42-56"><a href="#cb42-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-57"><a href="#cb42-57" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-58"><a href="#cb42-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-59"><a href="#cb42-59" aria-hidden="true" tabindex="-1"></a>Linear regression has two motivations. </span>
<span id="cb42-60"><a href="#cb42-60" aria-hidden="true" tabindex="-1"></a>The first is called **inference**, </span>
<span id="cb42-61"><a href="#cb42-61" aria-hidden="true" tabindex="-1"></a>which is when you want to say something about a population from a sample. </span>
<span id="cb42-62"><a href="#cb42-62" aria-hidden="true" tabindex="-1"></a>Very often data are only available for a subset of the population (a sample), </span>
<span id="cb42-63"><a href="#cb42-63" aria-hidden="true" tabindex="-1"></a>but we want to generalize our conclusions for the whole population. </span>
<span id="cb42-64"><a href="#cb42-64" aria-hidden="true" tabindex="-1"></a>Therefore, we use statistical models to **infer** effects at the whole </span>
<span id="cb42-65"><a href="#cb42-65" aria-hidden="true" tabindex="-1"></a>population level from what we find at the sample level. </span>
<span id="cb42-66"><a href="#cb42-66" aria-hidden="true" tabindex="-1"></a>The second motivation is **prediction**, </span>
<span id="cb42-67"><a href="#cb42-67" aria-hidden="true" tabindex="-1"></a>where we use a model to predict values of the response for specific values of </span>
<span id="cb42-68"><a href="#cb42-68" aria-hidden="true" tabindex="-1"></a>the explanatory variable. </span>
<span id="cb42-69"><a href="#cb42-69" aria-hidden="true" tabindex="-1"></a>These predictions can either be for observed values </span>
<span id="cb42-70"><a href="#cb42-70" aria-hidden="true" tabindex="-1"></a>of the explanatory (mainly used for plotting), for unobserved values of the </span>
<span id="cb42-71"><a href="#cb42-71" aria-hidden="true" tabindex="-1"></a>explanatory variable within the same range as observations, </span>
<span id="cb42-72"><a href="#cb42-72" aria-hidden="true" tabindex="-1"></a>or for novel values of the explanatory variable outside the range of </span>
<span id="cb42-73"><a href="#cb42-73" aria-hidden="true" tabindex="-1"></a>observations (this is more risky! - more on this later).</span>
<span id="cb42-74"><a href="#cb42-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-75"><a href="#cb42-75" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-76"><a href="#cb42-76" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb42-77"><a href="#cb42-77" aria-hidden="true" tabindex="-1"></a>**Example questions:** </span>
<span id="cb42-78"><a href="#cb42-78" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-79"><a href="#cb42-79" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**inference:** </span>
<span id="cb42-80"><a href="#cb42-80" aria-hidden="true" tabindex="-1"></a>does the height of plants increase with increasing temperatures?</span>
<span id="cb42-81"><a href="#cb42-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-82"><a href="#cb42-82" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**prediction:** </span>
<span id="cb42-83"><a href="#cb42-83" aria-hidden="true" tabindex="-1"></a>how tall will a plant be if mean temperatures increase by 2<span class="dv">&amp;deg;</span>C?</span>
<span id="cb42-84"><a href="#cb42-84" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-85"><a href="#cb42-85" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-86"><a href="#cb42-86" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-87"><a href="#cb42-87" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-plant-temp, echo=FALSE, eval=TRUE, fig.cap="Panel A shows an illustration of inferring the effect of temperature on plant height. Panel B shows an illustration of the prediction of a plant height under a 2&amp;deg;C increase in temperature. Created by Emily G. Simmonds", fig.height=150}</span></span>
<span id="cb42-88"><a href="#cb42-88" aria-hidden="true" tabindex="-1"></a><span class="fu">include_graphics</span>(<span class="st">"./Figures/plant_height_temp.png"</span>)</span>
<span id="cb42-89"><a href="#cb42-89" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-90"><a href="#cb42-90" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-91"><a href="#cb42-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-92"><a href="#cb42-92" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-93"><a href="#cb42-93" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb42-94"><a href="#cb42-94" aria-hidden="true" tabindex="-1"></a>In simple terms, we fit a straight line to:</span>
<span id="cb42-95"><a href="#cb42-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-96"><a href="#cb42-96" aria-hidden="true" tabindex="-1"></a>1) estimate a relationship between $X$ and $Y$</span>
<span id="cb42-97"><a href="#cb42-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-98"><a href="#cb42-98" aria-hidden="true" tabindex="-1"></a>2) predict change in $Y$ from change in $X$. </span>
<span id="cb42-99"><a href="#cb42-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-100"><a href="#cb42-100" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-101"><a href="#cb42-101" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb42-102"><a href="#cb42-102" aria-hidden="true" tabindex="-1"></a>Linear regression assumes a causal relationship between $X$ and $Y$, </span>
<span id="cb42-103"><a href="#cb42-103" aria-hidden="true" tabindex="-1"></a>i.e. it assumes that $X$ influences $Y$, but not vice versa. </span>
<span id="cb42-104"><a href="#cb42-104" aria-hidden="true" tabindex="-1"></a>It is important to understand that a regression only “quantifies” the pattern between $X$ and $Y$, </span>
<span id="cb42-105"><a href="#cb42-105" aria-hidden="true" tabindex="-1"></a>but does not actually test for a causal relationship. </span>
<span id="cb42-106"><a href="#cb42-106" aria-hidden="true" tabindex="-1"></a>To test if $X$ causes an effect on $Y$, </span>
<span id="cb42-107"><a href="#cb42-107" aria-hidden="true" tabindex="-1"></a>you need to conduct a scientific experiment. </span>
<span id="cb42-108"><a href="#cb42-108" aria-hidden="true" tabindex="-1"></a>A linear relationship between two variables does not necessarily mean that $X$ has a causal influence on $Y$. </span>
<span id="cb42-109"><a href="#cb42-109" aria-hidden="true" tabindex="-1"></a>For example, </span>
<span id="cb42-110"><a href="#cb42-110" aria-hidden="true" tabindex="-1"></a>the number of PhDs awarded in math has nothing to do with the amount of Uranium stored in the USA.</span>
<span id="cb42-111"><a href="#cb42-111" aria-hidden="true" tabindex="-1"></a>However, when plotting the two variables against each other, </span>
<span id="cb42-112"><a href="#cb42-112" aria-hidden="true" tabindex="-1"></a>one could assume a perfect relationship (see @fig-spurious)). </span>
<span id="cb42-113"><a href="#cb42-113" aria-hidden="true" tabindex="-1"></a>Therefore, before statistically analyzing data it is essential to make sure there is a biological explanation or assumption for a relationship between $X$ and $Y$. </span>
<span id="cb42-114"><a href="#cb42-114" aria-hidden="true" tabindex="-1"></a>For more examples of wrong assumptions of causality <span class="co">[</span><span class="ot">click here</span><span class="co">](https://www.tylervigen.com/spurious-correlations)</span>.</span>
<span id="cb42-115"><a href="#cb42-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-116"><a href="#cb42-116" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-117"><a href="#cb42-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-118"><a href="#cb42-118" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-uranium-plot, include=TRUE, echo=FALSE, results='hide'}</span></span>
<span id="cb42-119"><a href="#cb42-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-120"><a href="#cb42-120" aria-hidden="true" tabindex="-1"></a>uranium_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(Spurious, <span class="fu">aes</span>(<span class="at">y=</span>uranium_us, <span class="at">x=</span>maths_phd))<span class="sc">+</span></span>
<span id="cb42-121"><a href="#cb42-121" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb42-122"><a href="#cb42-122" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">"lm"</span>)<span class="sc">+</span></span>
<span id="cb42-123"><a href="#cb42-123" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y=</span><span class="st">"Uranium stored in US (million kg)"</span>, </span>
<span id="cb42-124"><a href="#cb42-124" aria-hidden="true" tabindex="-1"></a>  <span class="at">x=</span><span class="st">"Number maths PhDs awarded"</span>,</span>
<span id="cb42-125"><a href="#cb42-125" aria-hidden="true" tabindex="-1"></a>  <span class="at">title=</span><span class="st">"What NOT to do:</span><span class="sc">\n</span><span class="st"> An example of a spurious correlation"</span>)</span>
<span id="cb42-126"><a href="#cb42-126" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-127"><a href="#cb42-127" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-128"><a href="#cb42-128" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-129"><a href="#cb42-129" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-130"><a href="#cb42-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-133"><a href="#cb42-133" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-134"><a href="#cb42-134" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-spurious</span></span>
<span id="cb42-135"><a href="#cb42-135" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: true</span></span>
<span id="cb42-136"><a href="#cb42-136" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-137"><a href="#cb42-137" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Example of a spurious correlation (one that does not make sense causally). Scatterplot of number of maths PhDs awarded in a year against the amount of uranium stored in US power plants annually. Smooth line indicates a regression line for this data with the 95% confidence interval as the shaded area"</span></span>
<span id="cb42-138"><a href="#cb42-138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-139"><a href="#cb42-139" aria-hidden="true" tabindex="-1"></a>uranium_plot</span>
<span id="cb42-140"><a href="#cb42-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-141"><a href="#cb42-141" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-142"><a href="#cb42-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-143"><a href="#cb42-143" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-144"><a href="#cb42-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-145"><a href="#cb42-145" aria-hidden="true" tabindex="-1"></a><span class="fu">## &lt;i class="far fa-question-circle"&gt;&lt;/i&gt; Which questions? </span></span>
<span id="cb42-146"><a href="#cb42-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-147"><a href="#cb42-147" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-148"><a href="#cb42-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-149"><a href="#cb42-149" aria-hidden="true" tabindex="-1"></a>Example questions you can answer with a simple linear regression:</span>
<span id="cb42-150"><a href="#cb42-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-151"><a href="#cb42-151" aria-hidden="true" tabindex="-1"></a>Inference</span>
<span id="cb42-152"><a href="#cb42-152" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb42-153"><a href="#cb42-153" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>How does mean annual temperature change with time?</span>
<span id="cb42-154"><a href="#cb42-154" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>How does the time of breeding for a bird change with mean spring temperature?</span>
<span id="cb42-155"><a href="#cb42-155" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>How does relative plant biomass change with mean light intensity?</span>
<span id="cb42-156"><a href="#cb42-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-157"><a href="#cb42-157" aria-hidden="true" tabindex="-1"></a>Prediction</span>
<span id="cb42-158"><a href="#cb42-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-159"><a href="#cb42-159" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>What will the mean summer temperature be in 2100?</span>
<span id="cb42-160"><a href="#cb42-160" aria-hidden="true" tabindex="-1"></a><span class="ss"> * </span>How heavy will a sheep be if it is 100cm long?</span>
<span id="cb42-161"><a href="#cb42-161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-162"><a href="#cb42-162" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-163"><a href="#cb42-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-164"><a href="#cb42-164" aria-hidden="true" tabindex="-1"></a><span class="fu">## &lt;i class="fas fa-table"&gt;&lt;/i&gt; Type of data {.tabset .tabset-fade}</span></span>
<span id="cb42-165"><a href="#cb42-165" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-166"><a href="#cb42-166" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-167"><a href="#cb42-167" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-168"><a href="#cb42-168" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theory</span></span>
<span id="cb42-169"><a href="#cb42-169" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-170"><a href="#cb42-170" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-171"><a href="#cb42-171" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-172"><a href="#cb42-172" aria-hidden="true" tabindex="-1"></a>A linear regression is used when you have continuous numeric response variable </span>
<span id="cb42-173"><a href="#cb42-173" aria-hidden="true" tabindex="-1"></a>and a continuous numeric explanatory variables. </span>
<span id="cb42-174"><a href="#cb42-174" aria-hidden="true" tabindex="-1"></a>A **simple linear regression** has only one explanatory variable, </span>
<span id="cb42-175"><a href="#cb42-175" aria-hidden="true" tabindex="-1"></a>a **multiple linear regression** has more than one. </span>
<span id="cb42-176"><a href="#cb42-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-177"><a href="#cb42-177" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-178"><a href="#cb42-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-179"><a href="#cb42-179" aria-hidden="true" tabindex="-1"></a>**Examples of continuous numeric variables**:</span>
<span id="cb42-180"><a href="#cb42-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-181"><a href="#cb42-181" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Mean annual temperature (<span class="dv">&amp;deg;</span>C)</span>
<span id="cb42-182"><a href="#cb42-182" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Total annual precipitation (mm)</span>
<span id="cb42-183"><a href="#cb42-183" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Distance (km)</span>
<span id="cb42-184"><a href="#cb42-184" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Height (cm)</span>
<span id="cb42-185"><a href="#cb42-185" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Weight (kg)</span>
<span id="cb42-186"><a href="#cb42-186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-187"><a href="#cb42-187" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-188"><a href="#cb42-188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-189"><a href="#cb42-189" aria-hidden="true" tabindex="-1"></a>**Always remember to check that the way your variables are classified in R </span>
<span id="cb42-190"><a href="#cb42-190" aria-hidden="true" tabindex="-1"></a>is the same as the format you expect.** </span>
<span id="cb42-191"><a href="#cb42-191" aria-hidden="true" tabindex="-1"></a>It is a common mistake for a variable that should be numeric</span>
<span id="cb42-192"><a href="#cb42-192" aria-hidden="true" tabindex="-1"></a>to be classified as a Factor, or a Factor as a character string etc.</span>
<span id="cb42-193"><a href="#cb42-193" aria-hidden="true" tabindex="-1"></a>(This should not be a problem in the latest version of R, so</span>
<span id="cb42-194"><a href="#cb42-194" aria-hidden="true" tabindex="-1"></a>might become a historical problem.)</span>
<span id="cb42-195"><a href="#cb42-195" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-196"><a href="#cb42-196" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-197"><a href="#cb42-197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-198"><a href="#cb42-198" aria-hidden="true" tabindex="-1"></a><span class="fu">### Worked example</span></span>
<span id="cb42-199"><a href="#cb42-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-200"><a href="#cb42-200" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-201"><a href="#cb42-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-202"><a href="#cb42-202" aria-hidden="true" tabindex="-1"></a>For this worked example we will be using some data on dive depths of</span>
<span id="cb42-203"><a href="#cb42-203" aria-hidden="true" tabindex="-1"></a>marine mammals. </span>
<span id="cb42-204"><a href="#cb42-204" aria-hidden="true" tabindex="-1"></a>We will be answering the question:</span>
<span id="cb42-205"><a href="#cb42-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-206"><a href="#cb42-206" aria-hidden="true" tabindex="-1"></a>**Does body size (kg) influence maximum dive depth (m) in marine mammals?**</span>
<span id="cb42-207"><a href="#cb42-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-208"><a href="#cb42-208" aria-hidden="true" tabindex="-1"></a>We might expect that differences in foraging strategies, physiological processes, </span>
<span id="cb42-209"><a href="#cb42-209" aria-hidden="true" tabindex="-1"></a>metabolism, and power of the marine mammals would impact how deep the animals </span>
<span id="cb42-210"><a href="#cb42-210" aria-hidden="true" tabindex="-1"></a>can dive. </span>
<span id="cb42-211"><a href="#cb42-211" aria-hidden="true" tabindex="-1"></a>All of these variables correlate with body size. </span>
<span id="cb42-212"><a href="#cb42-212" aria-hidden="true" tabindex="-1"></a>Therefore, it could be expected that larger species can dive deeper as relative</span>
<span id="cb42-213"><a href="#cb42-213" aria-hidden="true" tabindex="-1"></a>movement compared to body size is lower. </span>
<span id="cb42-214"><a href="#cb42-214" aria-hidden="true" tabindex="-1"></a>Or perhaps it is less energetically demanding</span>
<span id="cb42-215"><a href="#cb42-215" aria-hidden="true" tabindex="-1"></a>for smaller species to dive deeper. </span>
<span id="cb42-216"><a href="#cb42-216" aria-hidden="true" tabindex="-1"></a>The direction and strength of the influence of body size on dive depth can be </span>
<span id="cb42-217"><a href="#cb42-217" aria-hidden="true" tabindex="-1"></a>quantified using a linear regression. </span>
<span id="cb42-218"><a href="#cb42-218" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-219"><a href="#cb42-219" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-mammal, echo=FALSE, eval=TRUE, fig.cap="Illustration of marine mammals by Emily G. Simmonds", fig.height=150}</span></span>
<span id="cb42-220"><a href="#cb42-220" aria-hidden="true" tabindex="-1"></a><span class="fu">include_graphics</span>(<span class="st">"./Figures/marine_mammals.png"</span>)</span>
<span id="cb42-221"><a href="#cb42-221" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-222"><a href="#cb42-222" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-223"><a href="#cb42-223" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-224"><a href="#cb42-224" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-225"><a href="#cb42-225" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Introduction to the data</span></span>
<span id="cb42-226"><a href="#cb42-226" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-227"><a href="#cb42-227" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-228"><a href="#cb42-228" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-229"><a href="#cb42-229" aria-hidden="true" tabindex="-1"></a>These data have four variables; species, maximum recorded dive depth in metres (m), </span>
<span id="cb42-230"><a href="#cb42-230" aria-hidden="true" tabindex="-1"></a>body weight in kilograms (kg), and taxonomic group. </span>
<span id="cb42-231"><a href="#cb42-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-232"><a href="#cb42-232" aria-hidden="true" tabindex="-1"></a>The data were collected from a variety of sources and cover several taxonomic </span>
<span id="cb42-233"><a href="#cb42-233" aria-hidden="true" tabindex="-1"></a>groups (including</span>
<span id="cb42-234"><a href="#cb42-234" aria-hidden="true" tabindex="-1"></a>polar bear, sea otters, baleen whales, toothed whales, seals, and sea lions). </span>
<span id="cb42-235"><a href="#cb42-235" aria-hidden="true" tabindex="-1"></a>You can find the dataset <span class="co">[</span><span class="ot">here</span><span class="co">](https://github.com/emilygsimmonds/biostats/blob/Regression/StatisticsInR/Files/dive_depths.csv)</span> if you want to try the analysis for yourself. </span>
<span id="cb42-236"><a href="#cb42-236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-237"><a href="#cb42-237" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-238"><a href="#cb42-238" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-239"><a href="#cb42-239" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;&lt;summary&gt;</span> Full list of data sources<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb42-240"><a href="#cb42-240" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-241"><a href="#cb42-241" aria-hidden="true" tabindex="-1"></a>Sources: </span>
<span id="cb42-242"><a href="#cb42-242" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-243"><a href="#cb42-243" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">British Broadcasting Coorporation (BBC)</span><span class="co">](http://www.bbc.co.uk/earth/story/20150115-extreme-divers-defy-explanation)</span></span>
<span id="cb42-244"><a href="#cb42-244" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>[Croll et al 2001,</span>
<span id="cb42-245"><a href="#cb42-245" aria-hidden="true" tabindex="-1"></a>Comparative Biochemistry and Physiology Part A: Molecular &amp; Integrative Physiology,</span>
<span id="cb42-246"><a href="#cb42-246" aria-hidden="true" tabindex="-1"></a>Volume 129, Issue 4,</span>
<span id="cb42-247"><a href="#cb42-247" aria-hidden="true" tabindex="-1"></a>Pages 797-809](https://www.researchgate.net/figure/Maximum-depth-and-duration-of-dive-tagged-blue-whales_tbl1_11900120)</span>
<span id="cb42-248"><a href="#cb42-248" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Baird et al 2000, Report prepared under Contract #40ABNC050729 from the Hawaiian Islands Humpback Whale National Marine Sanctuary</span><span class="co">](http://whitelab.biology.dal.ca/rwb/humpback.htm)</span></span>
<span id="cb42-249"><a href="#cb42-249" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Bannister 2008, Great Whales, CSIRO Publishing</span><span class="co">](https://books.google.co.uk/books?id=-dXAcVFhkuQC&amp;pg=PA33&amp;lpg=PA33&amp;dq=max+recorded+humpback+dive&amp;source=bl&amp;ots=mJvyxA4e3S&amp;sig=ACfU3U3ZFOnypZ0Rvej3VpK11Fpci-UfAg&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiHgq3enNbpAhXFSxUIHfCTD9MQ6AEwDnoECAkQAQ#v=onepage&amp;q=max%20recorded%20humpback%20dive&amp;f=false)</span></span>
<span id="cb42-250"><a href="#cb42-250" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Norwegian Polar Institute</span><span class="co">](https://www.npolar.no/en/species/walrus/)</span></span>
<span id="cb42-251"><a href="#cb42-251" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Eguchi and Harvey 2005, Marine Mammal Science, 21: 283-295</span><span class="co">](https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1748-7692.2005.tb01228.x)</span></span>
<span id="cb42-252"><a href="#cb42-252" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Lloyd Spencer Davis, Te Ara - the Encyclopedia of New Zealand, (accessed 30 September 2020)</span><span class="co">](https://teara.govt.nz/en/diagram/6175/ocean-dive-depths)</span></span>
<span id="cb42-253"><a href="#cb42-253" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Gales et al 2013, Unpubished Report to the IWC</span><span class="co">](https://www.researchgate.net/publication/260209989_Advances_in_non-lethal_research_on_Antarctic_minke_whales_biotelemetry_photo-identification_and_biopsy_sampling)</span></span>
<span id="cb42-254"><a href="#cb42-254" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Dolphin Communication Project</span><span class="co">](https://www.dolphincommunicationproject.org/index.php/the-latest-buzz/field-reports/bahamas-3/bahamas-2000/item/93037-how-deep-can-dolphins-dive)</span></span>
<span id="cb42-255"><a href="#cb42-255" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Encyclopedia of Marine Mammals edited by Würsig, Perrin, Thewissen, 2002, Elsevier Ltd</span><span class="co">](https://books.google.no/books?id=2rkHQpToi9sC&amp;pg=PA325&amp;lpg=PA325&amp;dq=max+recorded+common+dolphin+dive&amp;source=bl&amp;ots=hFnuNx8dwr&amp;sig=ACfU3U0Og9623-SPJkxROGsodqDcuEeDNQ&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwizoOnNodbpAhWyxaYKHW9hAHMQ6AEwDHoECAkQAQ#v=onepage&amp;q=max%20recorded%20common%20dolphin%20dive&amp;f=false)</span></span>
<span id="cb42-256"><a href="#cb42-256" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Polar Bear Science</span><span class="co">](https://polarbearscience.com/2018/10/15/scientific-study-finds-polar-bears-excel-at-diving-contradicting-previous-expert-opinion/)</span></span>
<span id="cb42-257"><a href="#cb42-257" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Marine Biology, compiled by Steele, edited by Steele, Thorpe, Turekian,  2009, Elsevier Ltd</span><span class="co">](https://books.google.no/books?id=kkRKJCofvXMC&amp;pg=PA445&amp;lpg=PA445&amp;dq=max+recorded+sea+otter+dive&amp;source=bl&amp;ots=HX_ypXO6zq&amp;sig=ACfU3U1ugMJRJtd21NLfrpDVirSmCx15kA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjo29WxotbpAhUGy6YKHQzmDHMQ6AEwAHoECAsQAQ#v=onepage&amp;q=max%20recorded%20sea%20otter%20dive&amp;f=false)</span></span>
<span id="cb42-258"><a href="#cb42-258" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">North Atlantic Marine Mammal Commission</span><span class="co">](https://nammco.no/marinemammals/)</span></span>
<span id="cb42-259"><a href="#cb42-259" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">National Oceanic and Atmospheric Administration, USA</span><span class="co">](https://www.fisheries.noaa.gov/species/)</span></span>
<span id="cb42-260"><a href="#cb42-260" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="co">[</span><span class="ot">Department of Conservation, New Zealand</span><span class="co">](https://www.doc.govt.nz/nature/native-animals/marine-mammals/)</span></span>
<span id="cb42-261"><a href="#cb42-261" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb42-262"><a href="#cb42-262" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-263"><a href="#cb42-263" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-264"><a href="#cb42-264" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-265"><a href="#cb42-265" aria-hidden="true" tabindex="-1"></a>First, we want to import the data and have a closer look by making a plot.</span>
<span id="cb42-266"><a href="#cb42-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-267"><a href="#cb42-267" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-268"><a href="#cb42-268" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-269"><a href="#cb42-269" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-dive-data-fig, include=TRUE, echo=TRUE}</span></span>
<span id="cb42-270"><a href="#cb42-270" aria-hidden="true" tabindex="-1"></a>dive_data</span>
<span id="cb42-271"><a href="#cb42-271" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-272"><a href="#cb42-272" aria-hidden="true" tabindex="-1"></a>dive_fig <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dive_data, <span class="fu">aes</span>(<span class="at">x=</span>body_size_kg, <span class="at">y=</span>max_depth, <span class="at">color=</span>group))<span class="sc">+</span></span>
<span id="cb42-273"><a href="#cb42-273" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span>
<span id="cb42-274"><a href="#cb42-274" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-275"><a href="#cb42-275" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-276"><a href="#cb42-276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-277"><a href="#cb42-277" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-dive, include=TRUE, echo=FALSE, fig.cap="Scatterplot of body size against maximum dive depth for marine mammals. Colours indicate taxonomic group"}</span></span>
<span id="cb42-278"><a href="#cb42-278" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-279"><a href="#cb42-279" aria-hidden="true" tabindex="-1"></a>dive_fig</span>
<span id="cb42-280"><a href="#cb42-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-281"><a href="#cb42-281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-282"><a href="#cb42-282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-283"><a href="#cb42-283" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-284"><a href="#cb42-284" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-285"><a href="#cb42-285" aria-hidden="true" tabindex="-1"></a>The output shows that two of the variables are factors (species and group), </span>
<span id="cb42-286"><a href="#cb42-286" aria-hidden="true" tabindex="-1"></a>one is continuous numeric (max_depth), and the last one is integer</span>
<span id="cb42-287"><a href="#cb42-287" aria-hidden="true" tabindex="-1"></a>(body_size_kg). </span>
<span id="cb42-288"><a href="#cb42-288" aria-hidden="true" tabindex="-1"></a>We know that body size actually is a continuous variable, </span>
<span id="cb42-289"><a href="#cb42-289" aria-hidden="true" tabindex="-1"></a>scientists probably rounded when they measured this variable, </span>
<span id="cb42-290"><a href="#cb42-290" aria-hidden="true" tabindex="-1"></a>because these are large numbers. </span>
<span id="cb42-291"><a href="#cb42-291" aria-hidden="true" tabindex="-1"></a>We will change this variable to be numeric so it better represents</span>
<span id="cb42-292"><a href="#cb42-292" aria-hidden="true" tabindex="-1"></a>the characteristics of the data.</span>
<span id="cb42-293"><a href="#cb42-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-294"><a href="#cb42-294" aria-hidden="true" tabindex="-1"></a><span class="in">```{r format-divedata, include=TRUE, echo=TRUE}</span></span>
<span id="cb42-295"><a href="#cb42-295" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-296"><a href="#cb42-296" aria-hidden="true" tabindex="-1"></a><span class="co"># format the divedata</span></span>
<span id="cb42-297"><a href="#cb42-297" aria-hidden="true" tabindex="-1"></a>dive_data <span class="ot">&lt;-</span> <span class="fu">mutate</span>(dive_data, <span class="at">body_size_kg =</span> <span class="fu">as.numeric</span>(body_size_kg))</span>
<span id="cb42-298"><a href="#cb42-298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-299"><a href="#cb42-299" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-300"><a href="#cb42-300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-301"><a href="#cb42-301" aria-hidden="true" tabindex="-1"></a>Remember, we are interested in **whether body size (kg) influences maximum </span>
<span id="cb42-302"><a href="#cb42-302" aria-hidden="true" tabindex="-1"></a>dive depth (m) in marine mammals.** To answer this question we will need the variables:</span>
<span id="cb42-303"><a href="#cb42-303" aria-hidden="true" tabindex="-1"></a><span class="in">`body_size_kg`</span> and <span class="in">`max_depth`</span>. </span>
<span id="cb42-304"><a href="#cb42-304" aria-hidden="true" tabindex="-1"></a>We will not consider <span class="in">`species`</span> or <span class="in">`group`</span> at the moment, </span>
<span id="cb42-305"><a href="#cb42-305" aria-hidden="true" tabindex="-1"></a>but we might need them later. </span>
<span id="cb42-306"><a href="#cb42-306" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-307"><a href="#cb42-307" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-308"><a href="#cb42-308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-309"><a href="#cb42-309" aria-hidden="true" tabindex="-1"></a>Now we have familiarized ourselves with the data, </span>
<span id="cb42-310"><a href="#cb42-310" aria-hidden="true" tabindex="-1"></a>we know our research question, and we have identified which variables we need for the analysis. </span>
<span id="cb42-311"><a href="#cb42-311" aria-hidden="true" tabindex="-1"></a>**We are ready to perform an analysis.** </span>
<span id="cb42-312"><a href="#cb42-312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-313"><a href="#cb42-313" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-314"><a href="#cb42-314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-315"><a href="#cb42-315" aria-hidden="true" tabindex="-1"></a><span class="fu">## &lt;i class="fas fa-project-diagram"&gt;&lt;/i&gt; Model details {.tabset .tabset-fade}</span></span>
<span id="cb42-316"><a href="#cb42-316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-317"><a href="#cb42-317" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-318"><a href="#cb42-318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-319"><a href="#cb42-319" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theory</span></span>
<span id="cb42-320"><a href="#cb42-320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-321"><a href="#cb42-321" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-322"><a href="#cb42-322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-323"><a href="#cb42-323" aria-hidden="true" tabindex="-1"></a>When we create a model we aim to represent mathematically the process that generated the data we observed. </span>
<span id="cb42-324"><a href="#cb42-324" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-325"><a href="#cb42-325" aria-hidden="true" tabindex="-1"></a>When we use a linear regression model (this is also true for other types of linear models), we make an assumption that there is a linear relationship between the explanatory and response variables. </span>
<span id="cb42-326"><a href="#cb42-326" aria-hidden="true" tabindex="-1"></a>Mathematically, we say that we can capture the data generation process with a straight line and some error.</span>
<span id="cb42-327"><a href="#cb42-327" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb42-328"><a href="#cb42-328" aria-hidden="true" tabindex="-1"></a>The line component of the linear regression is defined by two parameters: </span>
<span id="cb42-329"><a href="#cb42-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-330"><a href="#cb42-330" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:orange"</span><span class="kw">&gt;</span>**$\alpha$**<span class="kw">&lt;/span&gt;</span> (Greek letter alpha) = the intercept, </span>
<span id="cb42-331"><a href="#cb42-331" aria-hidden="true" tabindex="-1"></a>defining where the regression line crosses the y-axis. </span>
<span id="cb42-332"><a href="#cb42-332" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>**$\beta$**<span class="kw">&lt;/span&gt;</span> (Greek letter beta) = the slope (steepness/gradient), </span>
<span id="cb42-333"><a href="#cb42-333" aria-hidden="true" tabindex="-1"></a>which defines the steepness of the regression line, </span>
<span id="cb42-334"><a href="#cb42-334" aria-hidden="true" tabindex="-1"></a>i.e. how much $Y$ changes for every increase of 1 unit of $X$. </span>
<span id="cb42-335"><a href="#cb42-335" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-336"><a href="#cb42-336" aria-hidden="true" tabindex="-1"></a>We can alter the position and slope of the line by these two parameters. </span>
<span id="cb42-337"><a href="#cb42-337" aria-hidden="true" tabindex="-1"></a>The final part of the model is <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:red"</span><span class="kw">&gt;</span>**$\varepsilon$**<span class="kw">&lt;/span&gt;</span> </span>
<span id="cb42-338"><a href="#cb42-338" aria-hidden="true" tabindex="-1"></a>(Greek letter epsilon), </span>
<span id="cb42-339"><a href="#cb42-339" aria-hidden="true" tabindex="-1"></a>which is the error around the regression line. </span>
<span id="cb42-340"><a href="#cb42-340" aria-hidden="true" tabindex="-1"></a>This error is estimated with the parameter **$\sigma^{2}$** </span>
<span id="cb42-341"><a href="#cb42-341" aria-hidden="true" tabindex="-1"></a>(Greek letter sigma – squared) that is the variance of the error. </span>
<span id="cb42-342"><a href="#cb42-342" aria-hidden="true" tabindex="-1"></a>(Greek letters are used to refer to each part of the model using equations). </span>
<span id="cb42-343"><a href="#cb42-343" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-344"><a href="#cb42-344" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-345"><a href="#cb42-345" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-346"><a href="#cb42-346" aria-hidden="true" tabindex="-1"></a>We can write a linear regression model as and equation as a function of $Y$:</span>
<span id="cb42-347"><a href="#cb42-347" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-348"><a href="#cb42-348" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-349"><a href="#cb42-349" aria-hidden="true" tabindex="-1"></a>Y_i = \color{orange}\alpha + \color{blue}\beta X_i + \color{red}\varepsilon_i</span>
<span id="cb42-350"><a href="#cb42-350" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-351"><a href="#cb42-351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-352"><a href="#cb42-352" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Assumptions</span></span>
<span id="cb42-353"><a href="#cb42-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-354"><a href="#cb42-354" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-355"><a href="#cb42-355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-356"><a href="#cb42-356" aria-hidden="true" tabindex="-1"></a>There are several assumptions that we make when using a linear regression model:</span>
<span id="cb42-357"><a href="#cb42-357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-358"><a href="#cb42-358" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The relationship between X and Y is linear</span>
<span id="cb42-359"><a href="#cb42-359" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Residuals (this is another word for error) are normally distributed </span>
<span id="cb42-360"><a href="#cb42-360" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The residuals have a mean of 0</span>
<span id="cb42-361"><a href="#cb42-361" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The variance of the residuals is equal for all fitted values (homoscedasticity)</span>
<span id="cb42-362"><a href="#cb42-362" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>There are no outliers</span>
<span id="cb42-363"><a href="#cb42-363" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Each value of Y is independent</span>
<span id="cb42-364"><a href="#cb42-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-365"><a href="#cb42-365" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-366"><a href="#cb42-366" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-367"><a href="#cb42-367" aria-hidden="true" tabindex="-1"></a>All of these assumptions should be met for the model to work properly and </span>
<span id="cb42-368"><a href="#cb42-368" aria-hidden="true" tabindex="-1"></a>they ALWAYS need to be checked. </span>
<span id="cb42-369"><a href="#cb42-369" aria-hidden="true" tabindex="-1"></a>We will check five of them after we have fit the model (see below). </span>
<span id="cb42-370"><a href="#cb42-370" aria-hidden="true" tabindex="-1"></a>The last assumption, independence of $Y$ needs to be assured before or </span>
<span id="cb42-371"><a href="#cb42-371" aria-hidden="true" tabindex="-1"></a>during data collection. </span>
<span id="cb42-372"><a href="#cb42-372" aria-hidden="true" tabindex="-1"></a>For example, if data were collected on leaf length, </span>
<span id="cb42-373"><a href="#cb42-373" aria-hidden="true" tabindex="-1"></a>20 leaves each from five trees, these would not be independent. </span>
<span id="cb42-374"><a href="#cb42-374" aria-hidden="true" tabindex="-1"></a>It would be better to collect one leaf each from 100 trees. </span>
<span id="cb42-375"><a href="#cb42-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-376"><a href="#cb42-376" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-377"><a href="#cb42-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-378"><a href="#cb42-378" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Writing the model in &lt;i class="fab fa-r-project"&gt;&lt;/i&gt;</span></span>
<span id="cb42-379"><a href="#cb42-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-380"><a href="#cb42-380" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-381"><a href="#cb42-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-382"><a href="#cb42-382" aria-hidden="true" tabindex="-1"></a>To fit the simple linear regression in <span class="kw">&lt;i</span> <span class="er">class</span><span class="ot">=</span><span class="st">"fab fa-r-project"</span><span class="kw">&gt;&lt;/i&gt;</span> </span>
<span id="cb42-383"><a href="#cb42-383" aria-hidden="true" tabindex="-1"></a>we will use the <span class="in">`lm()`</span> function.</span>
<span id="cb42-384"><a href="#cb42-384" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-385"><a href="#cb42-385" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-386"><a href="#cb42-386" aria-hidden="true" tabindex="-1"></a><span class="in">`lm()`</span> stands for linear model (should seem familiar) and it takes several arguments:</span>
<span id="cb42-387"><a href="#cb42-387" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-388"><a href="#cb42-388" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>formula in form: <span class="in">`y ~ x`</span></span>
<span id="cb42-389"><a href="#cb42-389" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>data: your data object</span>
<span id="cb42-390"><a href="#cb42-390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-391"><a href="#cb42-391" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-392"><a href="#cb42-392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-393"><a href="#cb42-393" aria-hidden="true" tabindex="-1"></a>The function will fit the regression model using maximum likelihood estimation </span>
<span id="cb42-394"><a href="#cb42-394" aria-hidden="true" tabindex="-1"></a>and give us</span>
<span id="cb42-395"><a href="#cb42-395" aria-hidden="true" tabindex="-1"></a>the maximum likelihood estimates of </span>
<span id="cb42-396"><a href="#cb42-396" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:orange"</span><span class="kw">&gt;</span>$\alpha$<span class="kw">&lt;/span&gt;</span> and </span>
<span id="cb42-397"><a href="#cb42-397" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>$\beta$<span class="kw">&lt;/span&gt;</span> as an output. </span>
<span id="cb42-398"><a href="#cb42-398" aria-hidden="true" tabindex="-1"></a>It does also estimate $\sigma^{2}$ of the error, but it does not report this.</span>
<span id="cb42-399"><a href="#cb42-399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-400"><a href="#cb42-400" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-401"><a href="#cb42-401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-402"><a href="#cb42-402" aria-hidden="true" tabindex="-1"></a>To use the <span class="in">`lm()`</span> function you first need to think about the formula argument, </span>
<span id="cb42-403"><a href="#cb42-403" aria-hidden="true" tabindex="-1"></a>the <span class="in">`y ~ x`</span> part. </span>
<span id="cb42-404"><a href="#cb42-404" aria-hidden="true" tabindex="-1"></a>The same way as in the equation above, the letter $Y$ always </span>
<span id="cb42-405"><a href="#cb42-405" aria-hidden="true" tabindex="-1"></a>corresponds to the response variable </span>
<span id="cb42-406"><a href="#cb42-406" aria-hidden="true" tabindex="-1"></a>(the thing you are trying to explain) and </span>
<span id="cb42-407"><a href="#cb42-407" aria-hidden="true" tabindex="-1"></a>$X$ to an explanatory variable (the thing you assume affects the response). </span>
<span id="cb42-408"><a href="#cb42-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-409"><a href="#cb42-409" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-410"><a href="#cb42-410" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-411"><a href="#cb42-411" aria-hidden="true" tabindex="-1"></a>**Does temperature influence wing length of butterflies?**</span>
<span id="cb42-412"><a href="#cb42-412" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-413"><a href="#cb42-413" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-414"><a href="#cb42-414" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-415"><a href="#cb42-415" aria-hidden="true" tabindex="-1"></a>The explanatory variable ($X$) = temperature, it is the variable that</span>
<span id="cb42-416"><a href="#cb42-416" aria-hidden="true" tabindex="-1"></a>does the influencing.</span>
<span id="cb42-417"><a href="#cb42-417" aria-hidden="true" tabindex="-1"></a>The response variable ($Y$) = wing length, it is the result. </span>
<span id="cb42-418"><a href="#cb42-418" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-419"><a href="#cb42-419" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-420"><a href="#cb42-420" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-421"><a href="#cb42-421" aria-hidden="true" tabindex="-1"></a>You can then plug these variables into the <span class="in">`lm()`</span> function in the below format </span>
<span id="cb42-422"><a href="#cb42-422" aria-hidden="true" tabindex="-1"></a>using the column names in place of <span class="in">`y`</span> and <span class="in">`x`</span> and </span>
<span id="cb42-423"><a href="#cb42-423" aria-hidden="true" tabindex="-1"></a>including your data frame name as the data argument. </span>
<span id="cb42-424"><a href="#cb42-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-425"><a href="#cb42-425" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-426"><a href="#cb42-426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-427"><a href="#cb42-427" aria-hidden="true" tabindex="-1"></a><span class="in">```{r model-example, include=TRUE, echo=TRUE, eval=TRUE}</span></span>
<span id="cb42-428"><a href="#cb42-428" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-429"><a href="#cb42-429" aria-hidden="true" tabindex="-1"></a>model_object <span class="ot">&lt;-</span> <span class="fu">lm</span>(response <span class="sc">~</span> explanatory, <span class="at">data =</span> your_data)</span>
<span id="cb42-430"><a href="#cb42-430" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-431"><a href="#cb42-431" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-432"><a href="#cb42-432" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-433"><a href="#cb42-433" aria-hidden="true" tabindex="-1"></a>Running the <span class="in">`lm()`</span> as illustrated above runs the linear regression model </span>
<span id="cb42-434"><a href="#cb42-434" aria-hidden="true" tabindex="-1"></a>and saves the output as a 'model_object'.</span>
<span id="cb42-435"><a href="#cb42-435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-436"><a href="#cb42-436" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;&lt;summary&gt;</span>I saw an <span class="in">`lm()`</span> written differently, what's that about?<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb42-437"><a href="#cb42-437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-438"><a href="#cb42-438" aria-hidden="true" tabindex="-1"></a>You can use the <span class="in">`lm()`</span> function without the data argument. </span>
<span id="cb42-439"><a href="#cb42-439" aria-hidden="true" tabindex="-1"></a>If you do this, you</span>
<span id="cb42-440"><a href="#cb42-440" aria-hidden="true" tabindex="-1"></a>need to refer to your ($X$) and ($Y$) variables in the <span class="in">`y ~ x`</span> formula using a <span class="in">`$`</span></span>
<span id="cb42-441"><a href="#cb42-441" aria-hidden="true" tabindex="-1"></a>between the data name and the column name. </span>
<span id="cb42-442"><a href="#cb42-442" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-443"><a href="#cb42-443" aria-hidden="true" tabindex="-1"></a>**We do not recommend using this approach.** </span>
<span id="cb42-444"><a href="#cb42-444" aria-hidden="true" tabindex="-1"></a>There are several reasons for this</span>
<span id="cb42-445"><a href="#cb42-445" aria-hidden="true" tabindex="-1"></a>but a key one is that when using the <span class="in">`$`</span> syntax, R sees the variable name as the</span>
<span id="cb42-446"><a href="#cb42-446" aria-hidden="true" tabindex="-1"></a>whole entry <span class="in">`your_data$explanatory`</span> rather than as the column name <span class="in">`explanatory`</span>. </span>
<span id="cb42-447"><a href="#cb42-447" aria-hidden="true" tabindex="-1"></a>This makes it difficult to use this model for other things e.g. to predict.</span>
<span id="cb42-448"><a href="#cb42-448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-449"><a href="#cb42-449" aria-hidden="true" tabindex="-1"></a><span class="in">```{r alternative-model-fit, include=TRUE, echo=TRUE}</span></span>
<span id="cb42-450"><a href="#cb42-450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-451"><a href="#cb42-451" aria-hidden="true" tabindex="-1"></a>alternative <span class="ot">&lt;-</span> <span class="fu">lm</span>(your_data<span class="sc">$</span>response <span class="sc">~</span> your_data<span class="sc">$</span>explanatory)</span>
<span id="cb42-452"><a href="#cb42-452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-453"><a href="#cb42-453" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-454"><a href="#cb42-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-455"><a href="#cb42-455" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb42-456"><a href="#cb42-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-457"><a href="#cb42-457" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-458"><a href="#cb42-458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-459"><a href="#cb42-459" aria-hidden="true" tabindex="-1"></a>The results of the linear regression can be viewed using the function <span class="in">`coef()`</span>. </span>
<span id="cb42-460"><a href="#cb42-460" aria-hidden="true" tabindex="-1"></a>This takes the output of <span class="in">`lm()`</span>, the model object, </span>
<span id="cb42-461"><a href="#cb42-461" aria-hidden="true" tabindex="-1"></a>as its argument and extracts the maximum</span>
<span id="cb42-462"><a href="#cb42-462" aria-hidden="true" tabindex="-1"></a>likelihood estimates of <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:orange"</span><span class="kw">&gt;</span>$\alpha$<span class="kw">&lt;/span&gt;</span> and </span>
<span id="cb42-463"><a href="#cb42-463" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>$\beta$<span class="kw">&lt;/span&gt;</span>. </span>
<span id="cb42-464"><a href="#cb42-464" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:orange"</span><span class="kw">&gt;</span>$\alpha$<span class="kw">&lt;/span&gt;</span> will always be labelled <span class="in">`(Intercept)`</span> </span>
<span id="cb42-465"><a href="#cb42-465" aria-hidden="true" tabindex="-1"></a>but <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>$\beta$<span class="kw">&lt;/span&gt;</span> will be labelled by the name of the $X$ variable.</span>
<span id="cb42-466"><a href="#cb42-466" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-467"><a href="#cb42-467" aria-hidden="true" tabindex="-1"></a><span class="in">```{r example-coef1, include=TRUE, echo=TRUE}</span></span>
<span id="cb42-468"><a href="#cb42-468" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-469"><a href="#cb42-469" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(model_object)</span>
<span id="cb42-470"><a href="#cb42-470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-471"><a href="#cb42-471" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-472"><a href="#cb42-472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-473"><a href="#cb42-473" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-474"><a href="#cb42-474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-475"><a href="#cb42-475" aria-hidden="true" tabindex="-1"></a><span class="fu">### Worked example </span></span>
<span id="cb42-476"><a href="#cb42-476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-477"><a href="#cb42-477" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-478"><a href="#cb42-478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-479"><a href="#cb42-479" aria-hidden="true" tabindex="-1"></a>This worked example demonstrates how to fit a linear regression model in </span>
<span id="cb42-480"><a href="#cb42-480" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;i</span> <span class="er">class</span><span class="ot">=</span><span class="st">"fab fa-r-project"</span><span class="kw">&gt;&lt;/i&gt;</span> using the <span class="in">`lm()`</span> </span>
<span id="cb42-481"><a href="#cb42-481" aria-hidden="true" tabindex="-1"></a>function for the dive depths example.</span>
<span id="cb42-482"><a href="#cb42-482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-483"><a href="#cb42-483" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-484"><a href="#cb42-484" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-485"><a href="#cb42-485" aria-hidden="true" tabindex="-1"></a>In this example we are asking:</span>
<span id="cb42-486"><a href="#cb42-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-487"><a href="#cb42-487" aria-hidden="true" tabindex="-1"></a>**Does body size influence maximum dive depth in marine mammals?**</span>
<span id="cb42-488"><a href="#cb42-488" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-489"><a href="#cb42-489" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-490"><a href="#cb42-490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-491"><a href="#cb42-491" aria-hidden="true" tabindex="-1"></a>Our question is formulated to suggest a direction of causality, </span>
<span id="cb42-492"><a href="#cb42-492" aria-hidden="true" tabindex="-1"></a>we assume body size has a causal effect on maximum dive depth, </span>
<span id="cb42-493"><a href="#cb42-493" aria-hidden="true" tabindex="-1"></a>therefore maximum depth is our </span>
<span id="cb42-494"><a href="#cb42-494" aria-hidden="true" tabindex="-1"></a>response ($Y$) and body size as our explanatory variable ($X$). </span>
<span id="cb42-495"><a href="#cb42-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-496"><a href="#cb42-496" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-497"><a href="#cb42-497" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-498"><a href="#cb42-498" aria-hidden="true" tabindex="-1"></a>We can put these variables into the <span class="in">`lm()`</span> function in the below format. </span>
<span id="cb42-499"><a href="#cb42-499" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-500"><a href="#cb42-500" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dive-model, include=TRUE, echo=TRUE}</span></span>
<span id="cb42-501"><a href="#cb42-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-502"><a href="#cb42-502" aria-hidden="true" tabindex="-1"></a>dive_model <span class="ot">&lt;-</span> <span class="fu">lm</span>(max_depth <span class="sc">~</span> body_size_kg, <span class="at">data =</span> dive_data)</span>
<span id="cb42-503"><a href="#cb42-503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-504"><a href="#cb42-504" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-505"><a href="#cb42-505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-506"><a href="#cb42-506" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-507"><a href="#cb42-507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-508"><a href="#cb42-508" aria-hidden="true" tabindex="-1"></a>Great. </span>
<span id="cb42-509"><a href="#cb42-509" aria-hidden="true" tabindex="-1"></a>We have run a model and assigned it to an object name. </span>
<span id="cb42-510"><a href="#cb42-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-511"><a href="#cb42-511" aria-hidden="true" tabindex="-1"></a>We can look at the maximum likelihood estimates of our model parameters </span>
<span id="cb42-512"><a href="#cb42-512" aria-hidden="true" tabindex="-1"></a>(<span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:orange"</span><span class="kw">&gt;</span>$\alpha$<span class="kw">&lt;/span&gt;</span> and <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>$\beta$<span class="kw">&lt;/span&gt;</span>) </span>
<span id="cb42-513"><a href="#cb42-513" aria-hidden="true" tabindex="-1"></a>using the function <span class="in">`coef()`</span>.</span>
<span id="cb42-514"><a href="#cb42-514" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-515"><a href="#cb42-515" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dive-coef1, include=TRUE, echo=TRUE}</span></span>
<span id="cb42-516"><a href="#cb42-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-517"><a href="#cb42-517" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(dive_model)</span>
<span id="cb42-518"><a href="#cb42-518" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-519"><a href="#cb42-519" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-520"><a href="#cb42-520" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-521"><a href="#cb42-521" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-522"><a href="#cb42-522" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-523"><a href="#cb42-523" aria-hidden="true" tabindex="-1"></a>We will look at interpreting these in the next part of the worked example. </span>
<span id="cb42-524"><a href="#cb42-524" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-525"><a href="#cb42-525" aria-hidden="true" tabindex="-1"></a><span class="fu">## &lt;i class="fas fa-laptop"&gt;&lt;/i&gt; Parameters {.tabset .tabset-fade}</span></span>
<span id="cb42-526"><a href="#cb42-526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-527"><a href="#cb42-527" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-528"><a href="#cb42-528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-529"><a href="#cb42-529" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theory</span></span>
<span id="cb42-530"><a href="#cb42-530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-531"><a href="#cb42-531" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-532"><a href="#cb42-532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-533"><a href="#cb42-533" aria-hidden="true" tabindex="-1"></a>We introduced the three model parameters of a simple linear regression in the </span>
<span id="cb42-534"><a href="#cb42-534" aria-hidden="true" tabindex="-1"></a>section above: <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:orange"</span><span class="kw">&gt;</span>**$\alpha$**<span class="kw">&lt;/span&gt;</span> = the intercept, </span>
<span id="cb42-535"><a href="#cb42-535" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>**$\beta$**<span class="kw">&lt;/span&gt;</span> = the slope of the line </span>
<span id="cb42-536"><a href="#cb42-536" aria-hidden="true" tabindex="-1"></a>(steepness/gradient), and </span>
<span id="cb42-537"><a href="#cb42-537" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:red"</span><span class="kw">&gt;</span>**$\sigma^{2}$**<span class="kw">&lt;/span&gt;</span> the variance of the error. </span>
<span id="cb42-538"><a href="#cb42-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-539"><a href="#cb42-539" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-540"><a href="#cb42-540" aria-hidden="true" tabindex="-1"></a>Y_i = \color{orange}\alpha + \color{blue}\beta X_i + \color{red}\varepsilon_i</span>
<span id="cb42-541"><a href="#cb42-541" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-542"><a href="#cb42-542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-543"><a href="#cb42-543" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-544"><a href="#cb42-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-545"><a href="#cb42-545" aria-hidden="true" tabindex="-1"></a>**But what do these parameters really mean?**</span>
<span id="cb42-546"><a href="#cb42-546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-547"><a href="#cb42-547" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-548"><a href="#cb42-548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-549"><a href="#cb42-549" aria-hidden="true" tabindex="-1"></a>All regression analyses are fundamentally about using straight lines to </span>
<span id="cb42-550"><a href="#cb42-550" aria-hidden="true" tabindex="-1"></a>represent the relationship between a response ($Y$) and </span>
<span id="cb42-551"><a href="#cb42-551" aria-hidden="true" tabindex="-1"></a>some explanatory variables ($X$), called a **regression line**. </span>
<span id="cb42-552"><a href="#cb42-552" aria-hidden="true" tabindex="-1"></a>The parameters of the model determine the placement and gradient of the straight</span>
<span id="cb42-553"><a href="#cb42-553" aria-hidden="true" tabindex="-1"></a>line, as well as representing the distribution of data points around the line. </span>
<span id="cb42-554"><a href="#cb42-554" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-555"><a href="#cb42-555" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-556"><a href="#cb42-556" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-557"><a href="#cb42-557" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-parameter-plot, echo=FALSE}</span></span>
<span id="cb42-558"><a href="#cb42-558" aria-hidden="true" tabindex="-1"></a>fitted_values <span class="ot">&lt;-</span> <span class="fu">fitted</span>(model_object)</span>
<span id="cb42-559"><a href="#cb42-559" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-560"><a href="#cb42-560" aria-hidden="true" tabindex="-1"></a>parameter_plot <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(your_data, <span class="fu">aes</span>(<span class="at">x=</span>explanatory, <span class="at">y=</span>response))<span class="sc">+</span></span>
<span id="cb42-561"><a href="#cb42-561" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"grey"</span>)<span class="sc">+</span></span>
<span id="cb42-562"><a href="#cb42-562" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_abline</span>(<span class="at">intercept=</span><span class="fu">coef</span>(model_object)[<span class="dv">1</span>], </span>
<span id="cb42-563"><a href="#cb42-563" aria-hidden="true" tabindex="-1"></a>              <span class="at">slope=</span><span class="fu">coef</span>(model_object)[<span class="dv">2</span>], </span>
<span id="cb42-564"><a href="#cb42-564" aria-hidden="true" tabindex="-1"></a>              <span class="at">color =</span> <span class="st">"blue"</span>)<span class="sc">+</span></span>
<span id="cb42-565"><a href="#cb42-565" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="dv">0</span>, <span class="at">y=</span><span class="fu">coef</span>(model_object)[<span class="dv">1</span>]), </span>
<span id="cb42-566"><a href="#cb42-566" aria-hidden="true" tabindex="-1"></a>                 <span class="at">colour =</span> <span class="st">'orange'</span>, <span class="at">size =</span> <span class="dv">4</span>, <span class="at">pch=</span><span class="dv">8</span>)<span class="sc">+</span></span>
<span id="cb42-567"><a href="#cb42-567" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="dv">13</span>, <span class="at">xend=</span><span class="dv">13</span>, <span class="at">y=</span><span class="fu">coef</span>(model_object)[<span class="dv">1</span>]<span class="sc">+</span>(<span class="fu">coef</span>(model_object)[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">12</span>),</span>
<span id="cb42-568"><a href="#cb42-568" aria-hidden="true" tabindex="-1"></a>                                <span class="at">yend=</span><span class="fu">coef</span>(model_object)[<span class="dv">1</span>]<span class="sc">+</span>(<span class="fu">coef</span>(model_object)[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">13</span>)),</span>
<span id="cb42-569"><a href="#cb42-569" aria-hidden="true" tabindex="-1"></a>                <span class="at">colour =</span> <span class="st">'darkblue'</span>)<span class="sc">+</span></span>
<span id="cb42-570"><a href="#cb42-570" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="dv">12</span>,<span class="at">xend=</span><span class="dv">13</span>, <span class="at">y=</span><span class="fu">coef</span>(model_object)[<span class="dv">1</span>]<span class="sc">+</span>(<span class="fu">coef</span>(model_object)[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">12</span>),</span>
<span id="cb42-571"><a href="#cb42-571" aria-hidden="true" tabindex="-1"></a>                                <span class="at">yend=</span><span class="fu">coef</span>(model_object)[<span class="dv">1</span>]<span class="sc">+</span>(<span class="fu">coef</span>(model_object)[<span class="dv">2</span>]<span class="sc">*</span><span class="dv">12</span>)),</span>
<span id="cb42-572"><a href="#cb42-572" aria-hidden="true" tabindex="-1"></a>                <span class="at">colour =</span> <span class="st">'darkblue'</span>)<span class="sc">+</span></span>
<span id="cb42-573"><a href="#cb42-573" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="dv">15</span>, <span class="at">y=</span><span class="dv">11</span>, <span class="at">label =</span> <span class="st">"Gradient of slope"</span>),</span>
<span id="cb42-574"><a href="#cb42-574" aria-hidden="true" tabindex="-1"></a>            <span class="at">colour =</span> <span class="st">'darkblue'</span>, <span class="at">check_overlap =</span> <span class="cn">TRUE</span>)<span class="sc">+</span></span>
<span id="cb42-575"><a href="#cb42-575" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="fl">2.5</span>, <span class="at">y=</span><span class="dv">0</span>, <span class="at">label =</span> <span class="st">"Incercept"</span>),</span>
<span id="cb42-576"><a href="#cb42-576" aria-hidden="true" tabindex="-1"></a>            <span class="at">colour =</span> <span class="st">'orange'</span>, <span class="at">check_overlap =</span> <span class="cn">TRUE</span>)<span class="sc">+</span></span>
<span id="cb42-577"><a href="#cb42-577" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="fl">24.3</span>, <span class="at">y=</span><span class="dv">28</span>, <span class="at">label =</span> <span class="st">"Residual"</span>),</span>
<span id="cb42-578"><a href="#cb42-578" aria-hidden="true" tabindex="-1"></a>            <span class="at">colour =</span> <span class="st">'red'</span>, <span class="at">check_overlap =</span> <span class="cn">TRUE</span>)<span class="sc">+</span></span>
<span id="cb42-579"><a href="#cb42-579" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_segment</span>(<span class="fu">aes</span>(<span class="at">xend=</span>explanatory, </span>
<span id="cb42-580"><a href="#cb42-580" aria-hidden="true" tabindex="-1"></a>                   <span class="at">yend=</span>fitted_values), <span class="at">colour =</span> <span class="st">'red'</span>)</span>
<span id="cb42-581"><a href="#cb42-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-582"><a href="#cb42-582" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-583"><a href="#cb42-583" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-584"><a href="#cb42-584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-587"><a href="#cb42-587" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-588"><a href="#cb42-588" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-parameter-plot</span></span>
<span id="cb42-589"><a href="#cb42-589" aria-hidden="true" tabindex="-1"></a><span class="co">#| include: true</span></span>
<span id="cb42-590"><a href="#cb42-590" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: false</span></span>
<span id="cb42-591"><a href="#cb42-591" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Illustration of components of a linear regression. Intercept is in orange, slope is in blue, and the residuals (explained later) are in red"</span></span>
<span id="cb42-592"><a href="#cb42-592" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-593"><a href="#cb42-593" aria-hidden="true" tabindex="-1"></a>parameter_plot</span>
<span id="cb42-594"><a href="#cb42-594" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb42-595"><a href="#cb42-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-596"><a href="#cb42-596" aria-hidden="true" tabindex="-1"></a>In this section we will go through these parameters and </span>
<span id="cb42-597"><a href="#cb42-597" aria-hidden="true" tabindex="-1"></a>their meaning in terms of the relationship between $X$ and $Y$.</span>
<span id="cb42-598"><a href="#cb42-598" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-599"><a href="#cb42-599" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-600"><a href="#cb42-600" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-601"><a href="#cb42-601" aria-hidden="true" tabindex="-1"></a><span class="fu">#### &lt;span style="color:orange"&gt;$\alpha$&lt;/span&gt;, the intercept</span></span>
<span id="cb42-602"><a href="#cb42-602" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-603"><a href="#cb42-603" aria-hidden="true" tabindex="-1"></a>This first parameter gives the value of $Y$ when $X$ = 0, it is the point that</span>
<span id="cb42-604"><a href="#cb42-604" aria-hidden="true" tabindex="-1"></a>the regression line crossed the y-axis. </span>
<span id="cb42-605"><a href="#cb42-605" aria-hidden="true" tabindex="-1"></a>A positive value means that the value of $Y$ when $X$ = 0 is above 0, and a</span>
<span id="cb42-606"><a href="#cb42-606" aria-hidden="true" tabindex="-1"></a>negative intercept value means it is below the value of $Y$ is below 0, when</span>
<span id="cb42-607"><a href="#cb42-607" aria-hidden="true" tabindex="-1"></a>$X$ = 0.  </span>
<span id="cb42-608"><a href="#cb42-608" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-609"><a href="#cb42-609" aria-hidden="true" tabindex="-1"></a><span class="fu">#### &lt;span style="color:blue"&gt;$\beta$&lt;/span&gt;, the slope</span></span>
<span id="cb42-610"><a href="#cb42-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-611"><a href="#cb42-611" aria-hidden="true" tabindex="-1"></a>This second parameter gives the amount of change in $Y$ </span>
<span id="cb42-612"><a href="#cb42-612" aria-hidden="true" tabindex="-1"></a>for every unit change in $X$, it is the slope of the regression line. </span>
<span id="cb42-613"><a href="#cb42-613" aria-hidden="true" tabindex="-1"></a>Positive values indicate a positive relationship between $X$ and $Y$ i.e. $Y$ </span>
<span id="cb42-614"><a href="#cb42-614" aria-hidden="true" tabindex="-1"></a>increases as $X$ increases. </span>
<span id="cb42-615"><a href="#cb42-615" aria-hidden="true" tabindex="-1"></a>Negative slope values indicate the opposite, a negative relationship where $Y$</span>
<span id="cb42-616"><a href="#cb42-616" aria-hidden="true" tabindex="-1"></a> decreases as $X$ increases.</span>
<span id="cb42-617"><a href="#cb42-617" aria-hidden="true" tabindex="-1"></a>The higher the value of the slope, the stronger the regression relationship. </span>
<span id="cb42-618"><a href="#cb42-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-619"><a href="#cb42-619" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-620"><a href="#cb42-620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-621"><a href="#cb42-621" aria-hidden="true" tabindex="-1"></a>**Together $\alpha$ and $\beta$ control the position and steepness of the </span>
<span id="cb42-622"><a href="#cb42-622" aria-hidden="true" tabindex="-1"></a>regression line.** </span>
<span id="cb42-623"><a href="#cb42-623" aria-hidden="true" tabindex="-1"></a>They are called the **systematic** part of the model, </span>
<span id="cb42-624"><a href="#cb42-624" aria-hidden="true" tabindex="-1"></a>the bit that links $Y$ to the covariate $X$. </span>
<span id="cb42-625"><a href="#cb42-625" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-626"><a href="#cb42-626" aria-hidden="true" tabindex="-1"></a><span class="fu">#### $\sigma^{2}$, the variance of error</span></span>
<span id="cb42-627"><a href="#cb42-627" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb42-628"><a href="#cb42-628" aria-hidden="true" tabindex="-1"></a>This is the final parameter you need to estimate for the simple linear </span>
<span id="cb42-629"><a href="#cb42-629" aria-hidden="true" tabindex="-1"></a>regression and it is</span>
<span id="cb42-630"><a href="#cb42-630" aria-hidden="true" tabindex="-1"></a>a bit different from <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:orange"</span><span class="kw">&gt;</span>$\alpha$<span class="kw">&lt;/span&gt;</span> and <span class="kw">&lt;span</span> <span class="er">style</span><span class="ot">=</span><span class="st">"color:blue"</span><span class="kw">&gt;</span>$\beta$<span class="kw">&lt;/span&gt;</span>. </span>
<span id="cb42-631"><a href="#cb42-631" aria-hidden="true" tabindex="-1"></a>This parameter does not relate directly to the shape or </span>
<span id="cb42-632"><a href="#cb42-632" aria-hidden="true" tabindex="-1"></a>position of the regression line. </span>
<span id="cb42-633"><a href="#cb42-633" aria-hidden="true" tabindex="-1"></a>Instead, this parameter captures the variance of the data points around that </span>
<span id="cb42-634"><a href="#cb42-634" aria-hidden="true" tabindex="-1"></a>line, i.e. how close or far away each data point is from the regression line. </span>
<span id="cb42-635"><a href="#cb42-635" aria-hidden="true" tabindex="-1"></a>The variance is the **random** part of the model, </span>
<span id="cb42-636"><a href="#cb42-636" aria-hidden="true" tabindex="-1"></a>or in other words the error. </span>
<span id="cb42-637"><a href="#cb42-637" aria-hidden="true" tabindex="-1"></a>Higher error variance values indicate more variation around the model fit.</span>
<span id="cb42-638"><a href="#cb42-638" aria-hidden="true" tabindex="-1"></a>In the case of a simple linear regression, the error is assumed to be normally distributed.</span>
<span id="cb42-639"><a href="#cb42-639" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-640"><a href="#cb42-640" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-641"><a href="#cb42-641" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-642"><a href="#cb42-642" aria-hidden="true" tabindex="-1"></a>In @fig-parameter-plot), </span>
<span id="cb42-643"><a href="#cb42-643" aria-hidden="true" tabindex="-1"></a>you can see a plot of a regression line through the data points, </span>
<span id="cb42-644"><a href="#cb42-644" aria-hidden="true" tabindex="-1"></a>but it does not touch all of the points. </span>
<span id="cb42-645"><a href="#cb42-645" aria-hidden="true" tabindex="-1"></a>In other words, it is not capturing all of the variation in the data. </span>
<span id="cb42-646"><a href="#cb42-646" aria-hidden="true" tabindex="-1"></a>The regression line does not explain the exact position of all data points, </span>
<span id="cb42-647"><a href="#cb42-647" aria-hidden="true" tabindex="-1"></a>something else is also going on (this is to be expected for real data). </span>
<span id="cb42-648"><a href="#cb42-648" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-649"><a href="#cb42-649" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-650"><a href="#cb42-650" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-651"><a href="#cb42-651" aria-hidden="true" tabindex="-1"></a>The regression line is a **fitted line** that represents the best fit line of a relationship between $X$ and $Y$ (based on maximum likelihood estimation). </span>
<span id="cb42-652"><a href="#cb42-652" aria-hidden="true" tabindex="-1"></a>The value of $Y$ for each $X$ on the regression line is called a </span>
<span id="cb42-653"><a href="#cb42-653" aria-hidden="true" tabindex="-1"></a>**fitted value**. </span>
<span id="cb42-654"><a href="#cb42-654" aria-hidden="true" tabindex="-1"></a>The distance between the fitted values and the values of $Y$ </span>
<span id="cb42-655"><a href="#cb42-655" aria-hidden="true" tabindex="-1"></a>that were actually observed are called residuals. </span>
<span id="cb42-656"><a href="#cb42-656" aria-hidden="true" tabindex="-1"></a>You can extract the residuals from your model object using the function </span>
<span id="cb42-657"><a href="#cb42-657" aria-hidden="true" tabindex="-1"></a><span class="in">`residuals()`</span>, which is useful when checking model assumptions (see below). </span>
<span id="cb42-658"><a href="#cb42-658" aria-hidden="true" tabindex="-1"></a>Data points below the regression line have a negative the residual and </span>
<span id="cb42-659"><a href="#cb42-659" aria-hidden="true" tabindex="-1"></a>data points above the line have a positive residual. </span>
<span id="cb42-660"><a href="#cb42-660" aria-hidden="true" tabindex="-1"></a>These are highlighted red in @fig-parameter-plot).</span>
<span id="cb42-661"><a href="#cb42-661" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-662"><a href="#cb42-662" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-663"><a href="#cb42-663" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-664"><a href="#cb42-664" aria-hidden="true" tabindex="-1"></a>**The regression line must always pass through the point that represents the</span>
<span id="cb42-665"><a href="#cb42-665" aria-hidden="true" tabindex="-1"></a>mean of $X$ and the mean of $Y$. ($\bar{X}$, $\bar{Y}$).** </span>
<span id="cb42-666"><a href="#cb42-666" aria-hidden="true" tabindex="-1"></a>Therefore, if you change the intercept, the slope must change as well to keep the line going through the ($\bar{X}$, $\bar{Y}$) point. </span>
<span id="cb42-667"><a href="#cb42-667" aria-hidden="true" tabindex="-1"></a>You can have a go at doing this below. </span>
<span id="cb42-668"><a href="#cb42-668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-669"><a href="#cb42-669" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-670"><a href="#cb42-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-671"><a href="#cb42-671" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Exercise: Finding a 'best' line</span></span>
<span id="cb42-672"><a href="#cb42-672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-673"><a href="#cb42-673" aria-hidden="true" tabindex="-1"></a>Below you will see a window containing an app. </span>
<span id="cb42-674"><a href="#cb42-674" aria-hidden="true" tabindex="-1"></a>The aim of this app is to try and find</span>
<span id="cb42-675"><a href="#cb42-675" aria-hidden="true" tabindex="-1"></a>the straight line that best explains the data, by trying different slope values.</span>
<span id="cb42-676"><a href="#cb42-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-677"><a href="#cb42-677" aria-hidden="true" tabindex="-1"></a>There is a slider on the left hand side that lets you control the $\beta$ value, </span>
<span id="cb42-678"><a href="#cb42-678" aria-hidden="true" tabindex="-1"></a>the $\alpha$ is fixed at 0. </span>
<span id="cb42-679"><a href="#cb42-679" aria-hidden="true" tabindex="-1"></a>On the right you can see the fitted line (one is already plotted for you).  </span>
<span id="cb42-680"><a href="#cb42-680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-681"><a href="#cb42-681" aria-hidden="true" tabindex="-1"></a>In this example 'fit' of the line is measured using something called the </span>
<span id="cb42-682"><a href="#cb42-682" aria-hidden="true" tabindex="-1"></a>**sum of squared residuals**. </span>
<span id="cb42-683"><a href="#cb42-683" aria-hidden="true" tabindex="-1"></a>This is calculated by squaring the values of all of the residuals </span>
<span id="cb42-684"><a href="#cb42-684" aria-hidden="true" tabindex="-1"></a>and then adding them up to get a single number:</span>
<span id="cb42-685"><a href="#cb42-685" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-686"><a href="#cb42-686" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-687"><a href="#cb42-687" aria-hidden="true" tabindex="-1"></a>\Sigma (y_i - \bar{y_i})^2</span>
<span id="cb42-688"><a href="#cb42-688" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-689"><a href="#cb42-689" aria-hidden="true" tabindex="-1"></a>where, $y_i$ = the observed value of $y$ for $x_i$ and $\bar{y}$ = </span>
<span id="cb42-690"><a href="#cb42-690" aria-hidden="true" tabindex="-1"></a>the fitted y value for $x_i$, and $i$ is an index of 1 to $n$ (sample size).</span>
<span id="cb42-691"><a href="#cb42-691" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-692"><a href="#cb42-692" aria-hidden="true" tabindex="-1"></a>The reason the sum of squares is used to estimate the fit of a model line </span>
<span id="cb42-693"><a href="#cb42-693" aria-hidden="true" tabindex="-1"></a>to data is because there are roughly as many positive residuals as negative. </span>
<span id="cb42-694"><a href="#cb42-694" aria-hidden="true" tabindex="-1"></a>If you just sum them, the result will be roughly 0. </span>
<span id="cb42-695"><a href="#cb42-695" aria-hidden="true" tabindex="-1"></a>Therefore, squaring them before adding them means they don't cancel out. </span>
<span id="cb42-696"><a href="#cb42-696" aria-hidden="true" tabindex="-1"></a>This measure tells you how far away the observations are from the fitted line, </span>
<span id="cb42-697"><a href="#cb42-697" aria-hidden="true" tabindex="-1"></a>**the lower the number, the better the fit**. </span>
<span id="cb42-698"><a href="#cb42-698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-699"><a href="#cb42-699" aria-hidden="true" tabindex="-1"></a><span class="in">```{r shiny-app-reg, echo = FALSE, message = FALSE}</span></span>
<span id="cb42-700"><a href="#cb42-700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-701"><a href="#cb42-701" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_app</span>(<span class="st">"https://shiny.math.ntnu.no/qmbio/Shiny_apps/Regression/"</span>)</span>
<span id="cb42-702"><a href="#cb42-702" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-703"><a href="#cb42-703" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-704"><a href="#cb42-704" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-705"><a href="#cb42-705" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-706"><a href="#cb42-706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-707"><a href="#cb42-707" aria-hidden="true" tabindex="-1"></a>Click <span class="co">[</span><span class="ot">here</span><span class="co">]("https://shiny.math.ntnu.no/qmbio/Shiny_apps/Regression/")</span> </span>
<span id="cb42-708"><a href="#cb42-708" aria-hidden="true" tabindex="-1"></a>to open the app in full scale in a separate window.</span>
<span id="cb42-709"><a href="#cb42-709" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-710"><a href="#cb42-710" aria-hidden="true" tabindex="-1"></a>**What was the best fit you managed to get?**</span>
<span id="cb42-711"><a href="#cb42-711" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-712"><a href="#cb42-712" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;&lt;summary&gt;</span> What was the answer?<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb42-713"><a href="#cb42-713" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-714"><a href="#cb42-714" aria-hidden="true" tabindex="-1"></a>A slope of approximately 3 should give the best answer (lowest sum of squares), </span>
<span id="cb42-715"><a href="#cb42-715" aria-hidden="true" tabindex="-1"></a>which is 3423.5956.</span>
<span id="cb42-716"><a href="#cb42-716" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-717"><a href="#cb42-717" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb42-718"><a href="#cb42-718" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-719"><a href="#cb42-719" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-720"><a href="#cb42-720" aria-hidden="true" tabindex="-1"></a>**How confident are you that you found the best line?**</span>
<span id="cb42-721"><a href="#cb42-721" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-722"><a href="#cb42-722" aria-hidden="true" tabindex="-1"></a>It is hard to know by trial and error if you have found the 'best' </span>
<span id="cb42-723"><a href="#cb42-723" aria-hidden="true" tabindex="-1"></a>line for the data.</span>
<span id="cb42-724"><a href="#cb42-724" aria-hidden="true" tabindex="-1"></a>It is much easier, repeatable, </span>
<span id="cb42-725"><a href="#cb42-725" aria-hidden="true" tabindex="-1"></a>and reliable to use a simple linear regression instead. </span>
<span id="cb42-726"><a href="#cb42-726" aria-hidden="true" tabindex="-1"></a>The idea is the same as the app, but instead of trying until it looks good, </span>
<span id="cb42-727"><a href="#cb42-727" aria-hidden="true" tabindex="-1"></a>the equation for simple linear regression is used and </span>
<span id="cb42-728"><a href="#cb42-728" aria-hidden="true" tabindex="-1"></a>values for the unknown parameters are found using </span>
<span id="cb42-729"><a href="#cb42-729" aria-hidden="true" tabindex="-1"></a>**maximum likelihood estimation**.</span>
<span id="cb42-730"><a href="#cb42-730" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-731"><a href="#cb42-731" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-732"><a href="#cb42-732" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-733"><a href="#cb42-733" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-734"><a href="#cb42-734" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Interpreting the parameters</span></span>
<span id="cb42-735"><a href="#cb42-735" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-736"><a href="#cb42-736" aria-hidden="true" tabindex="-1"></a>Now you know what each of the three parameters in a simple linear regression</span>
<span id="cb42-737"><a href="#cb42-737" aria-hidden="true" tabindex="-1"></a>mean, you can now think about interpreting them. </span>
<span id="cb42-738"><a href="#cb42-738" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-739"><a href="#cb42-739" aria-hidden="true" tabindex="-1"></a>**Which of the three parameters do you think is most important for answering</span>
<span id="cb42-740"><a href="#cb42-740" aria-hidden="true" tabindex="-1"></a>the research question "Does $X$ influence $Y$?"?**</span>
<span id="cb42-741"><a href="#cb42-741" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-742"><a href="#cb42-742" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-743"><a href="#cb42-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-744"><a href="#cb42-744" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;&lt;summary&gt;</span>I had a go, now show me the answer.<span class="kw">&lt;/summary&gt;&lt;/span&gt;</span></span>
<span id="cb42-745"><a href="#cb42-745" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-746"><a href="#cb42-746" aria-hidden="true" tabindex="-1"></a>**The slope ($\beta$)** tells us the strength and direction the relationship </span>
<span id="cb42-747"><a href="#cb42-747" aria-hidden="true" tabindex="-1"></a>between $X$ and $Y$ is. </span>
<span id="cb42-748"><a href="#cb42-748" aria-hidden="true" tabindex="-1"></a>While the linear regression model also estimates the intercept and the residual variance, these do not directly answer our question of interest. </span>
<span id="cb42-749"><a href="#cb42-749" aria-hidden="true" tabindex="-1"></a>However, to make predictions, we will need all three parameters.</span>
<span id="cb42-750"><a href="#cb42-750" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-751"><a href="#cb42-751" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb42-752"><a href="#cb42-752" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-753"><a href="#cb42-753" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-754"><a href="#cb42-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-755"><a href="#cb42-755" aria-hidden="true" tabindex="-1"></a><span class="fu">### Worked example </span></span>
<span id="cb42-756"><a href="#cb42-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-757"><a href="#cb42-757" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-758"><a href="#cb42-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-759"><a href="#cb42-759" aria-hidden="true" tabindex="-1"></a>In the previous section of this worked example, we fit a simple linear </span>
<span id="cb42-760"><a href="#cb42-760" aria-hidden="true" tabindex="-1"></a>regression using the <span class="in">`lm()`</span> function and looked at the estimates of </span>
<span id="cb42-761"><a href="#cb42-761" aria-hidden="true" tabindex="-1"></a>some parameters using the <span class="in">`coef()`</span> function. </span>
<span id="cb42-762"><a href="#cb42-762" aria-hidden="true" tabindex="-1"></a>In this section, </span>
<span id="cb42-763"><a href="#cb42-763" aria-hidden="true" tabindex="-1"></a>we will use model theory to interpret what those parameters mean.</span>
<span id="cb42-764"><a href="#cb42-764" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-765"><a href="#cb42-765" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-766"><a href="#cb42-766" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-767"><a href="#cb42-767" aria-hidden="true" tabindex="-1"></a><span class="fu">#### The intercept and slope</span></span>
<span id="cb42-768"><a href="#cb42-768" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-769"><a href="#cb42-769" aria-hidden="true" tabindex="-1"></a>We already know that the parameters of the intercept and slope control the </span>
<span id="cb42-770"><a href="#cb42-770" aria-hidden="true" tabindex="-1"></a>position and steepness of the regression line. </span>
<span id="cb42-771"><a href="#cb42-771" aria-hidden="true" tabindex="-1"></a>It is the estimates of these two parameters that we get from the <span class="in">`coef()`</span> </span>
<span id="cb42-772"><a href="#cb42-772" aria-hidden="true" tabindex="-1"></a>function. </span>
<span id="cb42-773"><a href="#cb42-773" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-774"><a href="#cb42-774" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-775"><a href="#cb42-775" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-776"><a href="#cb42-776" aria-hidden="true" tabindex="-1"></a>For our dive depth model the estimates are:</span>
<span id="cb42-777"><a href="#cb42-777" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-778"><a href="#cb42-778" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dive-coef2, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-779"><a href="#cb42-779" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(dive_model)</span>
<span id="cb42-780"><a href="#cb42-780" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-781"><a href="#cb42-781" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-782"><a href="#cb42-782" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-783"><a href="#cb42-783" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-784"><a href="#cb42-784" aria-hidden="true" tabindex="-1"></a>The intercept is 756 m and the slope of the relationship between body </span>
<span id="cb42-785"><a href="#cb42-785" aria-hidden="true" tabindex="-1"></a>size and dive depth is -0.005. </span>
<span id="cb42-786"><a href="#cb42-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-787"><a href="#cb42-787" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-788"><a href="#cb42-788" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-789"><a href="#cb42-789" aria-hidden="true" tabindex="-1"></a>In this case, the intercept is not that interesting. </span>
<span id="cb42-790"><a href="#cb42-790" aria-hidden="true" tabindex="-1"></a>It tells us the expected value of $Y$ (maximum dive depth) </span>
<span id="cb42-791"><a href="#cb42-791" aria-hidden="true" tabindex="-1"></a>when $X$ (body size) = 0. </span>
<span id="cb42-792"><a href="#cb42-792" aria-hidden="true" tabindex="-1"></a>It does not make a lot of biological sense to know the expected dive depth of </span>
<span id="cb42-793"><a href="#cb42-793" aria-hidden="true" tabindex="-1"></a>a marine mammal that weighs 0 kg. </span>
<span id="cb42-794"><a href="#cb42-794" aria-hidden="true" tabindex="-1"></a>But, sometimes it can make sense to know the value $Y$ when $X$ is 0, </span>
<span id="cb42-795"><a href="#cb42-795" aria-hidden="true" tabindex="-1"></a>for example if $X$ was temperature.</span>
<span id="cb42-796"><a href="#cb42-796" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-797"><a href="#cb42-797" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-798"><a href="#cb42-798" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-799"><a href="#cb42-799" aria-hidden="true" tabindex="-1"></a>The slope on the other hand is interesting. </span>
<span id="cb42-800"><a href="#cb42-800" aria-hidden="true" tabindex="-1"></a>It tells us the direction and strength of the relationship between body size </span>
<span id="cb42-801"><a href="#cb42-801" aria-hidden="true" tabindex="-1"></a>and maximum dive depth. </span>
<span id="cb42-802"><a href="#cb42-802" aria-hidden="true" tabindex="-1"></a>In this case our model estimates a negative slope. </span>
<span id="cb42-803"><a href="#cb42-803" aria-hidden="true" tabindex="-1"></a>This means that for every increase of 1 kg in body size of marine mammals the maximum dive depth decreases by </span>
<span id="cb42-804"><a href="#cb42-804" aria-hidden="true" tabindex="-1"></a>0.005 m. </span>
<span id="cb42-805"><a href="#cb42-805" aria-hidden="true" tabindex="-1"></a>In other words, there is a negative relationship between body weight </span>
<span id="cb42-806"><a href="#cb42-806" aria-hidden="true" tabindex="-1"></a>and dive depth and as $X$ increases $Y$ decreases (@fig-fig-6).</span>
<span id="cb42-807"><a href="#cb42-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-808"><a href="#cb42-808" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-809"><a href="#cb42-809" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-810"><a href="#cb42-810" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Residual variance</span></span>
<span id="cb42-811"><a href="#cb42-811" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-812"><a href="#cb42-812" aria-hidden="true" tabindex="-1"></a>The <span class="in">`coef()`</span> function can give us the maximum likelihood estimates of the </span>
<span id="cb42-813"><a href="#cb42-813" aria-hidden="true" tabindex="-1"></a>intercept and slope parameters, </span>
<span id="cb42-814"><a href="#cb42-814" aria-hidden="true" tabindex="-1"></a>but it does not give any information on the residual variance, $\sigma^{2}$. </span>
<span id="cb42-815"><a href="#cb42-815" aria-hidden="true" tabindex="-1"></a>To get an estimation of the residual variance, we use the <span class="in">`summary()`</span> </span>
<span id="cb42-816"><a href="#cb42-816" aria-hidden="true" tabindex="-1"></a>function with the model object as an argument. </span>
<span id="cb42-817"><a href="#cb42-817" aria-hidden="true" tabindex="-1"></a>To extract $\sigma$ we use <span class="in">`$sigma`</span> </span>
<span id="cb42-818"><a href="#cb42-818" aria-hidden="true" tabindex="-1"></a>and square the result to get $\sigma^{2}$.</span>
<span id="cb42-819"><a href="#cb42-819" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-820"><a href="#cb42-820" aria-hidden="true" tabindex="-1"></a>You cannot take <span class="in">`var(residuals)`</span> directly because this uses <span class="in">`n-1`</span> as the </span>
<span id="cb42-821"><a href="#cb42-821" aria-hidden="true" tabindex="-1"></a>denominator of the variance equation whereas to estimate $\sigma^{2}$ for</span>
<span id="cb42-822"><a href="#cb42-822" aria-hidden="true" tabindex="-1"></a>a linear regression the denominator depends on the number of parameters being estimated. The denominator is the degrees of freedom (<span class="in">`n-number of parameters estimated`</span>). In a simple linear regression there are two parameters that have</span>
<span id="cb42-823"><a href="#cb42-823" aria-hidden="true" tabindex="-1"></a>been estimated (as well as $\sigma^{2}$) these are the intercept and the slope. Therefore, the denominator <span class="in">`n-2`</span>. The more explanatory variables </span>
<span id="cb42-824"><a href="#cb42-824" aria-hidden="true" tabindex="-1"></a>you add to a linear regression, the more parameters you estimate and the </span>
<span id="cb42-825"><a href="#cb42-825" aria-hidden="true" tabindex="-1"></a>fewer degrees of freedom you will have.  </span>
<span id="cb42-826"><a href="#cb42-826" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-827"><a href="#cb42-827" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-828"><a href="#cb42-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-829"><a href="#cb42-829" aria-hidden="true" tabindex="-1"></a><span class="in">```{r get-dive-residual_var, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-830"><a href="#cb42-830" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-831"><a href="#cb42-831" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(dive_model)<span class="sc">$</span>sigma<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb42-832"><a href="#cb42-832" aria-hidden="true" tabindex="-1"></a>sigma2</span>
<span id="cb42-833"><a href="#cb42-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-834"><a href="#cb42-834" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-835"><a href="#cb42-835" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-836"><a href="#cb42-836" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-837"><a href="#cb42-837" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-838"><a href="#cb42-838" aria-hidden="true" tabindex="-1"></a>For this model the $\sigma^{2}$ = <span class="in">`r summary(dive_model)$sigma^2`</span>. </span>
<span id="cb42-839"><a href="#cb42-839" aria-hidden="true" tabindex="-1"></a>This number is abstract and does not mean anything on its own, </span>
<span id="cb42-840"><a href="#cb42-840" aria-hidden="true" tabindex="-1"></a>but it *could* be used to compare models (though there are much better ways </span>
<span id="cb42-841"><a href="#cb42-841" aria-hidden="true" tabindex="-1"></a>to do this). </span>
<span id="cb42-842"><a href="#cb42-842" aria-hidden="true" tabindex="-1"></a>It does not help in terms of answering whether body size influences dive depth. </span>
<span id="cb42-843"><a href="#cb42-843" aria-hidden="true" tabindex="-1"></a>But we will use it for prediction later. </span>
<span id="cb42-844"><a href="#cb42-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-845"><a href="#cb42-845" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-846"><a href="#cb42-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-847"><a href="#cb42-847" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Plotting the results</span></span>
<span id="cb42-848"><a href="#cb42-848" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-849"><a href="#cb42-849" aria-hidden="true" tabindex="-1"></a>As well as looking at the maximum likelihood estimates of the parameters </span>
<span id="cb42-850"><a href="#cb42-850" aria-hidden="true" tabindex="-1"></a>from the simple linear regression, </span>
<span id="cb42-851"><a href="#cb42-851" aria-hidden="true" tabindex="-1"></a>we can also plot the estimated regression line. </span>
<span id="cb42-852"><a href="#cb42-852" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-853"><a href="#cb42-853" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-854"><a href="#cb42-854" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-855"><a href="#cb42-855" aria-hidden="true" tabindex="-1"></a>To do this, we will use <span class="in">`ggplot()`</span> with <span class="in">`geom_line()`</span>. </span>
<span id="cb42-856"><a href="#cb42-856" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-857"><a href="#cb42-857" aria-hidden="true" tabindex="-1"></a>We will also go into the second aim of a regression: **predicting**. </span>
<span id="cb42-858"><a href="#cb42-858" aria-hidden="true" tabindex="-1"></a>Therefore, we need to use a new function called <span class="in">`predict()`</span>. </span>
<span id="cb42-859"><a href="#cb42-859" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-860"><a href="#cb42-860" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-861"><a href="#cb42-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-862"><a href="#cb42-862" aria-hidden="true" tabindex="-1"></a>To make this first plot, we only need to use two arguments: </span>
<span id="cb42-863"><a href="#cb42-863" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-864"><a href="#cb42-864" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`object`</span> = your model object</span>
<span id="cb42-865"><a href="#cb42-865" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span><span class="in">`type`</span> = "response", which means predict on the response scale</span>
<span id="cb42-866"><a href="#cb42-866" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-867"><a href="#cb42-867" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-868"><a href="#cb42-868" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-869"><a href="#cb42-869" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-dive-predictions, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-870"><a href="#cb42-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-871"><a href="#cb42-871" aria-hidden="true" tabindex="-1"></a>depth_predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(dive_model, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb42-872"><a href="#cb42-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-873"><a href="#cb42-873" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-874"><a href="#cb42-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-875"><a href="#cb42-875" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-876"><a href="#cb42-876" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-877"><a href="#cb42-877" aria-hidden="true" tabindex="-1"></a>Once we have created predictions of $Y$ from the model object, we can then plot these using <span class="in">`geom_line()`</span> as in the code below. </span>
<span id="cb42-878"><a href="#cb42-878" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-879"><a href="#cb42-879" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-dive-model-fig, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-880"><a href="#cb42-880" aria-hidden="true" tabindex="-1"></a>dive_model_fig <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dive_data, <span class="fu">aes</span>(<span class="at">x=</span>body_size_kg, <span class="at">y=</span>max_depth))<span class="sc">+</span></span>
<span id="cb42-881"><a href="#cb42-881" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">colour =</span> <span class="st">'grey70'</span>)<span class="sc">+</span></span>
<span id="cb42-882"><a href="#cb42-882" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">y=</span>depth_predictions))<span class="sc">+</span></span>
<span id="cb42-883"><a href="#cb42-883" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y=</span><span class="st">"Maximum Dive Depth (m)"</span>,</span>
<span id="cb42-884"><a href="#cb42-884" aria-hidden="true" tabindex="-1"></a>  <span class="at">x=</span><span class="st">"Body Size (kg)"</span>)</span>
<span id="cb42-885"><a href="#cb42-885" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-886"><a href="#cb42-886" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-887"><a href="#cb42-887" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-dive-model, include=TRUE, echo=FALSE, fig.cap="Scatter plot of dive depths against body size. The black line is the regression line predicted from the linear model"}</span></span>
<span id="cb42-888"><a href="#cb42-888" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-889"><a href="#cb42-889" aria-hidden="true" tabindex="-1"></a>dive_model_fig</span>
<span id="cb42-890"><a href="#cb42-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-891"><a href="#cb42-891" aria-hidden="true" tabindex="-1"></a><span class="in">```</span> </span>
<span id="cb42-892"><a href="#cb42-892" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-893"><a href="#cb42-893" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-894"><a href="#cb42-894" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-895"><a href="#cb42-895" aria-hidden="true" tabindex="-1"></a>In the next section we will look at how to add uncertainty to these plots </span>
<span id="cb42-896"><a href="#cb42-896" aria-hidden="true" tabindex="-1"></a>and our interpretation. </span>
<span id="cb42-897"><a href="#cb42-897" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-898"><a href="#cb42-898" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-899"><a href="#cb42-899" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-900"><a href="#cb42-900" aria-hidden="true" tabindex="-1"></a><span class="fu">## &lt;i class="fas fa-arrows-alt-h"&gt;&lt;/i&gt; Quantify uncertainty {.tabset .tabset-fade}</span></span>
<span id="cb42-901"><a href="#cb42-901" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-902"><a href="#cb42-902" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-903"><a href="#cb42-903" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-904"><a href="#cb42-904" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theory</span></span>
<span id="cb42-905"><a href="#cb42-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-906"><a href="#cb42-906" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-907"><a href="#cb42-907" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-908"><a href="#cb42-908" aria-hidden="true" tabindex="-1"></a>You should already know that statistics does not give a single correct answer. </span>
<span id="cb42-909"><a href="#cb42-909" aria-hidden="true" tabindex="-1"></a>When you estimate the values of parameters in our statistical model, </span>
<span id="cb42-910"><a href="#cb42-910" aria-hidden="true" tabindex="-1"></a>there are many different values that could plausibly have produced </span>
<span id="cb42-911"><a href="#cb42-911" aria-hidden="true" tabindex="-1"></a>the observed data. </span>
<span id="cb42-912"><a href="#cb42-912" aria-hidden="true" tabindex="-1"></a>Some of these are more likely than others but several </span>
<span id="cb42-913"><a href="#cb42-913" aria-hidden="true" tabindex="-1"></a>will have very similar likelihoods. </span>
<span id="cb42-914"><a href="#cb42-914" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-915"><a href="#cb42-915" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-916"><a href="#cb42-916" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-917"><a href="#cb42-917" aria-hidden="true" tabindex="-1"></a>A simple linear regression is no different. </span>
<span id="cb42-918"><a href="#cb42-918" aria-hidden="true" tabindex="-1"></a>And a way to cope with this, </span>
<span id="cb42-919"><a href="#cb42-919" aria-hidden="true" tabindex="-1"></a>is to calculate and present the uncertainty in the parameters you estimate.</span>
<span id="cb42-920"><a href="#cb42-920" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-921"><a href="#cb42-921" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-922"><a href="#cb42-922" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-923"><a href="#cb42-923" aria-hidden="true" tabindex="-1"></a>The <span class="in">`lm()`</span> function produces results that are equivalent to maximum likelihood estimation of the parameters.</span>
<span id="cb42-924"><a href="#cb42-924" aria-hidden="true" tabindex="-1"></a>Therefore, our consideration of uncertainty for these models follows the same</span>
<span id="cb42-925"><a href="#cb42-925" aria-hidden="true" tabindex="-1"></a>principles as discussed <span class="co">[</span><span class="ot">here</span><span class="co">](link to ML page)</span>. </span>
<span id="cb42-926"><a href="#cb42-926" aria-hidden="true" tabindex="-1"></a>You can quantify uncertainty using</span>
<span id="cb42-927"><a href="#cb42-927" aria-hidden="true" tabindex="-1"></a>**standard errors**, **confidence intervals**, and **prediction intervals** </span>
<span id="cb42-928"><a href="#cb42-928" aria-hidden="true" tabindex="-1"></a>which should be familiar to you</span>
<span id="cb42-929"><a href="#cb42-929" aria-hidden="true" tabindex="-1"></a>but head to the <span class="co">[</span><span class="ot">uncertainty</span><span class="co">]()</span> pages if you need a recap.</span>
<span id="cb42-930"><a href="#cb42-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-931"><a href="#cb42-931" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-932"><a href="#cb42-932" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-933"><a href="#cb42-933" aria-hidden="true" tabindex="-1"></a>For any regression there are two different types of uncertainty. </span>
<span id="cb42-934"><a href="#cb42-934" aria-hidden="true" tabindex="-1"></a>Here, we cover at the</span>
<span id="cb42-935"><a href="#cb42-935" aria-hidden="true" tabindex="-1"></a>**uncertainty in the parameters of the regression line, </span>
<span id="cb42-936"><a href="#cb42-936" aria-hidden="true" tabindex="-1"></a>$\alpha$ and $\beta$** and the **uncertainty in</span>
<span id="cb42-937"><a href="#cb42-937" aria-hidden="true" tabindex="-1"></a>predictions of $Y$**.</span>
<span id="cb42-938"><a href="#cb42-938" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-939"><a href="#cb42-939" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-940"><a href="#cb42-940" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-941"><a href="#cb42-941" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Uncertainty in the estimates of $\alpha$ and $\beta$</span></span>
<span id="cb42-942"><a href="#cb42-942" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-943"><a href="#cb42-943" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Standard error</span></span>
<span id="cb42-944"><a href="#cb42-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-945"><a href="#cb42-945" aria-hidden="true" tabindex="-1"></a>**The standard error of a parameter is the standard deviation of its sampling distribution. It gives a measure of the spread of the sampling distribution </span>
<span id="cb42-946"><a href="#cb42-946" aria-hidden="true" tabindex="-1"></a>i.e. the uncertainty.** </span>
<span id="cb42-947"><a href="#cb42-947" aria-hidden="true" tabindex="-1"></a>To find the standard errors for the estimates of $\alpha$ and $\beta$ </span>
<span id="cb42-948"><a href="#cb42-948" aria-hidden="true" tabindex="-1"></a>you can use the <span class="in">`summary()`</span> function. </span>
<span id="cb42-949"><a href="#cb42-949" aria-hidden="true" tabindex="-1"></a>The argument that <span class="in">`summary()`</span> takes is a model object, the output from <span class="in">`lm()`</span>. </span>
<span id="cb42-950"><a href="#cb42-950" aria-hidden="true" tabindex="-1"></a>This function gives a big table with lots of information.</span>
<span id="cb42-951"><a href="#cb42-951" aria-hidden="true" tabindex="-1"></a>The first line shows the model formula used for the model object. </span>
<span id="cb42-952"><a href="#cb42-952" aria-hidden="true" tabindex="-1"></a>The second line shows a summary of the residuals of the model and the</span>
<span id="cb42-953"><a href="#cb42-953" aria-hidden="true" tabindex="-1"></a>standard errors are shown as the second column in the third part, </span>
<span id="cb42-954"><a href="#cb42-954" aria-hidden="true" tabindex="-1"></a><span class="in">`Coefficients:`</span>.</span>
<span id="cb42-955"><a href="#cb42-955" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-956"><a href="#cb42-956" aria-hidden="true" tabindex="-1"></a><span class="in">```{r example-model-summary, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-957"><a href="#cb42-957" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-958"><a href="#cb42-958" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model_object)</span>
<span id="cb42-959"><a href="#cb42-959" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-960"><a href="#cb42-960" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-961"><a href="#cb42-961" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-962"><a href="#cb42-962" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-963"><a href="#cb42-963" aria-hidden="true" tabindex="-1"></a>If we take the <span class="in">`summary()`</span> of the example model, </span>
<span id="cb42-964"><a href="#cb42-964" aria-hidden="true" tabindex="-1"></a>we can see the standard error or the intercept ($\alpha$) is 0.95825, </span>
<span id="cb42-965"><a href="#cb42-965" aria-hidden="true" tabindex="-1"></a>and the standard error for the slope ($\beta$) is 0.05483.</span>
<span id="cb42-966"><a href="#cb42-966" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-967"><a href="#cb42-967" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-968"><a href="#cb42-968" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-969"><a href="#cb42-969" aria-hidden="true" tabindex="-1"></a><span class="fu">##### Confidence intervals</span></span>
<span id="cb42-970"><a href="#cb42-970" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-971"><a href="#cb42-971" aria-hidden="true" tabindex="-1"></a>For interpretation of the uncertainty, </span>
<span id="cb42-972"><a href="#cb42-972" aria-hidden="true" tabindex="-1"></a>it can be easier to use the standard error to calculate confidence intervals </span>
<span id="cb42-973"><a href="#cb42-973" aria-hidden="true" tabindex="-1"></a>(CI). </span>
<span id="cb42-974"><a href="#cb42-974" aria-hidden="true" tabindex="-1"></a>Confidence intervals indicate the range of plausible values for a parameter. </span>
<span id="cb42-975"><a href="#cb42-975" aria-hidden="true" tabindex="-1"></a>**They represent an interval, that if you were to collect a sample and run the</span>
<span id="cb42-976"><a href="#cb42-976" aria-hidden="true" tabindex="-1"></a>analysis, then</span>
<span id="cb42-977"><a href="#cb42-977" aria-hidden="true" tabindex="-1"></a>repeat that many many times AND each time</span>
<span id="cb42-978"><a href="#cb42-978" aria-hidden="true" tabindex="-1"></a>draw a confidence interval, on average 95% of the time, </span>
<span id="cb42-979"><a href="#cb42-979" aria-hidden="true" tabindex="-1"></a>the true population value of the parameter would be found in </span>
<span id="cb42-980"><a href="#cb42-980" aria-hidden="true" tabindex="-1"></a>within the confidence interval.** </span>
<span id="cb42-981"><a href="#cb42-981" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-982"><a href="#cb42-982" aria-hidden="true" tabindex="-1"></a>If you need a reminder of this click <span class="co">[</span><span class="ot">here</span><span class="co">](link to uncertainty page)</span>.</span>
<span id="cb42-983"><a href="#cb42-983" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-984"><a href="#cb42-984" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-985"><a href="#cb42-985" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-986"><a href="#cb42-986" aria-hidden="true" tabindex="-1"></a>The confidence interval can be calculated using this formula:</span>
<span id="cb42-987"><a href="#cb42-987" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-988"><a href="#cb42-988" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-989"><a href="#cb42-989" aria-hidden="true" tabindex="-1"></a>\begin{aligned}</span>
<span id="cb42-990"><a href="#cb42-990" aria-hidden="true" tabindex="-1"></a>UpperCI = estimate + (1.96 SE) <span class="sc">\\</span></span>
<span id="cb42-991"><a href="#cb42-991" aria-hidden="true" tabindex="-1"></a>LowerCI = estimate - (1.96 SE) <span class="sc">\\</span></span>
<span id="cb42-992"><a href="#cb42-992" aria-hidden="true" tabindex="-1"></a>\end{aligned}</span>
<span id="cb42-993"><a href="#cb42-993" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-994"><a href="#cb42-994" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-995"><a href="#cb42-995" aria-hidden="true" tabindex="-1"></a>1.96 is used because in a standard normal distribution </span>
<span id="cb42-996"><a href="#cb42-996" aria-hidden="true" tabindex="-1"></a>95% of the distribution lies within 1.96 standard deviations of the mean. </span>
<span id="cb42-997"><a href="#cb42-997" aria-hidden="true" tabindex="-1"></a>In this case the distribution is the sampling distribution, </span>
<span id="cb42-998"><a href="#cb42-998" aria-hidden="true" tabindex="-1"></a>which is normal for $\alpha$ and $\beta$ and the </span>
<span id="cb42-999"><a href="#cb42-999" aria-hidden="true" tabindex="-1"></a>standard deviation is the standard error. </span>
<span id="cb42-1000"><a href="#cb42-1000" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1001"><a href="#cb42-1001" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1002"><a href="#cb42-1002" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1003"><a href="#cb42-1003" aria-hidden="true" tabindex="-1"></a>Using the formulas above, </span>
<span id="cb42-1004"><a href="#cb42-1004" aria-hidden="true" tabindex="-1"></a>calculate the confidence intervals for the intercept and</span>
<span id="cb42-1005"><a href="#cb42-1005" aria-hidden="true" tabindex="-1"></a>slope from the example model.</span>
<span id="cb42-1006"><a href="#cb42-1006" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1007"><a href="#cb42-1007" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1008"><a href="#cb42-1008" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1009"><a href="#cb42-1009" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;details&gt;&lt;summary&gt;</span> I had a go at calculating, what is the correct answer?<span class="kw">&lt;/summary&gt;</span></span>
<span id="cb42-1010"><a href="#cb42-1010" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1011"><a href="#cb42-1011" aria-hidden="true" tabindex="-1"></a><span class="in">```{r ci-calculation, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-1012"><a href="#cb42-1012" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1013"><a href="#cb42-1013" aria-hidden="true" tabindex="-1"></a><span class="co"># INTERCEPT</span></span>
<span id="cb42-1014"><a href="#cb42-1014" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1015"><a href="#cb42-1015" aria-hidden="true" tabindex="-1"></a><span class="co"># Upper confidence interval</span></span>
<span id="cb42-1016"><a href="#cb42-1016" aria-hidden="true" tabindex="-1"></a>upper_ci_intercept <span class="ot">&lt;-</span> <span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">1</span>] <span class="sc">+</span> </span>
<span id="cb42-1017"><a href="#cb42-1017" aria-hidden="true" tabindex="-1"></a>  (<span class="fl">1.96</span><span class="sc">*</span><span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">2</span>])</span>
<span id="cb42-1018"><a href="#cb42-1018" aria-hidden="true" tabindex="-1"></a><span class="co"># Lower confidence interval</span></span>
<span id="cb42-1019"><a href="#cb42-1019" aria-hidden="true" tabindex="-1"></a>lower_ci_intercept <span class="ot">&lt;-</span> <span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">1</span>] <span class="sc">-</span> </span>
<span id="cb42-1020"><a href="#cb42-1020" aria-hidden="true" tabindex="-1"></a>  (<span class="fl">1.96</span><span class="sc">*</span><span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">1</span>,<span class="dv">2</span>])</span>
<span id="cb42-1021"><a href="#cb42-1021" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1022"><a href="#cb42-1022" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the interval</span></span>
<span id="cb42-1023"><a href="#cb42-1023" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(upper_ci_intercept, lower_ci_intercept) </span>
<span id="cb42-1024"><a href="#cb42-1024" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1025"><a href="#cb42-1025" aria-hidden="true" tabindex="-1"></a><span class="co"># SLOPE</span></span>
<span id="cb42-1026"><a href="#cb42-1026" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1027"><a href="#cb42-1027" aria-hidden="true" tabindex="-1"></a><span class="co"># Upper confidence interval</span></span>
<span id="cb42-1028"><a href="#cb42-1028" aria-hidden="true" tabindex="-1"></a>upper_ci_slope <span class="ot">&lt;-</span> <span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">1</span>] <span class="sc">+</span> (<span class="fl">1.96</span><span class="sc">*</span><span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">2</span>])</span>
<span id="cb42-1029"><a href="#cb42-1029" aria-hidden="true" tabindex="-1"></a><span class="co"># Lower confidence interval</span></span>
<span id="cb42-1030"><a href="#cb42-1030" aria-hidden="true" tabindex="-1"></a>lower_ci_slope <span class="ot">&lt;-</span> <span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">1</span>] <span class="sc">-</span> (<span class="fl">1.96</span><span class="sc">*</span><span class="fu">summary</span>(model_object)<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">2</span>])</span>
<span id="cb42-1031"><a href="#cb42-1031" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1032"><a href="#cb42-1032" aria-hidden="true" tabindex="-1"></a><span class="co"># Print the interval</span></span>
<span id="cb42-1033"><a href="#cb42-1033" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(upper_ci_slope, lower_ci_slope) </span>
<span id="cb42-1034"><a href="#cb42-1034" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1035"><a href="#cb42-1035" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1036"><a href="#cb42-1036" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1037"><a href="#cb42-1037" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/details&gt;</span></span>
<span id="cb42-1038"><a href="#cb42-1038" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1039"><a href="#cb42-1039" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1040"><a href="#cb42-1040" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1041"><a href="#cb42-1041" aria-hidden="true" tabindex="-1"></a>It is also possible to get R to calculate the confidence intervals for you. </span>
<span id="cb42-1042"><a href="#cb42-1042" aria-hidden="true" tabindex="-1"></a>To do this you can use the <span class="in">`confint()`</span> function. </span>
<span id="cb42-1043"><a href="#cb42-1043" aria-hidden="true" tabindex="-1"></a>The argument is a model object. </span>
<span id="cb42-1044"><a href="#cb42-1044" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1045"><a href="#cb42-1045" aria-hidden="true" tabindex="-1"></a><span class="in">```{r example-confint, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-1046"><a href="#cb42-1046" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1047"><a href="#cb42-1047" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(model_object)</span>
<span id="cb42-1048"><a href="#cb42-1048" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1049"><a href="#cb42-1049" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1050"><a href="#cb42-1050" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1051"><a href="#cb42-1051" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1052"><a href="#cb42-1052" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1053"><a href="#cb42-1053" aria-hidden="true" tabindex="-1"></a>Hopefully these confidence intervals look the same as those you </span>
<span id="cb42-1054"><a href="#cb42-1054" aria-hidden="true" tabindex="-1"></a>calculated yourself. </span>
<span id="cb42-1055"><a href="#cb42-1055" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1056"><a href="#cb42-1056" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1057"><a href="#cb42-1057" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1058"><a href="#cb42-1058" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1059"><a href="#cb42-1059" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Uncertainty in a prediction of $Y$</span></span>
<span id="cb42-1060"><a href="#cb42-1060" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1061"><a href="#cb42-1061" aria-hidden="true" tabindex="-1"></a>So far, </span>
<span id="cb42-1062"><a href="#cb42-1062" aria-hidden="true" tabindex="-1"></a>we have covered uncertainty in parameter estimates using standard errors </span>
<span id="cb42-1063"><a href="#cb42-1063" aria-hidden="true" tabindex="-1"></a>and confidence intervals but linear regression analyses </span>
<span id="cb42-1064"><a href="#cb42-1064" aria-hidden="true" tabindex="-1"></a>can also be used for prediction. </span>
<span id="cb42-1065"><a href="#cb42-1065" aria-hidden="true" tabindex="-1"></a>When a linear regression is used for </span>
<span id="cb42-1066"><a href="#cb42-1066" aria-hidden="true" tabindex="-1"></a>prediction, an interval of confidence in the prediction should also be given.</span>
<span id="cb42-1067"><a href="#cb42-1067" aria-hidden="true" tabindex="-1"></a>This is a type of confidence interval specific for predictions and can be </span>
<span id="cb42-1068"><a href="#cb42-1068" aria-hidden="true" tabindex="-1"></a>called a **prediction interval**.</span>
<span id="cb42-1069"><a href="#cb42-1069" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1070"><a href="#cb42-1070" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1071"><a href="#cb42-1071" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1072"><a href="#cb42-1072" aria-hidden="true" tabindex="-1"></a>**A 95% prediction interval tells you, </span>
<span id="cb42-1073"><a href="#cb42-1073" aria-hidden="true" tabindex="-1"></a>if you were to collect a sample and run the analysis, then</span>
<span id="cb42-1074"><a href="#cb42-1074" aria-hidden="true" tabindex="-1"></a>go out an collect a new observation of the response variable ($Y$)</span>
<span id="cb42-1075"><a href="#cb42-1075" aria-hidden="true" tabindex="-1"></a>with particular value of the explanatory variable ($X$) </span>
<span id="cb42-1076"><a href="#cb42-1076" aria-hidden="true" tabindex="-1"></a>many many times AND each time</span>
<span id="cb42-1077"><a href="#cb42-1077" aria-hidden="true" tabindex="-1"></a>draw a prediction interval, 95% of the time, the new observation</span>
<span id="cb42-1078"><a href="#cb42-1078" aria-hidden="true" tabindex="-1"></a>would fall in within the prediction interval.** </span>
<span id="cb42-1079"><a href="#cb42-1079" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1080"><a href="#cb42-1080" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1081"><a href="#cb42-1081" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1082"><a href="#cb42-1082" aria-hidden="true" tabindex="-1"></a>To find the prediction interval for a prediction you use the <span class="in">`predict()`</span> </span>
<span id="cb42-1083"><a href="#cb42-1083" aria-hidden="true" tabindex="-1"></a>function with the <span class="in">`interval="prediction"`</span> argument. </span>
<span id="cb42-1084"><a href="#cb42-1084" aria-hidden="true" tabindex="-1"></a>You also set the <span class="in">`newdata`</span> argument to the value of $X$ you want to predict for.</span>
<span id="cb42-1085"><a href="#cb42-1085" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1086"><a href="#cb42-1086" aria-hidden="true" tabindex="-1"></a><span class="in">```{r example-predict, include = TRUE, echo = TRUE, eval = FALSE}</span></span>
<span id="cb42-1087"><a href="#cb42-1087" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1088"><a href="#cb42-1088" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(model_object, <span class="at">newdata=</span>x_predict, </span>
<span id="cb42-1089"><a href="#cb42-1089" aria-hidden="true" tabindex="-1"></a>                             <span class="at">type=</span><span class="st">"response"</span>, <span class="at">interval =</span> <span class="st">"prediction"</span>)</span>
<span id="cb42-1090"><a href="#cb42-1090" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1091"><a href="#cb42-1091" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1092"><a href="#cb42-1092" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1093"><a href="#cb42-1093" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1094"><a href="#cb42-1094" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1095"><a href="#cb42-1095" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1096"><a href="#cb42-1096" aria-hidden="true" tabindex="-1"></a><span class="fu">### Worked example </span></span>
<span id="cb42-1097"><a href="#cb42-1097" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1098"><a href="#cb42-1098" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1099"><a href="#cb42-1099" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1100"><a href="#cb42-1100" aria-hidden="true" tabindex="-1"></a>At the end of the last section, we created a plot of our dive depth data and the estimated linear regression line. </span>
<span id="cb42-1101"><a href="#cb42-1101" aria-hidden="true" tabindex="-1"></a>Now, we will add uncertainty to that plot. </span>
<span id="cb42-1102"><a href="#cb42-1102" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1103"><a href="#cb42-1103" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1104"><a href="#cb42-1104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1105"><a href="#cb42-1105" aria-hidden="true" tabindex="-1"></a>First, we should look at the confidence intervals of our parameter estimates.</span>
<span id="cb42-1106"><a href="#cb42-1106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1107"><a href="#cb42-1107" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dive-confint, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-1108"><a href="#cb42-1108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1109"><a href="#cb42-1109" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">confint</span>(dive_model),<span class="dv">2</span>)</span>
<span id="cb42-1110"><a href="#cb42-1110" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1111"><a href="#cb42-1111" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1112"><a href="#cb42-1112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1113"><a href="#cb42-1113" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1114"><a href="#cb42-1114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1115"><a href="#cb42-1115" aria-hidden="true" tabindex="-1"></a>The confidence intervals have been rounded to 2 decimal places to make them </span>
<span id="cb42-1116"><a href="#cb42-1116" aria-hidden="true" tabindex="-1"></a>easier to read. </span>
<span id="cb42-1117"><a href="#cb42-1117" aria-hidden="true" tabindex="-1"></a>The intercept interval spans from approx 450 to 1060. </span>
<span id="cb42-1118"><a href="#cb42-1118" aria-hidden="true" tabindex="-1"></a>The slope interval crosses 0, going from -0.02 to +0.01. </span>
<span id="cb42-1119"><a href="#cb42-1119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1120"><a href="#cb42-1120" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1121"><a href="#cb42-1121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1122"><a href="#cb42-1122" aria-hidden="true" tabindex="-1"></a>To add these intervals to the plot, </span>
<span id="cb42-1123"><a href="#cb42-1123" aria-hidden="true" tabindex="-1"></a>we need to make new predictions including the confidence interval. </span>
<span id="cb42-1124"><a href="#cb42-1124" aria-hidden="true" tabindex="-1"></a>In this case</span>
<span id="cb42-1125"><a href="#cb42-1125" aria-hidden="true" tabindex="-1"></a>we are using confidence intervals even though we are predicting, because we </span>
<span id="cb42-1126"><a href="#cb42-1126" aria-hidden="true" tabindex="-1"></a>want to show the uncertainty in $\alpha$ and $\beta$ rather than in a novel </span>
<span id="cb42-1127"><a href="#cb42-1127" aria-hidden="true" tabindex="-1"></a>prediction. </span>
<span id="cb42-1128"><a href="#cb42-1128" aria-hidden="true" tabindex="-1"></a>We have to make predictions in order to plot rather than because we</span>
<span id="cb42-1129"><a href="#cb42-1129" aria-hidden="true" tabindex="-1"></a>are interested in them. </span>
<span id="cb42-1130"><a href="#cb42-1130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1131"><a href="#cb42-1131" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-dive-predictions2, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-1132"><a href="#cb42-1132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1133"><a href="#cb42-1133" aria-hidden="true" tabindex="-1"></a>depth_predictions <span class="ot">&lt;-</span> <span class="fu">as_tibble</span>(<span class="fu">predict</span>(dive_model, <span class="at">type=</span><span class="st">"response"</span>, <span class="at">interval=</span><span class="st">"confidence"</span>))</span>
<span id="cb42-1134"><a href="#cb42-1134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1135"><a href="#cb42-1135" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1136"><a href="#cb42-1136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1137"><a href="#cb42-1137" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1138"><a href="#cb42-1138" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1139"><a href="#cb42-1139" aria-hidden="true" tabindex="-1"></a>Once we have created predictions of $Y$ from the model object, </span>
<span id="cb42-1140"><a href="#cb42-1140" aria-hidden="true" tabindex="-1"></a>we can then plot these using <span class="in">`geom_line()`</span> and <span class="in">`geom_ribbon()`</span> </span>
<span id="cb42-1141"><a href="#cb42-1141" aria-hidden="true" tabindex="-1"></a>for the confidence interval as in the code below.  </span>
<span id="cb42-1142"><a href="#cb42-1142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1143"><a href="#cb42-1143" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-dive-predictions-plot, include = TRUE, echo = TRUE}</span></span>
<span id="cb42-1144"><a href="#cb42-1144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1145"><a href="#cb42-1145" aria-hidden="true" tabindex="-1"></a>depth_predictions <span class="ot">&lt;-</span> depth_predictions <span class="sc">%&gt;%</span></span>
<span id="cb42-1146"><a href="#cb42-1146" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">mutate</span>(<span class="at">x=</span>dive_data<span class="sc">$</span>body_size_kg)</span>
<span id="cb42-1147"><a href="#cb42-1147" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1148"><a href="#cb42-1148" aria-hidden="true" tabindex="-1"></a>fig_7 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>()<span class="sc">+</span></span>
<span id="cb42-1149"><a href="#cb42-1149" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data=</span>depth_predictions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">ymin=</span>lwr, <span class="at">ymax=</span>upr), <span class="at">fill=</span><span class="st">'grey50'</span>)<span class="sc">+</span></span>
<span id="cb42-1150"><a href="#cb42-1150" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>dive_data, <span class="fu">aes</span>(<span class="at">x=</span>body_size_kg, <span class="at">y=</span>max_depth),<span class="at">colour =</span> <span class="st">'grey70'</span>)<span class="sc">+</span></span>
<span id="cb42-1151"><a href="#cb42-1151" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data=</span>depth_predictions, <span class="fu">aes</span>(<span class="at">y=</span>fit, <span class="at">x=</span>x))<span class="sc">+</span></span>
<span id="cb42-1152"><a href="#cb42-1152" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y=</span><span class="st">"Maximum Dive Depth (m)"</span>,</span>
<span id="cb42-1153"><a href="#cb42-1153" aria-hidden="true" tabindex="-1"></a>  <span class="at">x=</span><span class="st">"Body Size (kg)"</span>)</span>
<span id="cb42-1154"><a href="#cb42-1154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1155"><a href="#cb42-1155" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1156"><a href="#cb42-1156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1157"><a href="#cb42-1157" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-dive-predictions-plot, include = TRUE, echo = FALSE, fig.cap="Scatter plot of dive depths against body size. Line is the regression line from a linear model. Shaded area is 95% confidence interval"}</span></span>
<span id="cb42-1158"><a href="#cb42-1158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1159"><a href="#cb42-1159" aria-hidden="true" tabindex="-1"></a>depth_predictions <span class="ot">&lt;-</span> depth_predictions <span class="sc">%&gt;%</span></span>
<span id="cb42-1160"><a href="#cb42-1160" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">mutate</span>(<span class="at">x=</span>dive_data<span class="sc">$</span>body_size_kg)</span>
<span id="cb42-1161"><a href="#cb42-1161" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1162"><a href="#cb42-1162" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>()<span class="sc">+</span></span>
<span id="cb42-1163"><a href="#cb42-1163" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_ribbon</span>(<span class="at">data=</span>depth_predictions, <span class="fu">aes</span>(<span class="at">x=</span>x, <span class="at">ymin=</span>lwr, <span class="at">ymax=</span>upr), <span class="at">fill=</span><span class="st">'grey50'</span>)<span class="sc">+</span></span>
<span id="cb42-1164"><a href="#cb42-1164" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">data=</span>dive_data, <span class="fu">aes</span>(<span class="at">x=</span>body_size_kg, <span class="at">y=</span>max_depth),<span class="at">colour =</span> <span class="st">'grey70'</span>)<span class="sc">+</span></span>
<span id="cb42-1165"><a href="#cb42-1165" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data=</span>depth_predictions, <span class="fu">aes</span>(<span class="at">y=</span>fit, <span class="at">x=</span>x))<span class="sc">+</span></span>
<span id="cb42-1166"><a href="#cb42-1166" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y=</span><span class="st">"Maximum Dive Depth (m)"</span>,</span>
<span id="cb42-1167"><a href="#cb42-1167" aria-hidden="true" tabindex="-1"></a>  <span class="at">x=</span><span class="st">"Body Size (kg)"</span>)</span>
<span id="cb42-1168"><a href="#cb42-1168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1169"><a href="#cb42-1169" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1170"><a href="#cb42-1170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1171"><a href="#cb42-1171" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1172"><a href="#cb42-1172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1173"><a href="#cb42-1173" aria-hidden="true" tabindex="-1"></a>You will notice that the confidence interval is narrower </span>
<span id="cb42-1174"><a href="#cb42-1174" aria-hidden="true" tabindex="-1"></a>in the middle and wider at the ends. </span>
<span id="cb42-1175"><a href="#cb42-1175" aria-hidden="true" tabindex="-1"></a>This is partly to do with the constraint that the regression line </span>
<span id="cb42-1176"><a href="#cb42-1176" aria-hidden="true" tabindex="-1"></a>must go through the ($\bar{X}$, $\bar{Y}$) </span>
<span id="cb42-1177"><a href="#cb42-1177" aria-hidden="true" tabindex="-1"></a>point so the intercept and slope are not independent. </span>
<span id="cb42-1178"><a href="#cb42-1178" aria-hidden="true" tabindex="-1"></a>Therefore, the confidence interval will be narrowest close to that point. </span>
<span id="cb42-1179"><a href="#cb42-1179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1180"><a href="#cb42-1180" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1181"><a href="#cb42-1181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1182"><a href="#cb42-1182" aria-hidden="true" tabindex="-1"></a>The plot shows that the uncertainty in the estimated relationship </span>
<span id="cb42-1183"><a href="#cb42-1183" aria-hidden="true" tabindex="-1"></a>gets increasingly uncertain as you get to higher body sizes. </span>
<span id="cb42-1184"><a href="#cb42-1184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1185"><a href="#cb42-1185" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1186"><a href="#cb42-1186" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1187"><a href="#cb42-1187" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Predicting dive depths for a body size of 75000kg</span></span>
<span id="cb42-1188"><a href="#cb42-1188" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1189"><a href="#cb42-1189" aria-hidden="true" tabindex="-1"></a>A colleague as just found a new species of whale (fictional). </span>
<span id="cb42-1190"><a href="#cb42-1190" aria-hidden="true" tabindex="-1"></a>The whale washed up on shore in Tromsø, it weighed 75000kg.</span>
<span id="cb42-1191"><a href="#cb42-1191" aria-hidden="true" tabindex="-1"></a>Based on our linear regression analysis, how deep would we expect it to dive?</span>
<span id="cb42-1192"><a href="#cb42-1192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1193"><a href="#cb42-1193" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-dive-predictions3, echo = TRUE, warning = FALSE}</span></span>
<span id="cb42-1194"><a href="#cb42-1194" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1195"><a href="#cb42-1195" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(dive_model, <span class="at">newdata=</span><span class="fu">data.frame</span>(<span class="at">body_size_kg=</span><span class="dv">75000</span>), </span>
<span id="cb42-1196"><a href="#cb42-1196" aria-hidden="true" tabindex="-1"></a>                             <span class="at">type=</span><span class="st">"response"</span>, <span class="at">interval =</span> <span class="st">"prediction"</span>)</span>
<span id="cb42-1197"><a href="#cb42-1197" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1198"><a href="#cb42-1198" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1199"><a href="#cb42-1199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1200"><a href="#cb42-1200" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1201"><a href="#cb42-1201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1202"><a href="#cb42-1202" aria-hidden="true" tabindex="-1"></a>The mean prediction is 352m deep. </span>
<span id="cb42-1203"><a href="#cb42-1203" aria-hidden="true" tabindex="-1"></a>This seems ok. </span>
<span id="cb42-1204"><a href="#cb42-1204" aria-hidden="true" tabindex="-1"></a>But when we look at the prediction interval, we see that when we include uncertainty, </span>
<span id="cb42-1205"><a href="#cb42-1205" aria-hidden="true" tabindex="-1"></a>we are not even sure if they whale will dive below the surface by </span>
<span id="cb42-1206"><a href="#cb42-1206" aria-hidden="true" tabindex="-1"></a>2km or jump into the air by 1.3km. </span>
<span id="cb42-1207"><a href="#cb42-1207" aria-hidden="true" tabindex="-1"></a>When we include uncertainty, </span>
<span id="cb42-1208"><a href="#cb42-1208" aria-hidden="true" tabindex="-1"></a>it is clear that based on the current data and model, </span>
<span id="cb42-1209"><a href="#cb42-1209" aria-hidden="true" tabindex="-1"></a>we cannot say anything about the possible dive depth of the new whale. </span>
<span id="cb42-1210"><a href="#cb42-1210" aria-hidden="true" tabindex="-1"></a>We even get biologically unrealistic predictions. </span>
<span id="cb42-1211"><a href="#cb42-1211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1212"><a href="#cb42-1212" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1213"><a href="#cb42-1213" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1214"><a href="#cb42-1214" aria-hidden="true" tabindex="-1"></a>This is something we will look at in the next section.</span>
<span id="cb42-1215"><a href="#cb42-1215" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1216"><a href="#cb42-1216" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1217"><a href="#cb42-1217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1218"><a href="#cb42-1218" aria-hidden="true" tabindex="-1"></a><span class="fu">## &lt;i class="fas fa-tasks"&gt;&lt;/i&gt; Model checking {.tabset .tabset-fade}</span></span>
<span id="cb42-1219"><a href="#cb42-1219" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1220"><a href="#cb42-1220" aria-hidden="true" tabindex="-1"></a>You have now have a model, estimates of parameters, </span>
<span id="cb42-1221"><a href="#cb42-1221" aria-hidden="true" tabindex="-1"></a>and have calculated the uncertainty of the parameters. </span>
<span id="cb42-1222"><a href="#cb42-1222" aria-hidden="true" tabindex="-1"></a>**But how can we know if a model is any good?** </span>
<span id="cb42-1223"><a href="#cb42-1223" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1224"><a href="#cb42-1224" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1225"><a href="#cb42-1225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1226"><a href="#cb42-1226" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theory</span></span>
<span id="cb42-1227"><a href="#cb42-1227" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1228"><a href="#cb42-1228" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1229"><a href="#cb42-1229" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1230"><a href="#cb42-1230" aria-hidden="true" tabindex="-1"></a>To find out if the model is any good from a theoretical perspective, </span>
<span id="cb42-1231"><a href="#cb42-1231" aria-hidden="true" tabindex="-1"></a>you need to check if the model meets the </span>
<span id="cb42-1232"><a href="#cb42-1232" aria-hidden="true" tabindex="-1"></a>five assumptions of the linear regression that are stated </span>
<span id="cb42-1233"><a href="#cb42-1233" aria-hidden="true" tabindex="-1"></a>in the **Model details** section above. </span>
<span id="cb42-1234"><a href="#cb42-1234" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1235"><a href="#cb42-1235" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1236"><a href="#cb42-1236" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1237"><a href="#cb42-1237" aria-hidden="true" tabindex="-1"></a>For this, you can use graphs called **diagnostic plots**. </span>
<span id="cb42-1238"><a href="#cb42-1238" aria-hidden="true" tabindex="-1"></a>There are four key diagnostic plots that we use for simple linear regression </span>
<span id="cb42-1239"><a href="#cb42-1239" aria-hidden="true" tabindex="-1"></a>and each plot tests whether a different assumption has been met. </span>
<span id="cb42-1240"><a href="#cb42-1240" aria-hidden="true" tabindex="-1"></a>To make the diagnostic plots, you use the <span class="in">`plot()`</span> function with</span>
<span id="cb42-1241"><a href="#cb42-1241" aria-hidden="true" tabindex="-1"></a>our linear model object as the first argument and <span class="in">`which = number`</span> </span>
<span id="cb42-1242"><a href="#cb42-1242" aria-hidden="true" tabindex="-1"></a>as the second. </span>
<span id="cb42-1243"><a href="#cb42-1243" aria-hidden="true" tabindex="-1"></a>The number should be replaced by the number corresponding to the plot you want. </span>
<span id="cb42-1244"><a href="#cb42-1244" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1245"><a href="#cb42-1245" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1246"><a href="#cb42-1246" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1247"><a href="#cb42-1247" aria-hidden="true" tabindex="-1"></a>For more on what each plot means, go here: <span class="co">[</span><span class="ot">Model checking</span><span class="co">]()</span>. </span>
<span id="cb42-1248"><a href="#cb42-1248" aria-hidden="true" tabindex="-1"></a>On this page, you can find some example plots for a simple linear regression. </span>
<span id="cb42-1249"><a href="#cb42-1249" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1250"><a href="#cb42-1250" aria-hidden="true" tabindex="-1"></a>**Note:** for all of these plots, we do not expect perfection, especially for </span>
<span id="cb42-1251"><a href="#cb42-1251" aria-hidden="true" tabindex="-1"></a>biological data. </span>
<span id="cb42-1252"><a href="#cb42-1252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1253"><a href="#cb42-1253" aria-hidden="true" tabindex="-1"></a><span class="fu">#### 1. Residuals vs fitted plot</span></span>
<span id="cb42-1254"><a href="#cb42-1254" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1255"><a href="#cb42-1255" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1256"><a href="#cb42-1256" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1257"><a href="#cb42-1257" aria-hidden="true" tabindex="-1"></a>There are two examples of residuals vs fitted plots shown below. </span>
<span id="cb42-1258"><a href="#cb42-1258" aria-hidden="true" tabindex="-1"></a>If the assumptions are met, you can expect a few characteristics of the plot:</span>
<span id="cb42-1259"><a href="#cb42-1259" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1260"><a href="#cb42-1260" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The red line should be roughly horizontally straight and at 0</span>
<span id="cb42-1261"><a href="#cb42-1261" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>There should be no structure in the residuals</span>
<span id="cb42-1262"><a href="#cb42-1262" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The residuals should not curve</span>
<span id="cb42-1263"><a href="#cb42-1263" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1264"><a href="#cb42-1264" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1265"><a href="#cb42-1265" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1266"><a href="#cb42-1266" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-residuals-vs-fitted-fig, echo = FALSE, fig.cap="Example of a good (left) and a bad (right) residuals vs fitted plot for a simple linear regression"}</span></span>
<span id="cb42-1267"><a href="#cb42-1267" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1268"><a href="#cb42-1268" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb42-1269"><a href="#cb42-1269" aria-hidden="true" tabindex="-1"></a>example_data<span class="sc">$</span>a <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">100</span>,<span class="fu">as.numeric</span>(example_data<span class="sc">$</span>z)<span class="sc">^</span><span class="fl">1.2</span>)</span>
<span id="cb42-1270"><a href="#cb42-1270" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1271"><a href="#cb42-1271" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb42-1272"><a href="#cb42-1272" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1273"><a href="#cb42-1273" aria-hidden="true" tabindex="-1"></a>example_model1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(x <span class="sc">~</span> y, <span class="at">data =</span> example_data)</span>
<span id="cb42-1274"><a href="#cb42-1274" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model1, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb42-1275"><a href="#cb42-1275" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Good"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1276"><a href="#cb42-1276" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1277"><a href="#cb42-1277" aria-hidden="true" tabindex="-1"></a>example_model2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y <span class="sc">~</span> a, <span class="at">data =</span> example_data)</span>
<span id="cb42-1278"><a href="#cb42-1278" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model2, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb42-1279"><a href="#cb42-1279" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Bad"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1280"><a href="#cb42-1280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1281"><a href="#cb42-1281" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1282"><a href="#cb42-1282" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1283"><a href="#cb42-1283" aria-hidden="true" tabindex="-1"></a>**In reality, it will not be as clear cut as the examples above. </span>
<span id="cb42-1284"><a href="#cb42-1284" aria-hidden="true" tabindex="-1"></a>You will need to use</span>
<span id="cb42-1285"><a href="#cb42-1285" aria-hidden="true" tabindex="-1"></a>your own judgment to decide if the assumption is sufficiently met. </span>
<span id="cb42-1286"><a href="#cb42-1286" aria-hidden="true" tabindex="-1"></a>Do not expect perfection.**</span>
<span id="cb42-1287"><a href="#cb42-1287" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1288"><a href="#cb42-1288" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1289"><a href="#cb42-1289" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1290"><a href="#cb42-1290" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Normal QQ plot</span></span>
<span id="cb42-1291"><a href="#cb42-1291" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1292"><a href="#cb42-1292" aria-hidden="true" tabindex="-1"></a>There are two examples of normal QQ plots shown below. If the assumptions</span>
<span id="cb42-1293"><a href="#cb42-1293" aria-hidden="true" tabindex="-1"></a>are met, you can expect:</span>
<span id="cb42-1294"><a href="#cb42-1294" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1295"><a href="#cb42-1295" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The points to lie along the line</span>
<span id="cb42-1296"><a href="#cb42-1296" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1297"><a href="#cb42-1297" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1298"><a href="#cb42-1298" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1299"><a href="#cb42-1299" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-normal-qq, echo = FALSE, fig.cap="Example of a good (left) and a bad (right) normal QQ diagnostic plot"}</span></span>
<span id="cb42-1300"><a href="#cb42-1300" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1301"><a href="#cb42-1301" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb42-1302"><a href="#cb42-1302" aria-hidden="true" tabindex="-1"></a>example_data<span class="sc">$</span>b <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(example_data<span class="sc">$</span>z)<span class="sc">^</span><span class="dv">10</span></span>
<span id="cb42-1303"><a href="#cb42-1303" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1304"><a href="#cb42-1304" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb42-1305"><a href="#cb42-1305" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1306"><a href="#cb42-1306" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model1, <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb42-1307"><a href="#cb42-1307" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Good"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1308"><a href="#cb42-1308" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1309"><a href="#cb42-1309" aria-hidden="true" tabindex="-1"></a>example_model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(b<span class="sc">~</span>x, <span class="at">data=</span>example_data)</span>
<span id="cb42-1310"><a href="#cb42-1310" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model3, <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb42-1311"><a href="#cb42-1311" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Bad"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1312"><a href="#cb42-1312" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1313"><a href="#cb42-1313" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1314"><a href="#cb42-1314" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1315"><a href="#cb42-1315" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1316"><a href="#cb42-1316" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1317"><a href="#cb42-1317" aria-hidden="true" tabindex="-1"></a>**Notice that the y-axes have different values.**</span>
<span id="cb42-1318"><a href="#cb42-1318" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1319"><a href="#cb42-1319" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;br&gt;</span></span>
<span id="cb42-1320"><a href="#cb42-1320" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1321"><a href="#cb42-1321" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Scale-location</span></span>
<span id="cb42-1322"><a href="#cb42-1322" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1323"><a href="#cb42-1323" aria-hidden="true" tabindex="-1"></a>There are two examples of scale-leverage plots shown below. </span>
<span id="cb42-1324"><a href="#cb42-1324" aria-hidden="true" tabindex="-1"></a>If the assumptions are met, you can expect:</span>
<span id="cb42-1325"><a href="#cb42-1325" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1326"><a href="#cb42-1326" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>The red line to be horizontal</span>
<span id="cb42-1327"><a href="#cb42-1327" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>There is no structure in the points</span>
<span id="cb42-1328"><a href="#cb42-1328" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1329"><a href="#cb42-1329" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1330"><a href="#cb42-1330" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1331"><a href="#cb42-1331" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-scale-location, echo = FALSE, fig.cap = "Example of a good (left) and a bad (right) scale-location plot"}</span></span>
<span id="cb42-1332"><a href="#cb42-1332" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2020</span>)</span>
<span id="cb42-1333"><a href="#cb42-1333" aria-hidden="true" tabindex="-1"></a>example_data<span class="sc">$</span>b <span class="ot">&lt;-</span> <span class="fu">rpois</span>(<span class="dv">100</span>,<span class="fu">as.numeric</span>(example_data<span class="sc">$</span>z)<span class="sc">^</span><span class="dv">5</span>)</span>
<span id="cb42-1334"><a href="#cb42-1334" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1335"><a href="#cb42-1335" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb42-1336"><a href="#cb42-1336" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1337"><a href="#cb42-1337" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model1, <span class="at">which =</span> <span class="dv">3</span>)</span>
<span id="cb42-1338"><a href="#cb42-1338" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Good"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1339"><a href="#cb42-1339" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1340"><a href="#cb42-1340" aria-hidden="true" tabindex="-1"></a>example_model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(b<span class="sc">~</span>x, <span class="at">data=</span>example_data)</span>
<span id="cb42-1341"><a href="#cb42-1341" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model3, <span class="at">which =</span> <span class="dv">3</span>)</span>
<span id="cb42-1342"><a href="#cb42-1342" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Bad"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1343"><a href="#cb42-1343" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1344"><a href="#cb42-1344" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1345"><a href="#cb42-1345" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1346"><a href="#cb42-1346" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1347"><a href="#cb42-1347" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Cook's Distance</span></span>
<span id="cb42-1348"><a href="#cb42-1348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1349"><a href="#cb42-1349" aria-hidden="true" tabindex="-1"></a>There are two examples of Cook's Distance plots shown below. </span>
<span id="cb42-1350"><a href="#cb42-1350" aria-hidden="true" tabindex="-1"></a>If the assumptions are met, you can expect:</span>
<span id="cb42-1351"><a href="#cb42-1351" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1352"><a href="#cb42-1352" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Low values of Cook's Distance (y-axis) and no points standing out on their own</span>
<span id="cb42-1353"><a href="#cb42-1353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1354"><a href="#cb42-1354" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1355"><a href="#cb42-1355" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1356"><a href="#cb42-1356" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-cook-d, echo = FALSE, fig.cap = "Example of a good (left) and a bad (right) Cook's Distance plot"}</span></span>
<span id="cb42-1357"><a href="#cb42-1357" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1358"><a href="#cb42-1358" aria-hidden="true" tabindex="-1"></a>example_data<span class="sc">$</span>a <span class="ot">&lt;-</span> <span class="fu">c</span>(example_data<span class="sc">$</span>a[<span class="dv">1</span><span class="sc">:</span><span class="dv">98</span>], <span class="dv">1000</span>, <span class="dv">150</span>)</span>
<span id="cb42-1359"><a href="#cb42-1359" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1360"><a href="#cb42-1360" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))</span>
<span id="cb42-1361"><a href="#cb42-1361" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1362"><a href="#cb42-1362" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model1, <span class="at">which =</span> <span class="dv">4</span>)</span>
<span id="cb42-1363"><a href="#cb42-1363" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Good"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1364"><a href="#cb42-1364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1365"><a href="#cb42-1365" aria-hidden="true" tabindex="-1"></a>example_model3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(a<span class="sc">~</span>x, <span class="at">data=</span>example_data)</span>
<span id="cb42-1366"><a href="#cb42-1366" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(example_model3, <span class="at">which =</span> <span class="dv">4</span>)</span>
<span id="cb42-1367"><a href="#cb42-1367" aria-hidden="true" tabindex="-1"></a><span class="fu">title</span>(<span class="at">main=</span><span class="st">"Bad"</span>, <span class="at">line =</span> <span class="dv">1</span>)</span>
<span id="cb42-1368"><a href="#cb42-1368" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1369"><a href="#cb42-1369" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1370"><a href="#cb42-1370" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1371"><a href="#cb42-1371" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1372"><a href="#cb42-1372" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1373"><a href="#cb42-1373" aria-hidden="true" tabindex="-1"></a>**Notice that the y-axes have different values.**</span>
<span id="cb42-1374"><a href="#cb42-1374" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1375"><a href="#cb42-1375" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1376"><a href="#cb42-1376" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1377"><a href="#cb42-1377" aria-hidden="true" tabindex="-1"></a><span class="fu">### Worked example </span></span>
<span id="cb42-1378"><a href="#cb42-1378" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1379"><a href="#cb42-1379" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1380"><a href="#cb42-1380" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1381"><a href="#cb42-1381" aria-hidden="true" tabindex="-1"></a>Using the theory covered in the previous section, </span>
<span id="cb42-1382"><a href="#cb42-1382" aria-hidden="true" tabindex="-1"></a>we can now check our dive_model </span>
<span id="cb42-1383"><a href="#cb42-1383" aria-hidden="true" tabindex="-1"></a>to ensure that it meets the assumptions of a simple linear regression.</span>
<span id="cb42-1384"><a href="#cb42-1384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1385"><a href="#cb42-1385" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1386"><a href="#cb42-1386" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1387"><a href="#cb42-1387" aria-hidden="true" tabindex="-1"></a>We will use one plot at a time to test specific assumptions.</span>
<span id="cb42-1388"><a href="#cb42-1388" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1389"><a href="#cb42-1389" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1390"><a href="#cb42-1390" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1391"><a href="#cb42-1391" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Residuals vs fitted</span></span>
<span id="cb42-1392"><a href="#cb42-1392" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1395"><a href="#cb42-1395" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1396"><a href="#cb42-1396" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dive-residual</span></span>
<span id="cb42-1397"><a href="#cb42-1397" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-1398"><a href="#cb42-1398" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Residuals vs fitted plot for dive depths model"</span></span>
<span id="cb42-1399"><a href="#cb42-1399" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1400"><a href="#cb42-1400" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dive_model, <span class="at">which =</span> <span class="dv">1</span>)</span>
<span id="cb42-1401"><a href="#cb42-1401" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1402"><a href="#cb42-1402" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1403"><a href="#cb42-1403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1404"><a href="#cb42-1404" aria-hidden="true" tabindex="-1"></a> <span class="kw">&lt;/br&gt;</span> </span>
<span id="cb42-1405"><a href="#cb42-1405" aria-hidden="true" tabindex="-1"></a> </span>
<span id="cb42-1406"><a href="#cb42-1406" aria-hidden="true" tabindex="-1"></a>@fig-dive-residual looks quite unusual. </span>
<span id="cb42-1407"><a href="#cb42-1407" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1408"><a href="#cb42-1408" aria-hidden="true" tabindex="-1"></a>There are a few assumptions we are checking with this plot:</span>
<span id="cb42-1409"><a href="#cb42-1409" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1410"><a href="#cb42-1410" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Is the relationship between X and Y linear?** It does seem to be. </span>
<span id="cb42-1411"><a href="#cb42-1411" aria-hidden="true" tabindex="-1"></a>While the red line is not straight, </span>
<span id="cb42-1412"><a href="#cb42-1412" aria-hidden="true" tabindex="-1"></a>it does not show a clear pattern until the very end. </span>
<span id="cb42-1413"><a href="#cb42-1413" aria-hidden="true" tabindex="-1"></a>At the very end, there is a strong</span>
<span id="cb42-1414"><a href="#cb42-1414" aria-hidden="true" tabindex="-1"></a>negative trend. </span>
<span id="cb42-1415"><a href="#cb42-1415" aria-hidden="true" tabindex="-1"></a>We might need to come back to this! </span>
<span id="cb42-1416"><a href="#cb42-1416" aria-hidden="true" tabindex="-1"></a>It seems like there might be one pattern for shallow diving species </span>
<span id="cb42-1417"><a href="#cb42-1417" aria-hidden="true" tabindex="-1"></a>and another for the deep divers.</span>
<span id="cb42-1418"><a href="#cb42-1418" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Do the residuals have a mean of 0?** There is a deviation at fitted </span>
<span id="cb42-1419"><a href="#cb42-1419" aria-hidden="true" tabindex="-1"></a>values of &gt; 700, otherwise yes, the mean of the residuals is approximately 0. </span>
<span id="cb42-1420"><a href="#cb42-1420" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Is the variance of the residuals is equal for all fitted values (homoscedasticity)?** It is not the nice cloud of random points that we expect.</span>
<span id="cb42-1421"><a href="#cb42-1421" aria-hidden="true" tabindex="-1"></a>**But is it a problem?** To answer this, we need to look at bit closer. </span>
<span id="cb42-1422"><a href="#cb42-1422" aria-hidden="true" tabindex="-1"></a>The strange shape comes from the residuals at low fitted values, </span>
<span id="cb42-1423"><a href="#cb42-1423" aria-hidden="true" tabindex="-1"></a>these are the shallow diving marine mammals. </span>
<span id="cb42-1424"><a href="#cb42-1424" aria-hidden="true" tabindex="-1"></a>You might notice that there are very few of these values. </span>
<span id="cb42-1425"><a href="#cb42-1425" aria-hidden="true" tabindex="-1"></a>The majority of the data have fitted values &gt; 700. Where we have more data, the residuals vs fitted plot looks better. </span>
<span id="cb42-1426"><a href="#cb42-1426" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1427"><a href="#cb42-1427" aria-hidden="true" tabindex="-1"></a>At this point, it might be hard to say how problematic the low variance </span>
<span id="cb42-1428"><a href="#cb42-1428" aria-hidden="true" tabindex="-1"></a>caused by the lack of data for low fitted values is. </span>
<span id="cb42-1429"><a href="#cb42-1429" aria-hidden="true" tabindex="-1"></a>But, we can have a look at the points causing the pattern </span>
<span id="cb42-1430"><a href="#cb42-1430" aria-hidden="true" tabindex="-1"></a>(those with a maximum dive depth &lt; 600m).</span>
<span id="cb42-1431"><a href="#cb42-1431" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1432"><a href="#cb42-1432" aria-hidden="true" tabindex="-1"></a><span class="in">```{r dive-filter, echo = TRUE}</span></span>
<span id="cb42-1433"><a href="#cb42-1433" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1434"><a href="#cb42-1434" aria-hidden="true" tabindex="-1"></a><span class="fu">filter</span>(dive_data, max_depth <span class="sc">&lt;</span> <span class="dv">600</span>)</span>
<span id="cb42-1435"><a href="#cb42-1435" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1436"><a href="#cb42-1436" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1437"><a href="#cb42-1437" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1438"><a href="#cb42-1438" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1439"><a href="#cb42-1439" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1440"><a href="#cb42-1440" aria-hidden="true" tabindex="-1"></a>From these data, we can see that five of the six baleen whales (Group = Bwhale) </span>
<span id="cb42-1441"><a href="#cb42-1441" aria-hidden="true" tabindex="-1"></a>are included in this subset. </span>
<span id="cb42-1442"><a href="#cb42-1442" aria-hidden="true" tabindex="-1"></a>This is quite interesting. </span>
<span id="cb42-1443"><a href="#cb42-1443" aria-hidden="true" tabindex="-1"></a>It could be biologically reasonable that these whales follow a </span>
<span id="cb42-1444"><a href="#cb42-1444" aria-hidden="true" tabindex="-1"></a>different pattern to the other species because their physiology is </span>
<span id="cb42-1445"><a href="#cb42-1445" aria-hidden="true" tabindex="-1"></a>very different. </span>
<span id="cb42-1446"><a href="#cb42-1446" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1447"><a href="#cb42-1447" aria-hidden="true" tabindex="-1"></a>**Keep that last point in mind when we get on to interpreting the results.**</span>
<span id="cb42-1448"><a href="#cb42-1448" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1449"><a href="#cb42-1449" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Normal QQ</span></span>
<span id="cb42-1450"><a href="#cb42-1450" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1451"><a href="#cb42-1451" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-dive-qq, echo = TRUE, fig.cap="Normal QQ plot for dive depth model"}</span></span>
<span id="cb42-1452"><a href="#cb42-1452" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1453"><a href="#cb42-1453" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dive_model, <span class="at">which =</span> <span class="dv">2</span>)</span>
<span id="cb42-1454"><a href="#cb42-1454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1455"><a href="#cb42-1455" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1456"><a href="#cb42-1456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1457"><a href="#cb42-1457" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span> </span>
<span id="cb42-1458"><a href="#cb42-1458" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1459"><a href="#cb42-1459" aria-hidden="true" tabindex="-1"></a>The assumption we are checking with this plot is: </span>
<span id="cb42-1460"><a href="#cb42-1460" aria-hidden="true" tabindex="-1"></a>**are the residuals are normally distributed?**</span>
<span id="cb42-1461"><a href="#cb42-1461" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1462"><a href="#cb42-1462" aria-hidden="true" tabindex="-1"></a>As expected, </span>
<span id="cb42-1463"><a href="#cb42-1463" aria-hidden="true" tabindex="-1"></a>there is not a perfect match between the theoretical normal distribution and</span>
<span id="cb42-1464"><a href="#cb42-1464" aria-hidden="true" tabindex="-1"></a>the distribution of the residuals. </span>
<span id="cb42-1465"><a href="#cb42-1465" aria-hidden="true" tabindex="-1"></a>There is some deviation at both tails of the distribution. </span>
<span id="cb42-1466"><a href="#cb42-1466" aria-hidden="true" tabindex="-1"></a>At lower quantiles, this seems ok. </span>
<span id="cb42-1467"><a href="#cb42-1467" aria-hidden="true" tabindex="-1"></a>At higher values, points 9 and 10 deviate quite a lot. </span>
<span id="cb42-1468"><a href="#cb42-1468" aria-hidden="true" tabindex="-1"></a>These points also stood out in @fig-dive-residual. </span>
<span id="cb42-1469"><a href="#cb42-1469" aria-hidden="true" tabindex="-1"></a>We will need to look into them more in @fig-dive-cook-d. </span>
<span id="cb42-1470"><a href="#cb42-1470" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1471"><a href="#cb42-1471" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1472"><a href="#cb42-1472" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1473"><a href="#cb42-1473" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Scale-location</span></span>
<span id="cb42-1474"><a href="#cb42-1474" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1475"><a href="#cb42-1475" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-dive-scale, echo = TRUE, fig.cap="Scale-location plot for dive depth model"}</span></span>
<span id="cb42-1476"><a href="#cb42-1476" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1477"><a href="#cb42-1477" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dive_model, <span class="at">which =</span> <span class="dv">3</span>)</span>
<span id="cb42-1478"><a href="#cb42-1478" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1479"><a href="#cb42-1479" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1480"><a href="#cb42-1480" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1481"><a href="#cb42-1481" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span> </span>
<span id="cb42-1482"><a href="#cb42-1482" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1483"><a href="#cb42-1483" aria-hidden="true" tabindex="-1"></a>The assumption we are checking with this plot is: </span>
<span id="cb42-1484"><a href="#cb42-1484" aria-hidden="true" tabindex="-1"></a>**Do the residuals have equal variance across fitted values?**</span>
<span id="cb42-1485"><a href="#cb42-1485" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1486"><a href="#cb42-1486" aria-hidden="true" tabindex="-1"></a>@fig-fig-14 shows a very similar picture to @fig-fig-12. </span>
<span id="cb42-1487"><a href="#cb42-1487" aria-hidden="true" tabindex="-1"></a>While there is a slight increase in variance as the amount of data increases, </span>
<span id="cb42-1488"><a href="#cb42-1488" aria-hidden="true" tabindex="-1"></a>the amount of change is &lt; 0.5 and there is not much structure in the points. </span>
<span id="cb42-1489"><a href="#cb42-1489" aria-hidden="true" tabindex="-1"></a>So, this looks like things are ok.</span>
<span id="cb42-1490"><a href="#cb42-1490" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1491"><a href="#cb42-1491" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1492"><a href="#cb42-1492" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1493"><a href="#cb42-1493" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Cook's distance</span></span>
<span id="cb42-1494"><a href="#cb42-1494" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1497"><a href="#cb42-1497" aria-hidden="true" tabindex="-1"></a><span class="in">```{r}</span></span>
<span id="cb42-1498"><a href="#cb42-1498" aria-hidden="true" tabindex="-1"></a><span class="co">#| label: fig-dive-cook-d</span></span>
<span id="cb42-1499"><a href="#cb42-1499" aria-hidden="true" tabindex="-1"></a><span class="co">#| echo: true</span></span>
<span id="cb42-1500"><a href="#cb42-1500" aria-hidden="true" tabindex="-1"></a><span class="co">#| fig-cap: "Cook's distance plot for the dive depth model"</span></span>
<span id="cb42-1501"><a href="#cb42-1501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1502"><a href="#cb42-1502" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(dive_model, <span class="at">which =</span> <span class="dv">4</span>)</span>
<span id="cb42-1503"><a href="#cb42-1503" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1504"><a href="#cb42-1504" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1505"><a href="#cb42-1505" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1506"><a href="#cb42-1506" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span> </span>
<span id="cb42-1507"><a href="#cb42-1507" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1508"><a href="#cb42-1508" aria-hidden="true" tabindex="-1"></a>The assumption we are checking with this plot is: **Are there any outliers?**</span>
<span id="cb42-1509"><a href="#cb42-1509" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1510"><a href="#cb42-1510" aria-hidden="true" tabindex="-1"></a>@fig-dive-cook-d shows that the Cook's distances of this model are not </span>
<span id="cb42-1511"><a href="#cb42-1511" aria-hidden="true" tabindex="-1"></a>very high (max = 0.2).</span>
<span id="cb42-1512"><a href="#cb42-1512" aria-hidden="true" tabindex="-1"></a>So, it does not seem that any points have that large an influence on the </span>
<span id="cb42-1513"><a href="#cb42-1513" aria-hidden="true" tabindex="-1"></a>fitted values.</span>
<span id="cb42-1514"><a href="#cb42-1514" aria-hidden="true" tabindex="-1"></a>However, point 10 does seem to be quite different from the others. </span>
<span id="cb42-1515"><a href="#cb42-1515" aria-hidden="true" tabindex="-1"></a>This might be worth </span>
<span id="cb42-1516"><a href="#cb42-1516" aria-hidden="true" tabindex="-1"></a>looking into.</span>
<span id="cb42-1517"><a href="#cb42-1517" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1518"><a href="#cb42-1518" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1519"><a href="#cb42-1519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1520"><a href="#cb42-1520" aria-hidden="true" tabindex="-1"></a>We can find point 10 by looking at the 10th row of our data frame. </span>
<span id="cb42-1521"><a href="#cb42-1521" aria-hidden="true" tabindex="-1"></a>It is the entry for the Cuvier's beaked whale. </span>
<span id="cb42-1522"><a href="#cb42-1522" aria-hidden="true" tabindex="-1"></a>While this is a rare and unusual whale, it is not the only beaked whale in </span>
<span id="cb42-1523"><a href="#cb42-1523" aria-hidden="true" tabindex="-1"></a>our dataset and we have no reason to believe this data is a typo. </span>
<span id="cb42-1524"><a href="#cb42-1524" aria-hidden="true" tabindex="-1"></a>**Therefore, we would not consider this an outlier and </span>
<span id="cb42-1525"><a href="#cb42-1525" aria-hidden="true" tabindex="-1"></a>would not remove from the data.**</span>
<span id="cb42-1526"><a href="#cb42-1526" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1527"><a href="#cb42-1527" aria-hidden="true" tabindex="-1"></a><span class="in">```{r cuvier, echo = TRUE}</span></span>
<span id="cb42-1528"><a href="#cb42-1528" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1529"><a href="#cb42-1529" aria-hidden="true" tabindex="-1"></a>dive_data <span class="sc">%&gt;%</span> <span class="fu">slice</span>(<span class="dv">10</span>)</span>
<span id="cb42-1530"><a href="#cb42-1530" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1531"><a href="#cb42-1531" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1532"><a href="#cb42-1532" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1533"><a href="#cb42-1533" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1534"><a href="#cb42-1534" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1535"><a href="#cb42-1535" aria-hidden="true" tabindex="-1"></a><span class="fu">#### Summary</span></span>
<span id="cb42-1536"><a href="#cb42-1536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1537"><a href="#cb42-1537" aria-hidden="true" tabindex="-1"></a>Overall, it seems that most of the model assumptions are met well. </span>
<span id="cb42-1538"><a href="#cb42-1538" aria-hidden="true" tabindex="-1"></a>The only red flag is in the equal variance assumption. </span>
<span id="cb42-1539"><a href="#cb42-1539" aria-hidden="true" tabindex="-1"></a>However, this seems to be caused in part by a lower amount of </span>
<span id="cb42-1540"><a href="#cb42-1540" aria-hidden="true" tabindex="-1"></a>data available at the extremes of dive depths. </span>
<span id="cb42-1541"><a href="#cb42-1541" aria-hidden="true" tabindex="-1"></a>Therefore, we think it is ok to proceed with this model.</span>
<span id="cb42-1542"><a href="#cb42-1542" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1543"><a href="#cb42-1543" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1544"><a href="#cb42-1544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1545"><a href="#cb42-1545" aria-hidden="true" tabindex="-1"></a>In the next section we will interpret our results.</span>
<span id="cb42-1546"><a href="#cb42-1546" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1547"><a href="#cb42-1547" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1548"><a href="#cb42-1548" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1549"><a href="#cb42-1549" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1550"><a href="#cb42-1550" aria-hidden="true" tabindex="-1"></a><span class="fu">## &lt;i class="far fa-lightbulb"&gt;&lt;/i&gt; Draw conclusions {.tabset .tabset-fade}</span></span>
<span id="cb42-1551"><a href="#cb42-1551" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1552"><a href="#cb42-1552" aria-hidden="true" tabindex="-1"></a><span class="fu">### Theory</span></span>
<span id="cb42-1553"><a href="#cb42-1553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1554"><a href="#cb42-1554" aria-hidden="true" tabindex="-1"></a>In the previous sections you learned how to run a simple </span>
<span id="cb42-1555"><a href="#cb42-1555" aria-hidden="true" tabindex="-1"></a>linear regression models,</span>
<span id="cb42-1556"><a href="#cb42-1556" aria-hidden="true" tabindex="-1"></a>what the parameters of the model mean, </span>
<span id="cb42-1557"><a href="#cb42-1557" aria-hidden="true" tabindex="-1"></a>how to quantify uncertainty in the parameters, and </span>
<span id="cb42-1558"><a href="#cb42-1558" aria-hidden="true" tabindex="-1"></a>how to check the assumptions of the model. </span>
<span id="cb42-1559"><a href="#cb42-1559" aria-hidden="true" tabindex="-1"></a>Now, you can bring everything together to draw some conclusions. </span>
<span id="cb42-1560"><a href="#cb42-1560" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1561"><a href="#cb42-1561" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1562"><a href="#cb42-1562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1563"><a href="#cb42-1563" aria-hidden="true" tabindex="-1"></a>There are several components required in drawing a conclusion:</span>
<span id="cb42-1564"><a href="#cb42-1564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1565"><a href="#cb42-1565" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>statement of the maximum likelihood estimate of the parameters of </span>
<span id="cb42-1566"><a href="#cb42-1566" aria-hidden="true" tabindex="-1"></a>interest (including strength and direction)</span>
<span id="cb42-1567"><a href="#cb42-1567" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>statement of the uncertainty in the estimate</span>
<span id="cb42-1568"><a href="#cb42-1568" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>statement of how good the model is i.e. </span>
<span id="cb42-1569"><a href="#cb42-1569" aria-hidden="true" tabindex="-1"></a>how well the model meets assumptions and the amount of variance explained </span>
<span id="cb42-1570"><a href="#cb42-1570" aria-hidden="true" tabindex="-1"></a>(using $R^2$ - explained below)</span>
<span id="cb42-1571"><a href="#cb42-1571" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>link the results to biology and the question asked</span>
<span id="cb42-1572"><a href="#cb42-1572" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>Discussion of next directions</span>
<span id="cb42-1573"><a href="#cb42-1573" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1574"><a href="#cb42-1574" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1575"><a href="#cb42-1575" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1576"><a href="#cb42-1576" aria-hidden="true" tabindex="-1"></a>One measure that can be useful for conclusions is to know </span>
<span id="cb42-1577"><a href="#cb42-1577" aria-hidden="true" tabindex="-1"></a>**how much of the variation in $Y$ is explained by $X$**. </span>
<span id="cb42-1578"><a href="#cb42-1578" aria-hidden="true" tabindex="-1"></a>To answer this you can use a measure called the $R^2$. </span>
<span id="cb42-1579"><a href="#cb42-1579" aria-hidden="true" tabindex="-1"></a>It is calculated using the following equation:</span>
<span id="cb42-1580"><a href="#cb42-1580" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1581"><a href="#cb42-1581" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1582"><a href="#cb42-1582" aria-hidden="true" tabindex="-1"></a>R^2 = 1 - \frac{\color{darkblue}{\text{Residual Variance}} }{\text{Total Variance}}</span>
<span id="cb42-1583"><a href="#cb42-1583" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb42-1584"><a href="#cb42-1584" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1585"><a href="#cb42-1585" aria-hidden="true" tabindex="-1"></a>and can be found in R using <span class="in">`summary(your_model)$r.squared`</span>. </span>
<span id="cb42-1586"><a href="#cb42-1586" aria-hidden="true" tabindex="-1"></a>The value is a proportion, </span>
<span id="cb42-1587"><a href="#cb42-1587" aria-hidden="true" tabindex="-1"></a>so between 0 (no variance explained) and 1 (all variance explained). </span>
<span id="cb42-1588"><a href="#cb42-1588" aria-hidden="true" tabindex="-1"></a>A good value is subjective, but &gt; 0.5 is usually considered good, &gt; 0.7 </span>
<span id="cb42-1589"><a href="#cb42-1589" aria-hidden="true" tabindex="-1"></a>is very good and a value of 1 is suspicious. For biological data, achieving an </span>
<span id="cb42-1590"><a href="#cb42-1590" aria-hidden="true" tabindex="-1"></a>$R^{2}$ of 0.5 or higher can be challenging because in the real world there are</span>
<span id="cb42-1591"><a href="#cb42-1591" aria-hidden="true" tabindex="-1"></a>lots of variables influencing each response, more than we could measure and </span>
<span id="cb42-1592"><a href="#cb42-1592" aria-hidden="true" tabindex="-1"></a>include in an analysis. In these cases, $R^{2}$ could be as low as e.g. 0.3 or</span>
<span id="cb42-1593"><a href="#cb42-1593" aria-hidden="true" tabindex="-1"></a>0.1,</span>
<span id="cb42-1594"><a href="#cb42-1594" aria-hidden="true" tabindex="-1"></a>but this does not mean the model is not valid. It only means that other </span>
<span id="cb42-1595"><a href="#cb42-1595" aria-hidden="true" tabindex="-1"></a>processes are causing variation in the response on top of those included in the</span>
<span id="cb42-1596"><a href="#cb42-1596" aria-hidden="true" tabindex="-1"></a>model. </span>
<span id="cb42-1597"><a href="#cb42-1597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1598"><a href="#cb42-1598" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1599"><a href="#cb42-1599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1600"><a href="#cb42-1600" aria-hidden="true" tabindex="-1"></a><span class="fu">### Worked example </span></span>
<span id="cb42-1601"><a href="#cb42-1601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1602"><a href="#cb42-1602" aria-hidden="true" tabindex="-1"></a>This is the final section of our analysis of the data on marine mammal </span>
<span id="cb42-1603"><a href="#cb42-1603" aria-hidden="true" tabindex="-1"></a>maximum dive depths. </span>
<span id="cb42-1604"><a href="#cb42-1604" aria-hidden="true" tabindex="-1"></a>We will now bring together all of the results we have obtained and </span>
<span id="cb42-1605"><a href="#cb42-1605" aria-hidden="true" tabindex="-1"></a>draw a conclusion following the same format as in the theory section.</span>
<span id="cb42-1606"><a href="#cb42-1606" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1607"><a href="#cb42-1607" aria-hidden="true" tabindex="-1"></a>A reminder, we were asking: </span>
<span id="cb42-1608"><a href="#cb42-1608" aria-hidden="true" tabindex="-1"></a>**Does body size influence maximum dive depth in marine mammals?**</span>
<span id="cb42-1609"><a href="#cb42-1609" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1610"><a href="#cb42-1610" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1611"><a href="#cb42-1611" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1612"><a href="#cb42-1612" aria-hidden="true" tabindex="-1"></a>The maximum likelihood estimate of the relationship between body size and </span>
<span id="cb42-1613"><a href="#cb42-1613" aria-hidden="true" tabindex="-1"></a>maximum dive depth in marine mammals was -0.005. </span>
<span id="cb42-1614"><a href="#cb42-1614" aria-hidden="true" tabindex="-1"></a>In other words, for every 1 kg increase in body weight, </span>
<span id="cb42-1615"><a href="#cb42-1615" aria-hidden="true" tabindex="-1"></a>marine mammals dived 0.005 m less deep. </span>
<span id="cb42-1616"><a href="#cb42-1616" aria-hidden="true" tabindex="-1"></a>Given that some marine mammals can dive 1000s of metres, </span>
<span id="cb42-1617"><a href="#cb42-1617" aria-hidden="true" tabindex="-1"></a>this increase per kg is very low. </span>
<span id="cb42-1618"><a href="#cb42-1618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1619"><a href="#cb42-1619" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1620"><a href="#cb42-1620" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1621"><a href="#cb42-1621" aria-hidden="true" tabindex="-1"></a>When we look at the uncertainty in this estimate, </span>
<span id="cb42-1622"><a href="#cb42-1622" aria-hidden="true" tabindex="-1"></a>we see the 95% confidence interval is -0.017 to 0.006. </span>
<span id="cb42-1623"><a href="#cb42-1623" aria-hidden="true" tabindex="-1"></a>The confidence interval limits are different signs, </span>
<span id="cb42-1624"><a href="#cb42-1624" aria-hidden="true" tabindex="-1"></a>meaning that 0 is included as a plausible value for the strength of the </span>
<span id="cb42-1625"><a href="#cb42-1625" aria-hidden="true" tabindex="-1"></a>relationship. </span>
<span id="cb42-1626"><a href="#cb42-1626" aria-hidden="true" tabindex="-1"></a>Therefore, we cannot conclude that body size has any impact on maximum </span>
<span id="cb42-1627"><a href="#cb42-1627" aria-hidden="true" tabindex="-1"></a>dive depth in marine mammals. </span>
<span id="cb42-1628"><a href="#cb42-1628" aria-hidden="true" tabindex="-1"></a>This is supported by the $R^2$ value, which is 0.03, </span>
<span id="cb42-1629"><a href="#cb42-1629" aria-hidden="true" tabindex="-1"></a>suggesting only 3% of the variation in maximum dive depth is </span>
<span id="cb42-1630"><a href="#cb42-1630" aria-hidden="true" tabindex="-1"></a>explained by body size. This is a good example of the lower $R^2$ we often get</span>
<span id="cb42-1631"><a href="#cb42-1631" aria-hidden="true" tabindex="-1"></a>in biology. </span>
<span id="cb42-1632"><a href="#cb42-1632" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1633"><a href="#cb42-1633" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span> </span>
<span id="cb42-1634"><a href="#cb42-1634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1635"><a href="#cb42-1635" aria-hidden="true" tabindex="-1"></a>We should remember here, </span>
<span id="cb42-1636"><a href="#cb42-1636" aria-hidden="true" tabindex="-1"></a>that when we predicted a dive depth for the fictional whale, </span>
<span id="cb42-1637"><a href="#cb42-1637" aria-hidden="true" tabindex="-1"></a>it gave us a negative result. </span>
<span id="cb42-1638"><a href="#cb42-1638" aria-hidden="true" tabindex="-1"></a>Linear models fit a straight line, </span>
<span id="cb42-1639"><a href="#cb42-1639" aria-hidden="true" tabindex="-1"></a>which can extend beyond the realistic values for some variables. </span>
<span id="cb42-1640"><a href="#cb42-1640" aria-hidden="true" tabindex="-1"></a>This should be noted and predictions should not be made outside of values </span>
<span id="cb42-1641"><a href="#cb42-1641" aria-hidden="true" tabindex="-1"></a>that are plausible. </span>
<span id="cb42-1642"><a href="#cb42-1642" aria-hidden="true" tabindex="-1"></a>This is one reason why predicting outside of the range of your data </span>
<span id="cb42-1643"><a href="#cb42-1643" aria-hidden="true" tabindex="-1"></a>can be problematic. We can also fit models that are not linear, </span>
<span id="cb42-1644"><a href="#cb42-1644" aria-hidden="true" tabindex="-1"></a>there is more on those <span class="co">[</span><span class="ot">here</span><span class="co">](link to GLMs)</span>.</span>
<span id="cb42-1645"><a href="#cb42-1645" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1646"><a href="#cb42-1646" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1647"><a href="#cb42-1647" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1648"><a href="#cb42-1648" aria-hidden="true" tabindex="-1"></a>In model checking, there was an interesting pattern shown, </span>
<span id="cb42-1649"><a href="#cb42-1649" aria-hidden="true" tabindex="-1"></a>of little data at the lowest maximum dive depths and a </span>
<span id="cb42-1650"><a href="#cb42-1650" aria-hidden="true" tabindex="-1"></a>disproportionate representation of baleen whales. </span>
<span id="cb42-1651"><a href="#cb42-1651" aria-hidden="true" tabindex="-1"></a>If we plot the data by group and allow ggplot to fit a regression </span>
<span id="cb42-1652"><a href="#cb42-1652" aria-hidden="true" tabindex="-1"></a>line per group, we can see that there seems to be a different pattern for </span>
<span id="cb42-1653"><a href="#cb42-1653" aria-hidden="true" tabindex="-1"></a>different taxonomic groups. </span>
<span id="cb42-1654"><a href="#cb42-1654" aria-hidden="true" tabindex="-1"></a>This would make sense based on physiology and might explain why the </span>
<span id="cb42-1655"><a href="#cb42-1655" aria-hidden="true" tabindex="-1"></a>variance assumption was not met well AND why the estimated relationship </span>
<span id="cb42-1656"><a href="#cb42-1656" aria-hidden="true" tabindex="-1"></a>was so weak. </span>
<span id="cb42-1657"><a href="#cb42-1657" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1658"><a href="#cb42-1658" aria-hidden="true" tabindex="-1"></a><span class="in">```{r make-final-dive-fig, echo = TRUE}</span></span>
<span id="cb42-1659"><a href="#cb42-1659" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1660"><a href="#cb42-1660" aria-hidden="true" tabindex="-1"></a>final_dive_fig<span class="ot">&lt;-</span> <span class="fu">ggplot</span>(dive_data, <span class="fu">aes</span>(<span class="at">x=</span>body_size_kg, <span class="at">y=</span>max_depth, <span class="at">color=</span>group))<span class="sc">+</span></span>
<span id="cb42-1661"><a href="#cb42-1661" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()<span class="sc">+</span></span>
<span id="cb42-1662"><a href="#cb42-1662" aria-hidden="true" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(.<span class="sc">~</span>group)<span class="sc">+</span></span>
<span id="cb42-1663"><a href="#cb42-1663" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method=</span><span class="st">'lm'</span>)</span>
<span id="cb42-1664"><a href="#cb42-1664" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1665"><a href="#cb42-1665" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1666"><a href="#cb42-1666" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1667"><a href="#cb42-1667" aria-hidden="true" tabindex="-1"></a><span class="in">```{r fig-final-dive, include = TRUE, echo = FALSE, fig.cap = "Plot of the relationship between dive depth and body size faceted by taxonomic group"}</span></span>
<span id="cb42-1668"><a href="#cb42-1668" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1669"><a href="#cb42-1669" aria-hidden="true" tabindex="-1"></a>final_dive_fig</span>
<span id="cb42-1670"><a href="#cb42-1670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1671"><a href="#cb42-1671" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb42-1672"><a href="#cb42-1672" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1673"><a href="#cb42-1673" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb42-1674"><a href="#cb42-1674" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1675"><a href="#cb42-1675" aria-hidden="true" tabindex="-1"></a>While the baleen whales show no relationship between dive depth and body size, </span>
<span id="cb42-1676"><a href="#cb42-1676" aria-hidden="true" tabindex="-1"></a>both the pinnipeds (seals and sea lions) and the toothed whales (orca, dolphins, porpoises) show quite strong positive relationships between dive depth and </span>
<span id="cb42-1677"><a href="#cb42-1677" aria-hidden="true" tabindex="-1"></a>body size. </span>
<span id="cb42-1678"><a href="#cb42-1678" aria-hidden="true" tabindex="-1"></a>By treating all groups as the same in one analysis, </span>
<span id="cb42-1679"><a href="#cb42-1679" aria-hidden="true" tabindex="-1"></a>we might have been masking the true effects. </span>
<span id="cb42-1680"><a href="#cb42-1680" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1681"><a href="#cb42-1681" aria-hidden="true" tabindex="-1"></a>It might be more appropriate to consider an effect of Group as well as body </span>
<span id="cb42-1682"><a href="#cb42-1682" aria-hidden="true" tabindex="-1"></a>size. We can do this using **Linear models for categorical explanatory variables**/**ANOVA**, </span>
<span id="cb42-1683"><a href="#cb42-1683" aria-hidden="true" tabindex="-1"></a>check out these pages to continue the analysis of this data.</span>
<span id="cb42-1684"><a href="#cb42-1684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1685"><a href="#cb42-1685" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb42-1686"><a href="#cb42-1686" aria-hidden="true" tabindex="-1"></a><span class="fu">## What's next</span></span>
<span id="cb42-1687"><a href="#cb42-1687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1688"><a href="#cb42-1688" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Linear models for categorical explanatory variables**/**ANOVA** </span>
<span id="cb42-1689"><a href="#cb42-1689" aria-hidden="true" tabindex="-1"></a>for analyses when your explanatory variable is not numeric</span>
<span id="cb42-1690"><a href="#cb42-1690" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Multiple regression** for analyses with more than one numeric </span>
<span id="cb42-1691"><a href="#cb42-1691" aria-hidden="true" tabindex="-1"></a>explanatory variable</span>
<span id="cb42-1692"><a href="#cb42-1692" aria-hidden="true" tabindex="-1"></a><span class="ss">* </span>**Generalised linear models** for analyses when your response variable is not </span>
<span id="cb42-1693"><a href="#cb42-1693" aria-hidden="true" tabindex="-1"></a>normally distributed</span>
<span id="cb42-1694"><a href="#cb42-1694" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-1695"><a href="#cb42-1695" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1696"><a href="#cb42-1696" aria-hidden="true" tabindex="-1"></a>::: callout-note</span>
<span id="cb42-1697"><a href="#cb42-1697" aria-hidden="true" tabindex="-1"></a><span class="fu">## Further reading</span></span>
<span id="cb42-1698"><a href="#cb42-1698" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1699"><a href="#cb42-1699" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-1700"><a href="#cb42-1700" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1701"><a href="#cb42-1701" aria-hidden="true" tabindex="-1"></a>::: {.column-margin}</span>
<span id="cb42-1702"><a href="#cb42-1702" aria-hidden="true" tabindex="-1"></a><span class="fu">### Contributors {.unlisted .unnumbered}</span></span>
<span id="cb42-1703"><a href="#cb42-1703" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1704"><a href="#cb42-1704" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Emily G Simmonds</span>
<span id="cb42-1705"><a href="#cb42-1705" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb42-1706"><a href="#cb42-1706" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-1707"><a href="#cb42-1707" aria-hidden="true" tabindex="-1"></a></span>
</code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>