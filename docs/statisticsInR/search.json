[
  {
    "objectID": "2.2_descriptive_statistics.html",
    "href": "2.2_descriptive_statistics.html",
    "title": "\n2  Descriptive Statistics\n",
    "section": "",
    "text": "Before you start\n\n\n\nYou should be familiar with basic statistical theory and the basics of R."
  },
  {
    "objectID": "2.2_descriptive_statistics.html#introduction",
    "href": "2.2_descriptive_statistics.html#introduction",
    "title": "\n2  Descriptive Statistics\n",
    "section": "\n2.1 Introduction",
    "text": "2.1 Introduction\nYou are interested in the heights of plants in an alpine meadow.\n\n\nPhoto credit: Joshua Lynn\n\n\nYou have measured the heights of five of the plant species, entered the values (in cm) into the below table, and now you want to summarize the plant heights for the meadow. Notice that the one tree species, Juniper communis, is much taller than the other species in this meadow.\n\n\n\n\n\n              Species Height\n1    Juniper communis    200\n2         Betula nana     50\n3 Vaccinium myrtillus     15\n4       Festuca rubra     20\n5     Veronica alpina     10\n\n\nDescriptive statistics summarize or characterize a given sample and are the foundation of statistical tests and data visualizations. In this section, we will define a number of descriptive statistics and learn how to calculate them in R using our plant height sample from the above meadow.\n\n\n2.1.1 Mean\nTo start, we will describe our height data by its mean (or average), which is the most commonly used measure of central tendency of a sample (in our case - height). A measure of central tendency describes a typical value within a sample. The mean is often called the average and is one of the measures of the central tendency of your sample. The mean is the sum of all the values in your sample divided by the number of values in the sample set. Mathematically described as:\n\\[\\overline{x} = \\frac{\\sum_{i=1}^n x_i}{n}\\]\nWhere \\(\\overline{x}\\) is the mean of the sample equal to the sum (\\(\\sum\\)) of all observations, i, divided by the total number of observations, n.\nIn R, the function that calculates the mean is called mean(). We will first look at our height data and the use the mean() function to find the value for our data:\n\nhead(height_data) # we use `head()` to look at our data set already loaded into R\n\n              Species Height\n1    Juniper communis    200\n2         Betula nana     50\n3 Vaccinium myrtillus     15\n4       Festuca rubra     20\n5     Veronica alpina     10\n\nmean(height_data$Height) # then we use the `mean()` function to calculate the mean for our height sample\n\n[1] 59\n\n\nAnd so, we have a mean of 59 cm for the height of our five plant species. But notice how the mean is higher than 4 of the species. It seems reasonable to ask: in this case, is the mean an accurate representation of the samples central tendency?\n\n\n2.1.2 Median\nThe median is another measure of the central tendency of your sample. The median is the number “in the middle” of the sample, or, the middle value of a series of values sorted from smallest to largest. Given that the median only considers the middle of value, it may more accurately estimate a samples central tendency by not putting as much weight on outliers, or values that very are different from the rest of the sample.\nProvided that the sample contains an odd number n of entries, the median is the value of the \\((\\frac{(n+1)}{2})\\) entry in the sample. If the sample contains an even number n of entries, then the median is the mean of the values of the \\((\\frac{n}{2})\\) and the \\((\\frac{n}{2} + 1)\\) entries.\nIn R, the function that calculates the median is called median():\n\nmedian(height_data$Height) # takes the median of the height data\n\n[1] 20\n\n\nAbove, we have the median height of our odd numbered sample. Let’s say we go back to our meadow and measure the height of a new species, Viola biflora. Now our sample has six entries. How does that change the median?\n\nhead(height_data2) # we use `head()` to look at our new data set already loaded into R \n\n              Species Height\n1    Juniper communis    200\n2         Betula nana     50\n3 Vaccinium myrtillus     15\n4       Festuca rubra     20\n5     Veronica alpina     10\n6       Viola biflora     10\n\nmedian(height_data2$Height) # takes the median\n\n[1] 17.5\n\n\nWe see that the median of the even sample is between the two middle values in the data, 15 and 20.\n\n\n2.1.3 3. Minimum, maximum, range, midpoint, and mode\nThe minimum and maximum of a sample are the smallest and largest entries, respectively.\nIn R, the functions that calculate the minimum and maximum are called min() and max(), respectively:\n\nmin(height_data2$Height) # find the minimum\n\n[1] 10\n\nmax(height_data2$Height) # find the maximum\n\n[1] 200\n\n\nWe see that min() picked out the height of the shortest species in our data (Veronica alpina and Viola biflora) and max() picked out the height of the tallest species (Juniper communis).\nThe range defines the spread of the data and is the difference between the minimum and maximum values. Note, a range may be expressed as a single value (the actual difference between maximum and minimum) or by writing minimum-maximum. For instance, the range of the series (1, 2, 3, 4, 5, 6, 7, 8, 9, 10) can be expressed as 9 or 1-10.\nIn R, the function that calculates the range is range(). However, range() returns a vector that contains the minimum and the maximum, respectively. To calculate the difference between these values, you may use diff(range()) or max()-min():\n\nrange(height_data2$Height) # find the range of the sample as a vector\n\n[1]  10 200\n\ndiff(range(height_data2$Height)) # find the range as difference between minimum and maximum values with diff()\n\n[1] 190\n\nmax(height_data2$Height)-min(height_data2$Height) # find the range as difference between minimum and maximum values\n\n[1] 190\n\n\nWe see that the range() returns our minimum and maximum height values, while the other two functions return the difference between the minumum and and maximum height values.\nThe midpoint of a sample is the value equidistant from the minimum and the maximum. It can be calculated by taking taking the mean of the minumum and maximum value of a sample.\nIn R, you can calculate the midpoint of a sample with:\n\n(max(height_data2$Height) + min(height_data2$Height))/2\n\n[1] 105\n\n\nNotice how the midpoint is still greater than the height of five of the species measured because of the relative tallness of Juniper communis compared to the rest of the community.\nFinally, the mode of a sample is the most frequent or common value. A sample may have multiple modes if there are more than one value in the sample that are equally common.\nThere is not a standard mode function in R, so here, we present a method to find the most common value of a sample. We will use the tidyverse package to manipulate the data and find the mode (see the basics in R for more on tidyverse):\n\nheight_mode <- height_data2 %>% # use \"pipe operators\", `%>%`, to pass the data for further manipulations\n  group_by(Height) %>% # group the data by their height values\n  summarise(N_height = n()) %>% # count `n()` how many entries have the same value \n  filter(N_height == max(N_height)) # return the mode by pulling out the values with the highest count\n\nheight_mode # see the mode\n\n# A tibble: 1 × 2\n  Height N_height\n   <dbl>    <int>\n1     10        2\n\n\nWe see that the most common value of height in our dataset is 10 cm and there are two species with that height.\n\n\n2.1.4 4. Variance, standard deviation, and standard error\nMeans and medians describe the central tendency of a sample, but they give us no information on the spread or dispersion of the data used to find this central tendency. We cover measures of sample dispersion in this section.\nThe variance (var or \\(\\sigma^2\\)) corresponds to the mean of the squared differences from the mean. Mathematically, variance (\\(\\sigma^2\\)) of the sample (x) is:\n\\[\\sigma^2 (x) = \\frac{\\sum_{i=1}^n (x_i - \\overline{x})^2}{n}\\]\nWhere we take an entry in the sample, \\(x_i\\), and calculate the difference between its value and the mean, \\(\\overline{x}\\), then square it. Do the same for all the entries, n, in the sample. Finally, calculate the mean of these squared differences (divide by n) and you get the variance. Note-variance is always positive because of the squared difference.\nIn R, the function that calculates the variance is var():\n\nvar(height_data2$Height) # finds the variance of the sample\n\n[1] 5564.167\n\n\nHere, we get the variance of the height data- the variance is over 27 times larger than the tallest species’ height! Why might that be?\nThe standard deviation (sd or \\(\\sigma\\)) is the square root of the variance. Unlike the variance, the standard deviation has the same unit as the mean, median or any entry in the sample because of this square root transformation. This makes it very useful as it can be used in combination with the mean to define how values are spread around the mean. Often, you will find this expressed as mean +/- sd.\nIn R, the standard deviation is obtained via the function sd(). Note that you will obtain the same result by calculating “manually” the square root of the variance with sqrt(var()):\n\nsd(height_data2$Height) # finds the standard deviation of the sample\n\n[1] 74.59334\n\nsqrt(var(height_data2$Height)) # alternative method to find the standard deviation\n\n[1] 74.59334\n\n\nNote how much closer the sd is to the values within our height data.\nStandard error is a popular way of showing dispersion around a mean for modeling purposes because it further accounts for sampling effort, or the number of values/ replication in the sample, and is used in many frequentist statistical tests (see t-tests page). The standard error (se or \\(\\sigma_\\overline{x}\\), given it is a measure of dispersion on a calculated mean \\(\\overline{x}\\)) is:\n\\[\\sigma_\\overline{x} = \\frac{\\sigma}{\\sqrt{n}}\\]\nWhere \\(\\sigma\\) is the standard deviation of the sample and n is the number of independent observations in the sample.\nThere is no standard function to calculate a samples standard error in R, but many statistical test functions will calculate the standard error for a parameter as part of the output. Here is a way to calculate the se from scratch:\n\nsd(height_data2$Height)/sqrt(length(height_data2$Height)) # take the sd of the sample and divide by the square root, `sqrt()`, of the number of observations or `length()` of the sample. \n\n[1] 30.4526\n\n\nWe can interpret the se as the expected “error” in our estimate of mean plant height. What would happen to the standard error if we measured the height of every plant in the meadow? This is an important point! The standard error of a mean estimate approaches zero as we increase the number of observations ($_ 0 $ as \\(n \\rightarrow \\infty\\)).\n\n\n2.1.5 5. Quartiles\nTake a sample, sort the data from smallest to largest and split it in four equal subsets. The quartiles are the values of the sample that cut it off in four.\nQuartiles are called: Q1: the first quartile under which the first 25% of the data in the set can be found, Q2: the second quartile under which the first 50% of the data in the set can be found (Q2 is also the median), Q3: the third quartile under which the first 75% of the data in the set can be found.\nIn addition, one refers to: Q0: the minimum value in the set, Q4: the maximum value in the set.\nNote that the set of data between Q1 and Q3 (which contains the middle 50% of the data) is the interquartile range (IQR).\nIn R, quartiles may be obtained using the function quantile(). (NB: this is not a typo, quantile refers to the intervals (0, 25, 50, 75, 100%) at which the quartiles, the values in the data, are assessed). If you choose to use only quantile() with no other argument than the vector containing the sample, R returns Q0, Q1, Q2, Q3, and Q4. If you need only Q1, Q2 and Q3, you use an extra argument (see the following example):\n\nquantile(height_data2$Height) # Find the Q0, Q1, Q2, Q3, and Q4\n\n    0%    25%    50%    75%   100% \n 10.00  11.25  17.50  42.50 200.00 \n\nquantile(height_data2$Height, probs = c(0.25, 0.5, 0.75)) # Find the Q1, Q2, and Q3 by defining which quartiles (in proportions) using the probs argument\n\n  25%   50%   75% \n11.25 17.50 42.50 \n\n\nQuartiles can be visualized with ggplot() and geom_boxplot():\n\nggplot(height_data2, aes(y=Height, x=\"\"))+geom_boxplot()+# assign the vector \"x\" as the y variable in the 'aes' argument and pass it to 'geom_boxplot' \n  labs(title=\"Height Boxplot\")+ xlab(label=\"\")+ # this and the following lines label the axes and quartiles\n  annotate(\"text\", x = 1.1, y = 200, label = \"<-Q4 or max\")+\n  annotate(\"text\", x = 1.42, y = 42.50, label = \"<-Q3\")+\n  annotate(\"text\", x = 1.42, y = 18, label = \"<-Q2\")+\n  annotate(\"text\", x = 1.42, y = 11, label = \"<-Q1\")+\n  annotate(\"text\", x = 1.063, y = 5, label = \"^Q0 or min\")\n\n\n\nFigure 2.1: ?(caption)\n\n\n\n\nWe can see the distribution of the height data and its quartiles with the boxplot. Note how much of an outlier Juniper communis is relative to the other species.\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\n\n\n\n\n\n\nContributors\n\nJoshua Lynn\nKwaku P. Adjei"
  },
  {
    "objectID": "2.1_simple_linear_regression.html",
    "href": "2.1_simple_linear_regression.html",
    "title": "\n3  Simple linear Regression\n",
    "section": "",
    "text": "Before you start\n\n\n\nYou should be familiar with basic statistical theory, basics of R, continuous and categorical data, hypothesis testing, statistical modeling, and the concept of linear models."
  },
  {
    "objectID": "2.1_simple_linear_regression.html#introduction",
    "href": "2.1_simple_linear_regression.html#introduction",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.1 Introduction",
    "text": "3.1 Introduction\nIn this section, we will look at how we can use simple linear regression to analyze data with a continuous numeric response and a numeric explanatory variable. Linear regression is a type of linear model.\n\nLinear regression has two motivations. The first is called inference, which is when you want to say something about a population from a sample. Very often data are only available for a subset of the population (a sample), but we want to generalize our conclusions for the whole population. Therefore, we use statistical models to infer effects at the whole population level from what we find at the sample level. The second motivation is prediction, where we use a model to predict values of the response for specific values of the explanatory variable. These predictions can either be for observed values of the explanatory (mainly used for plotting), for unobserved values of the explanatory variable within the same range as observations, or for novel values of the explanatory variable outside the range of observations (this is more risky! - more on this later).\n\nExample questions:\n\ninference: does the height of plants increase with increasing temperatures?\nprediction: how tall will a plant be if mean temperatures increase by 2°C?\n\n\n\n\n\n\nFigure 3.1: Panel A shows an illustration of inferring the effect of temperature on plant height. Panel B shows an illustration of the prediction of a plant height under a 2°C increase in temperature. Created by Emily G. Simmonds\n\n\n\n\n\nIn simple terms, we fit a straight line to:\n\nestimate a relationship between \\(X\\) and \\(Y\\)\npredict change in \\(Y\\) from change in \\(X\\).\n\n\nLinear regression assumes a causal relationship between \\(X\\) and \\(Y\\), i.e. it assumes that \\(X\\) influences \\(Y\\), but not vice versa. It is important to understand that a regression only “quantifies” the pattern between \\(X\\) and \\(Y\\), but does not actually test for a causal relationship. To test if \\(X\\) causes an effect on \\(Y\\), you need to conduct a scientific experiment. A linear relationship between two variables does not necessarily mean that \\(X\\) has a causal influence on \\(Y\\). For example, the number of PhDs awarded in math has nothing to do with the amount of Uranium stored in the USA. However, when plotting the two variables against each other, one could assume a perfect relationship (see Figure 3.2)). Therefore, before statistically analyzing data it is essential to make sure there is a biological explanation or assumption for a relationship between \\(X\\) and \\(Y\\). For more examples of wrong assumptions of causality click here.\n\n\n\n\n\n\n\n\nFigure 3.2: Example of a spurious correlation (one that does not make sense causally). Scatterplot of number of maths PhDs awarded in a year against the amount of uranium stored in US power plants annually. Smooth line indicates a regression line for this data with the 95% confidence interval as the shaded area"
  },
  {
    "objectID": "2.1_simple_linear_regression.html#which-questions",
    "href": "2.1_simple_linear_regression.html#which-questions",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.2  Which questions?",
    "text": "3.2  Which questions?\n\nExample questions you can answer with a simple linear regression:\nInference\n\nHow does mean annual temperature change with time?\nHow does the time of breeding for a bird change with mean spring temperature?\nHow does relative plant biomass change with mean light intensity?\n\nPrediction\n\nWhat will the mean summer temperature be in 2100?\nHow heavy will a sheep be if it is 100cm long?"
  },
  {
    "objectID": "2.1_simple_linear_regression.html#type-of-data",
    "href": "2.1_simple_linear_regression.html#type-of-data",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.3  Type of data",
    "text": "3.3  Type of data\n\n\n3.3.1 Theory\n\nA linear regression is used when you have continuous numeric response variable and a continuous numeric explanatory variables. A simple linear regression has only one explanatory variable, a multiple linear regression has more than one.\n\nExamples of continuous numeric variables:\n\nMean annual temperature (°C)\nTotal annual precipitation (mm)\nDistance (km)\nHeight (cm)\nWeight (kg)\n\n\nAlways remember to check that the way your variables are classified in R is the same as the format you expect. It is a common mistake for a variable that should be numeric to be classified as a Factor, or a Factor as a character string etc. (This should not be a problem in the latest version of R, so might become a historical problem.)\n\n\n3.3.2 Worked example\n\nFor this worked example we will be using some data on dive depths of marine mammals. We will be answering the question:\nDoes body size (kg) influence maximum dive depth (m) in marine mammals?\nWe might expect that differences in foraging strategies, physiological processes, metabolism, and power of the marine mammals would impact how deep the animals can dive. All of these variables correlate with body size. Therefore, it could be expected that larger species can dive deeper as relative movement compared to body size is lower. Or perhaps it is less energetically demanding for smaller species to dive deeper. The direction and strength of the influence of body size on dive depth can be quantified using a linear regression.\n\n\n\n\nFigure 3.3: Illustration of marine mammals by Emily G. Simmonds\n\n\n\n\n\n\n3.3.2.1 Introduction to the data\n\nThese data have four variables; species, maximum recorded dive depth in metres (m), body weight in kilograms (kg), and taxonomic group.\nThe data were collected from a variety of sources and cover several taxonomic groups (including polar bear, sea otters, baleen whales, toothed whales, seals, and sea lions). You can find the dataset here if you want to try the analysis for yourself.\n\n\nFull list of data sources\nSources:\n\nBritish Broadcasting Coorporation (BBC)\nCroll et al 2001, Comparative Biochemistry and Physiology Part A: Molecular & Integrative Physiology, Volume 129, Issue 4, Pages 797-809\nBaird et al 2000, Report prepared under Contract #40ABNC050729 from the Hawaiian Islands Humpback Whale National Marine Sanctuary\nBannister 2008, Great Whales, CSIRO Publishing\nNorwegian Polar Institute\nEguchi and Harvey 2005, Marine Mammal Science, 21: 283-295\nLloyd Spencer Davis, Te Ara - the Encyclopedia of New Zealand, (accessed 30 September 2020)\nGales et al 2013, Unpubished Report to the IWC\nDolphin Communication Project\nEncyclopedia of Marine Mammals edited by Würsig, Perrin, Thewissen, 2002, Elsevier Ltd\nPolar Bear Science\nMarine Biology, compiled by Steele, edited by Steele, Thorpe, Turekian, 2009, Elsevier Ltd\nNorth Atlantic Marine Mammal Commission\nNational Oceanic and Atmospheric Administration, USA\nDepartment of Conservation, New Zealand\n\nFirst, we want to import the data and have a closer look by making a plot.\n\n\ndive_data\n\n# A tibble: 30 × 6\n   species                 max_depth body_size_kg group    Species         Group\n   <chr>                       <int>        <dbl> <chr>    <fct>           <fct>\n 1 Orca                          264         4500 Twhale   Orca            Twha…\n 2 WeddellSeal                   741          500 Pinniped WeddellSeal     Pinn…\n 3 LongFinnedPilot               828         1300 Twhale   LongFinnedPilot Twha…\n 4 ShortFinnedPilot             1019         2000 Twhale   ShortFinnedPil… Twha…\n 5 BlainvillesBeakedWhale       1408          900 Twhale   BlainvillesBea… Twha…\n 6 NorthernBottlenoseWhale      1453         8000 Twhale   NorthernBottle… Twha…\n 7 SouthernElephantSeal         1653         3000 Pinniped SouthernElepha… Pinn…\n 8 BairdsBeakedWhale            1777        12000 Twhale   BairdsBeakedWh… Twha…\n 9 SpermWhale                   2035        27000 Twhale   SpermWhale      Twha…\n10 CuviersBeakedWhale           2992         2500 Twhale   CuviersBeakedW… Twha…\n# … with 20 more rows\n\ndive_fig <- ggplot(dive_data, aes(x=body_size_kg, y=max_depth, color=group))+\n  geom_point()\n\n\n\n\n\nFigure 3.4: Scatterplot of body size against maximum dive depth for marine mammals. Colours indicate taxonomic group\n\n\n\n\n\nThe output shows that two of the variables are factors (species and group), one is continuous numeric (max_depth), and the last one is integer (body_size_kg). We know that body size actually is a continuous variable, scientists probably rounded when they measured this variable, because these are large numbers. We will change this variable to be numeric so it better represents the characteristics of the data.\n\n# format the divedata\ndive_data <- mutate(dive_data, body_size_kg = as.numeric(body_size_kg))\n\nRemember, we are interested in whether body size (kg) influences maximum dive depth (m) in marine mammals. To answer this question we will need the variables: body_size_kg and max_depth. We will not consider species or group at the moment, but we might need them later.\n\nNow we have familiarized ourselves with the data, we know our research question, and we have identified which variables we need for the analysis. We are ready to perform an analysis."
  },
  {
    "objectID": "2.1_simple_linear_regression.html#model-details",
    "href": "2.1_simple_linear_regression.html#model-details",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.4  Model details",
    "text": "3.4  Model details\n\n\n3.4.1 Theory\n\nWhen we create a model we aim to represent mathematically the process that generated the data we observed.\nWhen we use a linear regression model (this is also true for other types of linear models), we make an assumption that there is a linear relationship between the explanatory and response variables. Mathematically, we say that we can capture the data generation process with a straight line and some error.\nThe line component of the linear regression is defined by two parameters:\n\n\n\\(\\alpha\\) (Greek letter alpha) = the intercept, defining where the regression line crosses the y-axis.\n\n\\(\\beta\\) (Greek letter beta) = the slope (steepness/gradient), which defines the steepness of the regression line, i.e. how much \\(Y\\) changes for every increase of 1 unit of \\(X\\).\n\nWe can alter the position and slope of the line by these two parameters. The final part of the model is \\(\\varepsilon\\) (Greek letter epsilon), which is the error around the regression line. This error is estimated with the parameter \\(\\sigma^{2}\\) (Greek letter sigma – squared) that is the variance of the error. (Greek letters are used to refer to each part of the model using equations).\n\nWe can write a linear regression model as and equation as a function of \\(Y\\):\n\\[\nY_i = \\color{orange}\\alpha + \\color{blue}\\beta X_i + \\color{red}\\varepsilon_i\n\\]\n\n3.4.1.1 Assumptions\n\nThere are several assumptions that we make when using a linear regression model:\n\nThe relationship between X and Y is linear\nResiduals (this is another word for error) are normally distributed\nThe residuals have a mean of 0\nThe variance of the residuals is equal for all fitted values (homoscedasticity)\nThere are no outliers\nEach value of Y is independent\n\n\nAll of these assumptions should be met for the model to work properly and they ALWAYS need to be checked. We will check five of them after we have fit the model (see below). The last assumption, independence of \\(Y\\) needs to be assured before or during data collection. For example, if data were collected on leaf length, 20 leaves each from five trees, these would not be independent. It would be better to collect one leaf each from 100 trees.\n\n\n3.4.1.2 Writing the model in \n\n\nTo fit the simple linear regression in  we will use the lm() function. \nlm() stands for linear model (should seem familiar) and it takes several arguments:\n\nformula in form: y ~ x\n\ndata: your data object\n\n\nThe function will fit the regression model using maximum likelihood estimation and give us the maximum likelihood estimates of \\(\\alpha\\) and \\(\\beta\\) as an output. It does also estimate \\(\\sigma^{2}\\) of the error, but it does not report this.\n\nTo use the lm() function you first need to think about the formula argument, the y ~ x part. The same way as in the equation above, the letter \\(Y\\) always corresponds to the response variable (the thing you are trying to explain) and \\(X\\) to an explanatory variable (the thing you assume affects the response).\n\nDoes temperature influence wing length of butterflies?\n\nThe explanatory variable (\\(X\\)) = temperature, it is the variable that does the influencing. The response variable (\\(Y\\)) = wing length, it is the result.\n\nYou can then plug these variables into the lm() function in the below format using the column names in place of y and x and including your data frame name as the data argument.\n\n\nmodel_object <- lm(response ~ explanatory, data = your_data)\n\nRunning the lm() as illustrated above runs the linear regression model and saves the output as a ‘model_object’.\n\nI saw an lm() written differently, what’s that about?\nYou can use the lm() function without the data argument. If you do this, you need to refer to your (\\(X\\)) and (\\(Y\\)) variables in the y ~ x formula using a $ between the data name and the column name.\nWe do not recommend using this approach. There are several reasons for this but a key one is that when using the $ syntax, R sees the variable name as the whole entry your_data$explanatory rather than as the column name explanatory. This makes it difficult to use this model for other things e.g. to predict.\n\nalternative <- lm(your_data$response ~ your_data$explanatory)\n\n\nThe results of the linear regression can be viewed using the function coef(). This takes the output of lm(), the model object, as its argument and extracts the maximum likelihood estimates of \\(\\alpha\\) and \\(\\beta\\). \\(\\alpha\\) will always be labelled (Intercept) but \\(\\beta\\) will be labelled by the name of the \\(X\\) variable.\n\ncoef(model_object)\n\n(Intercept) explanatory \n  2.7720862   0.7969848 \n\n\n\n\n3.4.2 Worked example\n\nThis worked example demonstrates how to fit a linear regression model in  using the lm() function for the dive depths example.\n\nIn this example we are asking:\nDoes body size influence maximum dive depth in marine mammals?\n\nOur question is formulated to suggest a direction of causality, we assume body size has a causal effect on maximum dive depth, therefore maximum depth is our response (\\(Y\\)) and body size as our explanatory variable (\\(X\\)).\n\nWe can put these variables into the lm() function in the below format.\n\ndive_model <- lm(max_depth ~ body_size_kg, data = dive_data)\n\n\nGreat. We have run a model and assigned it to an object name.\nWe can look at the maximum likelihood estimates of our model parameters (\\(\\alpha\\) and \\(\\beta\\)) using the function coef().\n\ncoef(dive_model)\n\n  (Intercept)  body_size_kg \n755.977336598  -0.005384027 \n\n\n\nWe will look at interpreting these in the next part of the worked example."
  },
  {
    "objectID": "2.1_simple_linear_regression.html#parameters",
    "href": "2.1_simple_linear_regression.html#parameters",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.5  Parameters",
    "text": "3.5  Parameters\n\n\n3.5.1 Theory\n\nWe introduced the three model parameters of a simple linear regression in the section above: \\(\\alpha\\) = the intercept, \\(\\beta\\) = the slope of the line (steepness/gradient), and \\(\\sigma^{2}\\) the variance of the error.\n\\[\nY_i = \\color{orange}\\alpha + \\color{blue}\\beta X_i + \\color{red}\\varepsilon_i\n\\]\n\nBut what do these parameters really mean?\n\nAll regression analyses are fundamentally about using straight lines to represent the relationship between a response (\\(Y\\)) and some explanatory variables (\\(X\\)), called a regression line. The parameters of the model determine the placement and gradient of the straight line, as well as representing the distribution of data points around the line.\n\n\n\n\n\n\n\n\nFigure 3.5: Illustration of components of a linear regression. Intercept is in orange, slope is in blue, and the residuals (explained later) are in red\n\n\n\n\nIn this section we will go through these parameters and their meaning in terms of the relationship between \\(X\\) and \\(Y\\).\n\n\n3.5.1.1 \\(\\alpha\\), the intercept\nThis first parameter gives the value of \\(Y\\) when \\(X\\) = 0, it is the point that the regression line crossed the y-axis. A positive value means that the value of \\(Y\\) when \\(X\\) = 0 is above 0, and a negative intercept value means it is below the value of \\(Y\\) is below 0, when \\(X\\) = 0.\n\n3.5.1.2 \\(\\beta\\), the slope\nThis second parameter gives the amount of change in \\(Y\\) for every unit change in \\(X\\), it is the slope of the regression line. Positive values indicate a positive relationship between \\(X\\) and \\(Y\\) i.e. \\(Y\\) increases as \\(X\\) increases. Negative slope values indicate the opposite, a negative relationship where \\(Y\\) decreases as \\(X\\) increases. The higher the value of the slope, the stronger the regression relationship.\n\nTogether \\(\\alpha\\) and \\(\\beta\\) control the position and steepness of the regression line. They are called the systematic part of the model, the bit that links \\(Y\\) to the covariate \\(X\\).\n\n3.5.1.3 \\(\\sigma^{2}\\), the variance of error\nThis is the final parameter you need to estimate for the simple linear regression and it is a bit different from \\(\\alpha\\) and \\(\\beta\\). This parameter does not relate directly to the shape or position of the regression line. Instead, this parameter captures the variance of the data points around that line, i.e. how close or far away each data point is from the regression line. The variance is the random part of the model, or in other words the error. Higher error variance values indicate more variation around the model fit. In the case of a simple linear regression, the error is assumed to be normally distributed.\n\nIn Figure 3.5), you can see a plot of a regression line through the data points, but it does not touch all of the points. In other words, it is not capturing all of the variation in the data. The regression line does not explain the exact position of all data points, something else is also going on (this is to be expected for real data).\n\nThe regression line is a fitted line that represents the best fit line of a relationship between \\(X\\) and \\(Y\\) (based on maximum likelihood estimation). The value of \\(Y\\) for each \\(X\\) on the regression line is called a fitted value. The distance between the fitted values and the values of \\(Y\\) that were actually observed are called residuals. You can extract the residuals from your model object using the function residuals(), which is useful when checking model assumptions (see below). Data points below the regression line have a negative the residual and data points above the line have a positive residual. These are highlighted red in Figure 3.5).\n\nThe regression line must always pass through the point that represents the mean of \\(X\\) and the mean of \\(Y\\). (\\(\\bar{X}\\), \\(\\bar{Y}\\)). Therefore, if you change the intercept, the slope must change as well to keep the line going through the (\\(\\bar{X}\\), \\(\\bar{Y}\\)) point. You can have a go at doing this below.\n\n\n3.5.1.4 Exercise: Finding a ‘best’ line\nBelow you will see a window containing an app. The aim of this app is to try and find the straight line that best explains the data, by trying different slope values.\nThere is a slider on the left hand side that lets you control the \\(\\beta\\) value, the \\(\\alpha\\) is fixed at 0. On the right you can see the fitted line (one is already plotted for you).\nIn this example ‘fit’ of the line is measured using something called the sum of squared residuals. This is calculated by squaring the values of all of the residuals and then adding them up to get a single number:\n\\[\n\\Sigma (y_i - \\bar{y_i})^2\n\\]\nwhere, \\(y_i\\) = the observed value of \\(y\\) for \\(x_i\\) and \\(\\bar{y}\\) = the fitted y value for \\(x_i\\), and \\(i\\) is an index of 1 to \\(n\\) (sample size).\nThe reason the sum of squares is used to estimate the fit of a model line to data is because there are roughly as many positive residuals as negative. If you just sum them, the result will be roughly 0. Therefore, squaring them before adding them means they don’t cancel out. This measure tells you how far away the observations are from the fitted line, the lower the number, the better the fit.\n\n\n\n\n\nClick here to open the app in full scale in a separate window.\nWhat was the best fit you managed to get?\n\nWhat was the answer?\nA slope of approximately 3 should give the best answer (lowest sum of squares), which is 3423.5956.\nHow confident are you that you found the best line?\nIt is hard to know by trial and error if you have found the ‘best’ line for the data. It is much easier, repeatable, and reliable to use a simple linear regression instead. The idea is the same as the app, but instead of trying until it looks good, the equation for simple linear regression is used and values for the unknown parameters are found using maximum likelihood estimation.\n\n\n3.5.1.5 Interpreting the parameters\nNow you know what each of the three parameters in a simple linear regression mean, you can now think about interpreting them.\nWhich of the three parameters do you think is most important for answering the research question “Does \\(X\\) influence \\(Y\\)?”?\n\n\nI had a go, now show me the answer.\n\nThe slope (\\(\\beta\\)) tells us the strength and direction the relationship between \\(X\\) and \\(Y\\) is. While the linear regression model also estimates the intercept and the residual variance, these do not directly answer our question of interest. However, to make predictions, we will need all three parameters.\n\n\n3.5.2 Worked example\n\nIn the previous section of this worked example, we fit a simple linear regression using the lm() function and looked at the estimates of some parameters using the coef() function. In this section, we will use model theory to interpret what those parameters mean.\n\n\n3.5.2.1 The intercept and slope\nWe already know that the parameters of the intercept and slope control the position and steepness of the regression line. It is the estimates of these two parameters that we get from the coef() function.\n\nFor our dive depth model the estimates are:\n\ncoef(dive_model)\n\n  (Intercept)  body_size_kg \n755.977336598  -0.005384027 \n\n\n\nThe intercept is 756 m and the slope of the relationship between body size and dive depth is -0.005.\n\nIn this case, the intercept is not that interesting. It tells us the expected value of \\(Y\\) (maximum dive depth) when \\(X\\) (body size) = 0. It does not make a lot of biological sense to know the expected dive depth of a marine mammal that weighs 0 kg. But, sometimes it can make sense to know the value \\(Y\\) when \\(X\\) is 0, for example if \\(X\\) was temperature.\n\nThe slope on the other hand is interesting. It tells us the direction and strength of the relationship between body size and maximum dive depth. In this case our model estimates a negative slope. This means that for every increase of 1 kg in body size of marine mammals the maximum dive depth decreases by 0.005 m. In other words, there is a negative relationship between body weight and dive depth and as \\(X\\) increases \\(Y\\) decreases (?fig-fig-6).\n\n\n3.5.2.2 Residual variance\nThe coef() function can give us the maximum likelihood estimates of the intercept and slope parameters, but it does not give any information on the residual variance, \\(\\sigma^{2}\\). To get an estimation of the residual variance, we use the summary() function with the model object as an argument. To extract \\(\\sigma\\) we use $sigma and square the result to get \\(\\sigma^{2}\\).\nYou cannot take var(residuals) directly because this uses n-1 as the denominator of the variance equation whereas to estimate \\(\\sigma^{2}\\) for a linear regression the denominator depends on the number of parameters being estimated. The denominator is the degrees of freedom (n-number of parameters estimated). In a simple linear regression there are two parameters that have been estimated (as well as \\(\\sigma^{2}\\)) these are the intercept and the slope. Therefore, the denominator n-2. The more explanatory variables you add to a linear regression, the more parameters you estimate and the fewer degrees of freedom you will have.\n\n\nsigma2 <- summary(dive_model)$sigma^2\nsigma2\n\n[1] 526362.7\n\n\n\nFor this model the \\(\\sigma^{2}\\) = 5.263627^{5}. This number is abstract and does not mean anything on its own, but it could be used to compare models (though there are much better ways to do this). It does not help in terms of answering whether body size influences dive depth. But we will use it for prediction later.\n\n\n3.5.2.3 Plotting the results\nAs well as looking at the maximum likelihood estimates of the parameters from the simple linear regression, we can also plot the estimated regression line.\n\nTo do this, we will use ggplot() with geom_line().\nWe will also go into the second aim of a regression: predicting. Therefore, we need to use a new function called predict().\n\nTo make this first plot, we only need to use two arguments:\n\n\nobject = your model object\n\ntype = “response”, which means predict on the response scale\n\n\n\ndepth_predictions <- predict(dive_model, type=\"response\")\n\n\nOnce we have created predictions of \\(Y\\) from the model object, we can then plot these using geom_line() as in the code below.\n\ndive_model_fig <- ggplot(dive_data, aes(x=body_size_kg, y=max_depth))+\n  geom_point(colour = 'grey70')+\n  geom_line(aes(y=depth_predictions))+\n  labs(y=\"Maximum Dive Depth (m)\",\n  x=\"Body Size (kg)\")\n\n\n\n\n\nFigure 3.6: Scatter plot of dive depths against body size. The black line is the regression line predicted from the linear model\n\n\n\n\n\nIn the next section we will look at how to add uncertainty to these plots and our interpretation."
  },
  {
    "objectID": "2.1_simple_linear_regression.html#quantify-uncertainty",
    "href": "2.1_simple_linear_regression.html#quantify-uncertainty",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.6  Quantify uncertainty",
    "text": "3.6  Quantify uncertainty\n\n\n3.6.1 Theory\n\nYou should already know that statistics does not give a single correct answer. When you estimate the values of parameters in our statistical model, there are many different values that could plausibly have produced the observed data. Some of these are more likely than others but several will have very similar likelihoods.\n\nA simple linear regression is no different. And a way to cope with this, is to calculate and present the uncertainty in the parameters you estimate.\n\nThe lm() function produces results that are equivalent to maximum likelihood estimation of the parameters. Therefore, our consideration of uncertainty for these models follows the same principles as discussed here. You can quantify uncertainty using standard errors, confidence intervals, and prediction intervals which should be familiar to you but head to the uncertainty pages if you need a recap.\n\nFor any regression there are two different types of uncertainty. Here, we cover at the uncertainty in the parameters of the regression line, \\(\\alpha\\) and \\(\\beta\\) and the uncertainty in predictions of \\(Y\\).\n\n\n3.6.1.1 Uncertainty in the estimates of \\(\\alpha\\) and \\(\\beta\\)\n\n\n3.6.1.1.1 Standard error\nThe standard error of a parameter is the standard deviation of its sampling distribution. It gives a measure of the spread of the sampling distribution i.e. the uncertainty. To find the standard errors for the estimates of \\(\\alpha\\) and \\(\\beta\\) you can use the summary() function. The argument that summary() takes is a model object, the output from lm(). This function gives a big table with lots of information. The first line shows the model formula used for the model object. The second line shows a summary of the residuals of the model and the standard errors are shown as the second column in the third part, Coefficients:.\n\nsummary(model_object)\n\n\nCall:\nlm(formula = response ~ explanatory, data = your_data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1510 -3.0636  0.3854  1.4128  8.1477 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  2.77209    1.11970   2.476   0.0196 *  \nexplanatory  0.79698    0.05925  13.452 9.61e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 3.28 on 28 degrees of freedom\nMultiple R-squared:  0.866, Adjusted R-squared:  0.8612 \nF-statistic:   181 on 1 and 28 DF,  p-value: 9.611e-14\n\n\n\nIf we take the summary() of the example model, we can see the standard error or the intercept (\\(\\alpha\\)) is 0.95825, and the standard error for the slope (\\(\\beta\\)) is 0.05483.\n\n\n3.6.1.1.2 Confidence intervals\nFor interpretation of the uncertainty, it can be easier to use the standard error to calculate confidence intervals (CI). Confidence intervals indicate the range of plausible values for a parameter. They represent an interval, that if you were to collect a sample and run the analysis, then repeat that many many times AND each time draw a confidence interval, on average 95% of the time, the true population value of the parameter would be found in within the confidence interval.\nIf you need a reminder of this click here.\n\nThe confidence interval can be calculated using this formula:\n\\[\n\\begin{aligned}\nUpperCI = estimate + (1.96 SE) \\\\\nLowerCI = estimate - (1.96 SE) \\\\\n\\end{aligned}\n\\]\n1.96 is used because in a standard normal distribution 95% of the distribution lies within 1.96 standard deviations of the mean. In this case the distribution is the sampling distribution, which is normal for \\(\\alpha\\) and \\(\\beta\\) and the standard deviation is the standard error.\n\nUsing the formulas above, calculate the confidence intervals for the intercept and slope from the example model.\n\n\nI had a go at calculating, what is the correct answer?\n\n# INTERCEPT\n\n# Upper confidence interval\nupper_ci_intercept <- summary(model_object)$coefficients[1,1] + \n  (1.96*summary(model_object)$coefficients[1,2])\n# Lower confidence interval\nlower_ci_intercept <- summary(model_object)$coefficients[1,1] - \n  (1.96*summary(model_object)$coefficients[1,2])\n\n# Print the interval\nc(upper_ci_intercept, lower_ci_intercept) \n\n[1] 4.9667025 0.5774699\n\n# SLOPE\n\n# Upper confidence interval\nupper_ci_slope <- summary(model_object)$coefficients[2,1] + (1.96*summary(model_object)$coefficients[2,2])\n# Lower confidence interval\nlower_ci_slope <- summary(model_object)$coefficients[2,1] - (1.96*summary(model_object)$coefficients[2,2])\n\n# Print the interval\nc(upper_ci_slope, lower_ci_slope) \n\n[1] 0.9131062 0.6808633\n\n\n\nIt is also possible to get R to calculate the confidence intervals for you. To do this you can use the confint() function. The argument is a model object.\n\nconfint(model_object)\n\n                2.5 %   97.5 %\n(Intercept) 0.4784802 5.065692\nexplanatory 0.6756256 0.918344\n\n\n\nHopefully these confidence intervals look the same as those you calculated yourself.\n\n\n3.6.1.2 Uncertainty in a prediction of \\(Y\\)\n\nSo far, we have covered uncertainty in parameter estimates using standard errors and confidence intervals but linear regression analyses can also be used for prediction. When a linear regression is used for prediction, an interval of confidence in the prediction should also be given. This is a type of confidence interval specific for predictions and can be called a prediction interval.\n\nA 95% prediction interval tells you, if you were to collect a sample and run the analysis, then go out an collect a new observation of the response variable (\\(Y\\)) with particular value of the explanatory variable (\\(X\\)) many many times AND each time draw a prediction interval, 95% of the time, the new observation would fall in within the prediction interval.\n\nTo find the prediction interval for a prediction you use the predict() function with the interval=\"prediction\" argument. You also set the newdata argument to the value of \\(X\\) you want to predict for.\n\npredict(model_object, newdata=x_predict, \n                             type=\"response\", interval = \"prediction\")\n\n\n\n3.6.2 Worked example\n\nAt the end of the last section, we created a plot of our dive depth data and the estimated linear regression line. Now, we will add uncertainty to that plot.\n\nFirst, we should look at the confidence intervals of our parameter estimates.\n\nround(confint(dive_model),2)\n\n              2.5 %  97.5 %\n(Intercept)  449.03 1062.93\nbody_size_kg  -0.02    0.01\n\n\n\nThe confidence intervals have been rounded to 2 decimal places to make them easier to read. The intercept interval spans from approx 450 to 1060. The slope interval crosses 0, going from -0.02 to +0.01.\n\nTo add these intervals to the plot, we need to make new predictions including the confidence interval. In this case we are using confidence intervals even though we are predicting, because we want to show the uncertainty in \\(\\alpha\\) and \\(\\beta\\) rather than in a novel prediction. We have to make predictions in order to plot rather than because we are interested in them.\n\ndepth_predictions <- as_tibble(predict(dive_model, type=\"response\", interval=\"confidence\"))\n\n\nOnce we have created predictions of \\(Y\\) from the model object, we can then plot these using geom_line() and geom_ribbon() for the confidence interval as in the code below.\n\ndepth_predictions <- depth_predictions %>%\n                      mutate(x=dive_data$body_size_kg)\n\nfig_7 <- ggplot()+\n  geom_ribbon(data=depth_predictions, aes(x=x, ymin=lwr, ymax=upr), fill='grey50')+\n  geom_point(data=dive_data, aes(x=body_size_kg, y=max_depth),colour = 'grey70')+\n  geom_line(data=depth_predictions, aes(y=fit, x=x))+\n  labs(y=\"Maximum Dive Depth (m)\",\n  x=\"Body Size (kg)\")\n\n\n\n\n\nFigure 3.7: Scatter plot of dive depths against body size. Line is the regression line from a linear model. Shaded area is 95% confidence interval\n\n\n\n\n\nYou will notice that the confidence interval is narrower in the middle and wider at the ends. This is partly to do with the constraint that the regression line must go through the (\\(\\bar{X}\\), \\(\\bar{Y}\\)) point so the intercept and slope are not independent. Therefore, the confidence interval will be narrowest close to that point.\n\nThe plot shows that the uncertainty in the estimated relationship gets increasingly uncertain as you get to higher body sizes.\n\n\n3.6.2.1 Predicting dive depths for a body size of 75000kg\nA colleague as just found a new species of whale (fictional). The whale washed up on shore in Tromsø, it weighed 75000kg. Based on our linear regression analysis, how deep would we expect it to dive?\n\npredict(dive_model, newdata=data.frame(body_size_kg=75000), \n                             type=\"response\", interval = \"prediction\")\n\n       fit       lwr      upr\n1 352.1753 -1328.376 2032.727\n\n\n\nThe mean prediction is 352m deep. This seems ok. But when we look at the prediction interval, we see that when we include uncertainty, we are not even sure if they whale will dive below the surface by 2km or jump into the air by 1.3km. When we include uncertainty, it is clear that based on the current data and model, we cannot say anything about the possible dive depth of the new whale. We even get biologically unrealistic predictions.\n\nThis is something we will look at in the next section."
  },
  {
    "objectID": "2.1_simple_linear_regression.html#model-checking",
    "href": "2.1_simple_linear_regression.html#model-checking",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.7  Model checking",
    "text": "3.7  Model checking\nYou have now have a model, estimates of parameters, and have calculated the uncertainty of the parameters. But how can we know if a model is any good?\n\n\n3.7.1 Theory\n\nTo find out if the model is any good from a theoretical perspective, you need to check if the model meets the five assumptions of the linear regression that are stated in the Model details section above.\n\nFor this, you can use graphs called diagnostic plots. There are four key diagnostic plots that we use for simple linear regression and each plot tests whether a different assumption has been met. To make the diagnostic plots, you use the plot() function with our linear model object as the first argument and which = number as the second. The number should be replaced by the number corresponding to the plot you want.\n\nFor more on what each plot means, go here: Model checking. On this page, you can find some example plots for a simple linear regression.\nNote: for all of these plots, we do not expect perfection, especially for biological data.\n\n3.7.1.1 1. Residuals vs fitted plot\n\nThere are two examples of residuals vs fitted plots shown below. If the assumptions are met, you can expect a few characteristics of the plot:\n\nThe red line should be roughly horizontally straight and at 0\nThere should be no structure in the residuals\nThe residuals should not curve\n\n\n\n\n\n\nFigure 3.8: Example of a good (left) and a bad (right) residuals vs fitted plot for a simple linear regression\n\n\n\n\nIn reality, it will not be as clear cut as the examples above. You will need to use your own judgment to decide if the assumption is sufficiently met. Do not expect perfection.\n\n\n3.7.1.2 Normal QQ plot\nThere are two examples of normal QQ plots shown below. If the assumptions are met, you can expect:\n\nThe points to lie along the line\n\n\n\n\n\n\nFigure 3.9: Example of a good (left) and a bad (right) normal QQ diagnostic plot\n\n\n\n\n\nNotice that the y-axes have different values.\n\n\n3.7.1.3 Scale-location\nThere are two examples of scale-leverage plots shown below. If the assumptions are met, you can expect:\n\nThe red line to be horizontal\nThere is no structure in the points\n\n\n\n\n\n\nFigure 3.10: Example of a good (left) and a bad (right) scale-location plot\n\n\n\n\n\n\n3.7.1.4 Cook’s Distance\nThere are two examples of Cook’s Distance plots shown below. If the assumptions are met, you can expect:\n\nLow values of Cook’s Distance (y-axis) and no points standing out on their own\n\n\n\n\n\n\nFigure 3.11: Example of a good (left) and a bad (right) Cook’s Distance plot\n\n\n\n\n\nNotice that the y-axes have different values.\n\n\n3.7.2 Worked example\n\nUsing the theory covered in the previous section, we can now check our dive_model to ensure that it meets the assumptions of a simple linear regression.\n\nWe will use one plot at a time to test specific assumptions.\n\n\n3.7.2.1 Residuals vs fitted\n\nplot(dive_model, which = 1)\n\n\n\nFigure 3.12: Residuals vs fitted plot for dive depths model\n\n\n\n\n\nFigure 3.12 looks quite unusual.\nThere are a few assumptions we are checking with this plot:\n\n\nIs the relationship between X and Y linear? It does seem to be. While the red line is not straight, it does not show a clear pattern until the very end. At the very end, there is a strong negative trend. We might need to come back to this! It seems like there might be one pattern for shallow diving species and another for the deep divers.\n\nDo the residuals have a mean of 0? There is a deviation at fitted values of > 700, otherwise yes, the mean of the residuals is approximately 0.\n\nIs the variance of the residuals is equal for all fitted values (homoscedasticity)? It is not the nice cloud of random points that we expect. But is it a problem? To answer this, we need to look at bit closer. The strange shape comes from the residuals at low fitted values, these are the shallow diving marine mammals. You might notice that there are very few of these values. The majority of the data have fitted values > 700. Where we have more data, the residuals vs fitted plot looks better.\n\nAt this point, it might be hard to say how problematic the low variance caused by the lack of data for low fitted values is. But, we can have a look at the points causing the pattern (those with a maximum dive depth < 600m).\n\nfilter(dive_data, max_depth < 600)\n\n# A tibble: 19 × 6\n   species            max_depth body_size_kg group    Species            Group  \n   <chr>                  <int>        <dbl> <chr>    <fct>              <fct>  \n 1 Orca                     264         4500 Twhale   Orca               Twhale \n 2 HomoSapien               112           85 Other    HomoSapien         Other  \n 3 BlueWhale                172       100000 Bwhale   BlueWhale          Bwhale \n 4 FinWhale                 128        60000 Bwhale   FinWhale           Bwhale \n 5 HumpbackWhale            240        36000 Bwhale   HumpbackWhale      Bwhale \n 6 SouthernRightWhale       180        54000 Bwhale   SouthernRightWhale Bwhale \n 7 BrydesWhale              300        41000 Bwhale   BrydesWhale        Bwhale \n 8 Walrus                   450         1500 Pinniped Walrus             Pinnip…\n 9 LeopardSeal               16          400 Pinniped LeopardSeal        Pinnip…\n10 HarbourSeal              481           85 Pinniped HarbourSeal        Pinnip…\n11 CaliforniaSeaLion        536          226 Pinniped CaliforniaSeaLion  Pinnip…\n12 NZFurSeal                238          100 Pinniped NZFurSeal          Pinnip…\n13 NZSeaLion                550          110 Pinniped NZSeaLion          Pinnip…\n14 MinkeWhale               106         8000 Bwhale   MinkeWhale         Bwhale \n15 CommonDolphin            260           80 Twhale   CommonDolphin      Twhale \n16 HarbourPorpoise          100           55 Twhale   HarbourPorpoise    Twhale \n17 PolarBear                 13          500 Other    PolarBear          Other  \n18 SeaOtter                 101           30 Other    SeaOtter           Other  \n19 BottlenoseDolphin        300          450 Twhale   BottlenoseDolphin  Twhale \n\n\n\nFrom these data, we can see that five of the six baleen whales (Group = Bwhale) are included in this subset. This is quite interesting. It could be biologically reasonable that these whales follow a different pattern to the other species because their physiology is very different.\nKeep that last point in mind when we get on to interpreting the results.\n\n3.7.2.2 Normal QQ\n\nplot(dive_model, which = 2)\n\n\n\nFigure 3.13: Normal QQ plot for dive depth model\n\n\n\n\n\nThe assumption we are checking with this plot is: are the residuals are normally distributed?\nAs expected, there is not a perfect match between the theoretical normal distribution and the distribution of the residuals. There is some deviation at both tails of the distribution. At lower quantiles, this seems ok. At higher values, points 9 and 10 deviate quite a lot. These points also stood out in Figure 3.12. We will need to look into them more in Figure 3.15.\n\n\n3.7.2.3 Scale-location\n\nplot(dive_model, which = 3)\n\n\n\nFigure 3.14: Scale-location plot for dive depth model\n\n\n\n\n\nThe assumption we are checking with this plot is: Do the residuals have equal variance across fitted values?\n?fig-fig-14 shows a very similar picture to ?fig-fig-12. While there is a slight increase in variance as the amount of data increases, the amount of change is < 0.5 and there is not much structure in the points. So, this looks like things are ok.\n\n\n3.7.2.4 Cook’s distance\n\nplot(dive_model, which = 4)\n\n\n\nFigure 3.15: Cook’s distance plot for the dive depth model\n\n\n\n\n\nThe assumption we are checking with this plot is: Are there any outliers?\nFigure 3.15 shows that the Cook’s distances of this model are not very high (max = 0.2). So, it does not seem that any points have that large an influence on the fitted values. However, point 10 does seem to be quite different from the others. This might be worth looking into.\n\nWe can find point 10 by looking at the 10th row of our data frame. It is the entry for the Cuvier’s beaked whale. While this is a rare and unusual whale, it is not the only beaked whale in our dataset and we have no reason to believe this data is a typo. Therefore, we would not consider this an outlier and would not remove from the data.\n\ndive_data %>% slice(10)\n\n# A tibble: 1 × 6\n  species            max_depth body_size_kg group  Species            Group \n  <chr>                  <int>        <dbl> <chr>  <fct>              <fct> \n1 CuviersBeakedWhale      2992         2500 Twhale CuviersBeakedWhale Twhale\n\n\n\n\n3.7.2.5 Summary\nOverall, it seems that most of the model assumptions are met well. The only red flag is in the equal variance assumption. However, this seems to be caused in part by a lower amount of data available at the extremes of dive depths. Therefore, we think it is ok to proceed with this model.\n\nIn the next section we will interpret our results."
  },
  {
    "objectID": "2.1_simple_linear_regression.html#draw-conclusions",
    "href": "2.1_simple_linear_regression.html#draw-conclusions",
    "title": "\n3  Simple linear Regression\n",
    "section": "\n3.8  Draw conclusions",
    "text": "3.8  Draw conclusions\n\n3.8.1 Theory\nIn the previous sections you learned how to run a simple linear regression models, what the parameters of the model mean, how to quantify uncertainty in the parameters, and how to check the assumptions of the model. Now, you can bring everything together to draw some conclusions.\n\nThere are several components required in drawing a conclusion:\n\nstatement of the maximum likelihood estimate of the parameters of interest (including strength and direction)\nstatement of the uncertainty in the estimate\nstatement of how good the model is i.e.  how well the model meets assumptions and the amount of variance explained (using \\(R^2\\) - explained below)\nlink the results to biology and the question asked\nDiscussion of next directions\n\n\nOne measure that can be useful for conclusions is to know how much of the variation in \\(Y\\) is explained by \\(X\\). To answer this you can use a measure called the \\(R^2\\). It is calculated using the following equation:\n\\[\nR^2 = 1 - \\frac{\\color{darkblue}{\\text{Residual Variance}} }{\\text{Total Variance}}\n\\]\nand can be found in R using summary(your_model)$r.squared. The value is a proportion, so between 0 (no variance explained) and 1 (all variance explained). A good value is subjective, but > 0.5 is usually considered good, > 0.7 is very good and a value of 1 is suspicious. For biological data, achieving an \\(R^{2}\\) of 0.5 or higher can be challenging because in the real world there are lots of variables influencing each response, more than we could measure and include in an analysis. In these cases, \\(R^{2}\\) could be as low as e.g. 0.3 or 0.1, but this does not mean the model is not valid. It only means that other processes are causing variation in the response on top of those included in the model.\n\n\n3.8.2 Worked example\nThis is the final section of our analysis of the data on marine mammal maximum dive depths. We will now bring together all of the results we have obtained and draw a conclusion following the same format as in the theory section.\nA reminder, we were asking: Does body size influence maximum dive depth in marine mammals?\n\nThe maximum likelihood estimate of the relationship between body size and maximum dive depth in marine mammals was -0.005. In other words, for every 1 kg increase in body weight, marine mammals dived 0.005 m less deep. Given that some marine mammals can dive 1000s of metres, this increase per kg is very low.\n\nWhen we look at the uncertainty in this estimate, we see the 95% confidence interval is -0.017 to 0.006. The confidence interval limits are different signs, meaning that 0 is included as a plausible value for the strength of the relationship. Therefore, we cannot conclude that body size has any impact on maximum dive depth in marine mammals. This is supported by the \\(R^2\\) value, which is 0.03, suggesting only 3% of the variation in maximum dive depth is explained by body size. This is a good example of the lower \\(R^2\\) we often get in biology.\n\nWe should remember here, that when we predicted a dive depth for the fictional whale, it gave us a negative result. Linear models fit a straight line, which can extend beyond the realistic values for some variables. This should be noted and predictions should not be made outside of values that are plausible. This is one reason why predicting outside of the range of your data can be problematic. We can also fit models that are not linear, there is more on those here.\n\nIn model checking, there was an interesting pattern shown, of little data at the lowest maximum dive depths and a disproportionate representation of baleen whales. If we plot the data by group and allow ggplot to fit a regression line per group, we can see that there seems to be a different pattern for different taxonomic groups. This would make sense based on physiology and might explain why the variance assumption was not met well AND why the estimated relationship was so weak.\n\nfinal_dive_fig<- ggplot(dive_data, aes(x=body_size_kg, y=max_depth, color=group))+\n  geom_point()+\n  facet_wrap(.~group)+\n  geom_smooth(method='lm')\n\n\n\n\n\nFigure 3.16: Plot of the relationship between dive depth and body size faceted by taxonomic group\n\n\n\n\n\nWhile the baleen whales show no relationship between dive depth and body size, both the pinnipeds (seals and sea lions) and the toothed whales (orca, dolphins, porpoises) show quite strong positive relationships between dive depth and body size. By treating all groups as the same in one analysis, we might have been masking the true effects.\nIt might be more appropriate to consider an effect of Group as well as body size. We can do this using Linear models for categorical explanatory variables/ANOVA, check out these pages to continue the analysis of this data.\n\n\n\n\n\n\nWhat’s next\n\n\n\n\n\nLinear models for categorical explanatory variables/ANOVA for analyses when your explanatory variable is not numeric\n\nMultiple regression for analyses with more than one numeric explanatory variable\n\nGeneralised linear models for analyses when your response variable is not normally distributed\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\n\n\n\n\n\n\nContributors\n\nEmily G Simmonds"
  },
  {
    "objectID": "2.X_introduction_to_GLMs.html",
    "href": "2.X_introduction_to_GLMs.html",
    "title": "\n4  Introduction to generalised linear models\n",
    "section": "",
    "text": "Before you start\n\n\n\nBefore reading this page, you should be comfortable with basic statistical theory, using R, continuous and categorical data, and linear models."
  },
  {
    "objectID": "2.X_introduction_to_GLMs.html#introduction",
    "href": "2.X_introduction_to_GLMs.html#introduction",
    "title": "\n4  Introduction to generalised linear models\n",
    "section": "\n4.1 Introduction",
    "text": "4.1 Introduction\nThis model builds on from the standard linear models covered on these pages 1, 2, 3. GLMs are similar to the linear models conceptually and in R, but are much more flexible. GLMs are actually the general case of linear models, hence their name (generalised linear models).\nLike the linear regression, the GLM also has two motivations. inference and prediction. But as the name suggests, it is more general than the standard linear models (used for linear regression, ANOVA, and analyses with categorical and continuous variables).\n\nLinear models are used to model a continuous response as a function of explanatory variables. GLMs also model a response as a function of explanatory variables. However, as they are more flexible GLMs can be used for discrete as well as continuous response variables, They can model non-linear relationships, and handle cases where model residuals would not be normally distributed.\n\nIn particular, GLMs are useful when the assumptions of the linear model are violated. The most common violations that can be addressed with a GLM are:\n\nResiduals that are not normally distributed\nNon-linearity\nUnequal variance\n\nWhile some of these violations could be addressed by transformation of the response to try and improve linearity or equalise the variance - this is not always possible or preferable. The GLM makes it possible to account for violations of linearity and variance of residuals in a single model without changing the response. This is especially useful when you know that the response data will not follow a normal distribution e.g. if they are binary results or derive from counting. In these cases, different distributions will better represent the data generation process than the normal distribution used in the linear model."
  },
  {
    "objectID": "2.X_introduction_to_GLMs.html#model-checking",
    "href": "2.X_introduction_to_GLMs.html#model-checking",
    "title": "\n4  Introduction to generalised linear models\n",
    "section": "\n4.2  Model checking",
    "text": "4.2  Model checking\nFor linear models, we used residuals vs fitted plots to check for equal variance and linearity, normal Q-Q plots to check for normality of residuals and the Cooks distance to check for the outliers.\nFor GLMs things are a little different since GLMs have non-normal and non-constant variance (for Binomial and Poisson distributions the variance is controlled by the mean).\nTo account for the non-constant variance and be able to use diagnostic plots to check if model assumptions are met, the residuals of a GLM need to be altered. There are two ways of doing this: Pearson and Deviance residuals. These are not perfect in any way. These measures scale the residuals by the variance. Once we have scaled the residuals in this way to account for non-equal variance, they should be approximately normal.\nPearson residuals\nThese are calculated by dividing the residual (difference between observed data point \\(y_i\\) and the fitted value \\(\\hat{\\mu}\\)) but the standard deviation of the estimates \\(\\sigma_x\\):\n\\[\nRes_p = \\frac{y_i - \\hat{\\mu}}{\\sigma_x}.\n\\]\nIn \\(R\\), the Pearson residuals are obtained by:\n\nresiduals_pearson <- resid(glm_model_object, type = \"pearson\")\n\nPearson residuals follow a chi-squared (\\(\\chi^2\\)) distribution.\nDeviance Residuals\nThese are calculated by calculating the individual deviance \\(d_i\\) (the contribution of each data point to the deviance of the model) and then assigning this a direction based on the sign of the difference between the observed data point \\(y_i\\) and the fitted value \\(\\hat{\\mu}\\). :\n\\[\nRes_D = sign(y_i - \\hat{\\mu})\\sqrt{d_i}\n\\]\nwhere \\(sign(y_i - \\hat{\\mu}) = 1\\) when \\(y_i - \\hat{\\mu} > 0\\) and \\(sign(y_i - \\hat{\\mu}) = -1\\) when \\(y_i - \\hat{\\mu} < 0\\).\nThe deviance residuals are the default in the glm().\nIn \\(R\\), the Deviance residuals are obtained by:\n\nresiduals_deviance <- resid(glm_model_object, type = \"deviance\")\n\n\nTHEN SHOW SOME EXAMPLES AND SHOW IT IS NOT PERFECT. SO, INSTEAD WE CHECK OVERDISPERSION AND PLOT PREDICTIONS VS DATA.\nOverdispersion\nLooking back to the start of this section, we gave a list of assumptions of a GLM:\n\nLack of outliers\nCorrect distribution used\nCorrect link function is used\nCorrect variance function is used\nDispersion parameter is constant\nIndependence of y\n\nSome of these are the same as for linear models. But some are different. This section focuses on the two assumptions in bold above.\n\nIn Binomial and Poisson GLMs we assume that the variance is controlled by the mean. But this is not always true. It is something we need to check as part of the model checking process.\n\nTwo things can happen:\n\nWe could get overdispersion (more variation than we expect).\nWe could get less variation than we expect.\n\nThe first option is a bigger problem and something we need to correct for, if we find it.\n\n\n4.2.0.1 How do we check for overdispersion?\nTo check for overdispersion in GLMs we need to calculate the deviance. To do this we take the ratio of residual deviance and residual degrees of freedom.\nOur assumption is that the deviance = 1. So, we want a value close to that. >1.2 indicates a potential problem.\n\nWe can find these deviance values in summary() they are in the final paragraph of the output as discussed back in Part C. (link) e.g.\n\nsummary(PhoenixModel)\n\n\nCall:\nglm(formula = ClutchSize ~ Location, family = poisson(link = log), \n    data = PhoenixData)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.4495  -1.2961   0.1694   0.5491   2.3861  \n\nCoefficients:\n                 Estimate Std. Error z value Pr(>|z|)    \n(Intercept)       1.09861    0.08165  13.455  < 2e-16 ***\nLocationScotland -1.27297    0.17457  -7.292 3.06e-13 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 180.62  on 99  degrees of freedom\nResidual deviance: 116.17  on 98  degrees of freedom\nAIC: 319.86\n\nNumber of Fisher Scoring iterations: 5\n\n\nFor the example above (the phoenix model) the Deviance ratio = 116.17/98 = 1.1854082.\nWe assume a value of 1, 1.185 is just ok. Any higher and we might want to investigate further.\n\nThe main problem with overdispersion is: uncertainty. If there is more variation, the uncertainty in the estimate should be wider. However, if our model does not know there is extra variation and it is assuming something else, it will give uncertainty that is too narrow! We want the correct amount of uncertainty for our model and data.\n\nThere are a few ways to correct for overdispersion, more on that in two weeks!\nFor now, just know that it is something we should check for.\n\n\n\n\n\nContributors\nEmily G Simmonds"
  },
  {
    "objectID": "2.X_binomial_GLM.html",
    "href": "2.X_binomial_GLM.html",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "",
    "text": "Before you start\n\n\n\nBefore reading this page, you should be comfortable with basic statistical theory, using R, continuous and categorical data, and linear models.\nYou should also review the basics of the Binomial distribution here. EGS: ADD LINK."
  },
  {
    "objectID": "2.X_binomial_GLM.html#introduction",
    "href": "2.X_binomial_GLM.html#introduction",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.1 Introduction",
    "text": "5.1 Introduction\nIn this section, we will look at how we can use a Binomial Generalized Linear Model (GLM) to analyze data with a binary response and numeric explanatory variables.\n\nOn this page, we focus on one particular type of GLM, the Binomial GLM. The Binomial GLM fits a non-linear line to:\n\nestimate a relationship between \\(X\\) and \\(Y\\), where \\(Y\\) comes from binary trials and is therefore bounded between 0 and 1.\npredict change in \\(Y\\) from change in \\(X\\).\n\n\nBut unlike a linear model, the Binomial GLM does not do this with a straight line (on the scale of the data). The Binomial GLM fits a curved line bounded between 0 and 1 on the y-axis. This is because the Binomial GLM (also called a logistic regression - more on why later), the response data are the result of binary trials e.g Yes or No, anything with only two outcomes. But it can represent the result of single trials or many e.g. did an individual survive or die (1 trial), or the proportion of survivors from a population of 10 (10 trials). The \\(Y\\) values can only take values between 0 or 1 (either 0 and 1 themselves or proportions e.g. 0.1).\n\n\n\n\nFigure 5.1: Example of a fitted Binomial GLM model. The estimated relationship is plotted on the scale of the data.\n\n\n\n\n\nA large number of the models that are used in biological research are GLMs. This is because a lot of biological data would not meet the assumptions required for a linear model, for example survival data, occupancy data, or presence of a particular gene are all examples of binary responses.\nAs a result of their wide usage, GLMs are a key part of modern quantitative biology!"
  },
  {
    "objectID": "2.X_binomial_GLM.html#which-questions",
    "href": "2.X_binomial_GLM.html#which-questions",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.2  Which questions?",
    "text": "5.2  Which questions?\nExample questions that can be answered with the Binomial GLM:\nInference\n\nHow does body weight (kg) influence survival probability of sparrows?\nHow does forest cover (type) affect the occurrence probability of a plant species?\n\nPrediction\n\nWhat is the mortality of beetles exposed to different concentrations of carbon disulfide \\(CS_2\\)?"
  },
  {
    "objectID": "2.X_binomial_GLM.html#type-of-data",
    "href": "2.X_binomial_GLM.html#type-of-data",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.3  Type of data",
    "text": "5.3  Type of data\n\n\n5.3.1 Theory\nAs mentioned above, in a Binomial GLM the response data are always the result of binary trials. The values of the response variable should have either only two outcomes or be the result of many trials (a number of successes and number of failures or a proportion). Examples of this type of data would be:\n\nNumber that survived and number that died\nPresent/absent\nYes/no\nOn/off\nProportion of seedlings that germinated\n\nJust as was stated for the linear models, always remember to check that the way your variables are classified in R is the same as the format you expect.\nIn this case, there are several options that will work. The response variable \\(Y\\) can be stored as a factor, an integer, or as a continuous numeric variable.\n\n5.3.2 Worked example\nFor this worked example, we will try to find out if/how body weight (kg) influences the survival probability of Soay sheep.\n\n\n\nBiologically, it is expected that smaller sheep would find it harder to survive harsh winters as they have fewer reserves (such as body fat) than larger sheep.\n\n5.3.2.1 Introduction to the data\nThis data for this example are from 1986 to 1996 for a population of Soay sheep from the St. Kilda islands in Scotland, UK.\nThey have been monitored following a standardised protocol since 1985. Each year the sheep are caught, weighed, and the population size is counted. Information on the project can be found here. These data are open source and can be found in the appendix of this paper EGS: CITE COULSON 2012.\nThe data consists of five variables:\n\nYear - year of recording\nAge - age of the sheep in years\nSurvival - whether the sheep survived until the next year or not\nWeight - weight in kg\nPopulation size (PopSize) - number of females counted that year\n\n\nsheep_data\n\n# A tibble: 1,328 × 5\n    Year   Age Survival Weight PopSize\n   <dbl> <dbl>    <dbl>  <dbl>   <dbl>\n 1  1987    11        1   26.5     331\n 2  1988    12        0   27.2     457\n 3  1987    10        1   26       331\n 4  1988    11        0   26       457\n 5  1986     8        1   26.7     211\n 6  1987     9        0   24       331\n 7  1986     8        1   26.5     211\n 8  1987     9        1   25       331\n 9  1988    10        0   23.2     457\n10  1988    10        0   22.2     457\n# … with 1,318 more rows\n\n\nAll measures are for female sheep only.\nYou can find the data here if you want to follow along with the example. It is a .csv file with column headings.\nTo begin the analysis, let us first have a look at the data after it has been imported. We do this by looking at the raw data and making a plot. It can be easier to see the data if we jitter it because many data points sit on top of each other.\nEGS: NEED TO ADD LINE TO READ IN DATA YOU CAN GET IT FROM THE PAPER LINK ABOVE THEN HOST IT.\n\nplot1 <- ggplot(sheep_data, aes(x = Weight, y = Survival))+\n geom_point(colour = \"grey70\", size = 2, alpha = 0.25)+\n labs(x = \"Weight of sheep (kg)\",\n      y = \"Survival of sheep\",\n      tag = \"a\")\n\nplot2 <- ggplot(sheep_data, aes(x = Weight, y = Survival))+\n geom_jitter(colour = \"grey70\", size = 2, height = 0.1, alpha = 0.25)+\n labs(x = \"Weight of sheep (kg)\",\n      y = \"Survival of sheep\",\n      tag = \"b\")\n\nplot1 + plot2 + plot_layout(nrow = 1)\n\n\n\nFigure 5.2: Scatterplot of weight and against survival of sheep, plot a = raw data, plot b = jittered points\n\n\n\n\nSince we are interested in whether weight (kg) influences the survival of sheep, we will need two of the five variables in the data: Weight and Survival. We will not need Year, PopSize and Age.\nThe response variable then is Survival, which is a binary variable (it has two outcomes 0/1). The explanatory variable is Weight, which is continuous numeric."
  },
  {
    "objectID": "2.X_binomial_GLM.html#model-details",
    "href": "2.X_binomial_GLM.html#model-details",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.4  Model details",
    "text": "5.4  Model details\n\n\n5.4.1 Theory\n\nA Binomial GLM is just like all other statistical models, it aims to represent mathematically how the data that are being modelled were generated. In this case, it is assumed that the data were generated by a Binomial distribution and influenced by a relationship with some explanatory variables.\nThe sections below detail the three components of a GLM and describe what form they take for the Binomial GLM:\n\nThe systematic part: \\(\\alpha\\) + \\(\\beta\\)\\(X_i\\)\n\nThe random part: the distribution of the error\nThe link function: that links them together\n\n\nIn  it looks like this:\nglm(y ~ x, data, family = binomial(link = \"logit\"))\nthere are more details below in the fitting the model in  section.\n\nThe systematic part\nThis is the part of the model that is hopefully the most familiar, it is a linear equation just like those used in linear models.\nThis is also known as the linear predictor, \\(\\eta\\).\nAn example is \\(\\eta\\) = \\(\\alpha + \\beta_1 X_{1} + \\beta_2 X_{2}\\)\nwhere \\(\\alpha\\) = an intercept, and the \\(\\beta\\) values represent the change in \\(\\eta\\) with every unit change of \\(X\\).\n\nIn  this is written as y ~ x.\n\nThe random part\nThis part of the model represents the spread of the actual data points around the linear predictor. This random part is how we deal with the errors (residuals) of the model \\(\\varepsilon\\). In linear models, this part was assumed to be Normal. In a Binomial GLM, it is assumed to be Binomially distributed (the clue is in the name).\nThe Binomial distribution is used to represent the number of successes (\\(r\\)) from a number of independent trials (\\(N\\)) when the probability of success (\\(p\\)) is the same for each trial. We use it for data from binary trials.\nThe Binomial distribution has two parameters \\(N\\) and \\(p\\). Usually, \\(N\\) is known (it comes from the data), so there is only one unknown parameter that must be estimated. That is \\(p\\).\n\nIn  the random part of the GLM is specified by the family argument for a Binomial GLM it is family = binomial.\n\nThe Link function\nThe link function transforms the systematic part of the model onto the scale of data (called the response scale), connecting it to the random part.\nThis step is necessary because the model is non-linear. If you were to directly estimate \\(Y\\) (the response data) with a linear predictor as you do in a linear model, this would give a straight line. The straight line would not be bounded and could therefore predict values of \\(Y\\) above 1 or below 0, which does not make any sense.\nInstead, the Binomial GLM links the estimate from the linear predictor to \\(Y\\) via a link function.\nThe default link function, or canonical function, for a Binomial distribution is the logit function (hence the alternative name of logistic regression). So, in a Binomial GLM the logit of the linear predictor is linked to \\(Y\\) instead of the linear predictor itself.\n\nIn  the link is specified within the family argument, but with an extra argument called link. For a Binomial GLM with a logit link it is family = binomial(link = logit).\n\nUsing the logit link converts a probability to a log-odds. The log-odds is the natural logarithm of the odds ratio: \\[\\frac{p}{1-p}\\]. Where \\(p\\) = the probability of an event occurring.\n\nThe odds ratio is the probability of a event occurring (\\(p\\)) over the probability it doesn’t occur (\\(1-p\\)). Odds are often used in the things like betting, e.g. to represent the odds of a particular horse winning a race. An odds ratio of 10:1 means that the companies assume that for every 10 successes (for the company i.e. a horse loses and they keep the money) there will be 1 failure (the horse wins and the company has to pay).\n\nThe logit link takes the following form:\n\\[\n\\begin{aligned}\n\\mu = log(\\frac{p}{1-p})\n\\end{aligned}\n\\]\nWhere \\(\\mu\\) = the log-odds, which is the output of the model.\n\nThe inverse of the logit link is:\n\\[\n\\begin{aligned}\np = \\frac{e^{\\mu}}{1+e^{\\mu}}\n\\end{aligned}\n\\]\nOR\n\\[\n\\begin{aligned}\np = \\frac{1}{1+e^{-\\mu}}\n\\end{aligned}\n\\]\nWhere \\(p\\) = the probability of success.\nHere \\(\\mu\\) is on the link scale and \\(p\\) is on the response scale (the scale of the response variable).\n\nOther possible link functions for a Binomial GLM are the probit and cloglog functions.\nFor more information\n\nclick here\nThe Probit link\nOne way of thinking of binomial problems is as a threshold:\ne.g. imagine you have a dam, and if the water is too high, it will flow over the dam.\nTherefore a model is needed that can capture when the dam overflows (it either does or does not). What is observed, and modelled, is whether the water was too high, or not. But, hidden underneath this is a variable of water height, which is not observed. But it is water height that controls if the dam overflows or not. An unobserved variable like this is called a latent variable.\nThis idea can be used in the modeling. If the water height was observed, it could be modelled with a simple linear regression of water height against rainfall, and assume the residuals are normally distributed. But, if only data on whether this value is above a certain threshold, or not is available. It turns out that this is the same as a Binomial GLM with a probit link!\nMathematically the model is \\(Y_i = 1\\) if \\(\\mu_i > 0\\), where \\(\\mu_i\\) is the latent variable.\nThe threshold idea can be useful for interpreting models: if you think there is some unobserved variable that causes the binary response when it is above a threshold, it can be easier to understand the process.\nIn practice the estimates from the probit and logit link functions give almost the same results, even though they have different interpretations.\nThe probit uses an inverse normal link function where a higher mean = higher probability of success.\nUse when you want a threshold model because you have an unobserved variable that causes a binary response.\ncloglog\nUsing a cloglog link allows binary data to be linked to count data.\nIt is useful when the 0s and 1s actually come from counts, where the count is recorded as “0/zero” or “more than zero”. For example, the presence or absence of a species. In this case, the presence or absence is really a result of counting abundance of a species.\nThe cloglog link allows these binary data to be linked to a log(abundance) using the equations below.\n\\[\nlog(\\lambda) = log(-log(1-p))\n\\]\nWhere \\(\\lambda\\) = the mean abundance and \\(p\\) = probability of presence.\nUse when you want to link the binary data to abundance because they represent counts.\n\nAssumptions\nThere are several assumptions that should be met for the Binomial GLM to be valid.\n\nThere are no outliers\nEach value of Y is independent\nThe dispersion parameter is constant\nThe correct variance function is used (in a Binomial GLM this is assumed to be controlled by the mean)\nThe correct distribution is used (Binomial here - it is assumed that the random part of the model does follow a Binomial distribution)\n\n\nAll of these assumptions should be met for the model to work properly and they ALWAYS need to be checked. Outliers, dispersion, and variance can be checked once the model has been fitted.\nIndependence of Y should be ensured during data collection and the correct distribution is determined by the characteristics of the data.\n\nWriting the model in \nTo fit the model in , we will use the glm() function.\nglm(y ~ x, data, family = binomial(link = \"logit\"))\n\nThe glm() function takes several arguments:\n\nformula in form: y ~ x (systematic part)\ndata: your data object.\nfamily: specifies the distribution used for the random part of the model and the link function. In this case, the model uses the binomial family with a logit link.\n\n\nThe function will fit the GLM using maximum likelihood estimation and gives us the maximum likelihood estimates of \\(\\alpha\\) and \\(\\beta_is\\) as an output.\nThe formula part y ~ x, is the same as in the function lm(). The \\(y\\) is the response variable and \\(x\\) is an explanatory variable. To run the GLM in  first it is necessary to identify which variable is the response and which is/are explanatory.\n\nThere are two ways of fitting a Binomial GLM using the glm() function:\n\nOption 1: fitting response as a single factor (for single trials and proportions).\nOption 2: fitting response as two columns (for multiple trials).\n\n\nFor data with results of single trials (0s and 1s) or proportions (0-1)\nThe \\(y\\) is the response variable and is a single vector of numbers.\n\nFor data with results of multiple trials (number of successes and number of failures)\nThe \\(y\\) is still the response variable but instead of single column of 0s and 1s or proportions, there are two columns (one of successes and one of failures). The columns are combined using cbind() within the glm() function:\nglm(cbind(success, failure) ~ x, data = data,  family = binomial(link = \"logit\"))\nDoing this accounts for number of trials because glm() will also get information on the number of trials conducted (successes + failures).\n\nOnce you have an identified response and explanatory variable/variables, you can then plug these variables into the glm() function in the below format using the column names in place of response and explanatory and including your data frame name as the data argument.\nBoth modes of fitting are shown below.\n\n\n### single trial version\n\nglm_model_object <- glm(response ~ explanatory, data = your_data,\n                     family = binomial(link = \"logit\"))\n\n### multiple trials version\n\nglm_multiple_trials <- glm(cbind(successes, failures) ~ explanatory, \n                           data = example_data2,\n                     family = binomial(link = \"logit\"))\n\nRunning the glm() as illustrated above runs the GLM and saves the output as a glm_model_object.\nWe can then view our results from the model object by using the function coef(). This will take the output of the glm(), the model object, as its argument and extracts the maximum likelihood estimates of \\(\\alpha\\) and \\(\\beta\\).\n\ncoef(glm_model_object)\n\n(Intercept) explanatory \n -1.5908333   0.2032877 \n\ncoef(glm_multiple_trials)\n\n (Intercept)  explanatory \n 0.487107213 -0.005335974 \n\n\nYou can see that the format of the output is the same regardless of whether it is a Binomial GLM on a set of single trials, or multiple trials.\n\n\n5.4.2 Worked example\n\nThis worked example demonstrates how to fit a GLM in \\(R\\) using the glm() function for the Soay sheep data example. This is an example of a single trial question.\nIn this example, we are asking: Does body weight affect the survival probability of sheep?\nThe survival of the sheep (0 or 1) is the response (\\(Y\\)) and body weight (kg) (\\(X\\)) is the explanatory variable.\nWe put these variables in the glm() function in the below format.\n\nsheep_model <- glm(Survival ~ Weight, data = sheep_data, \n                   family = binomial(link = \"logit\"))\n\nWe have run the model and have assigned it to an object name. A logit link was used as these data do not come from a latent continuous variable or from counts, so we can use the default/canonical link function here.\nLet us take a look at the maximum likelihood estimates of our model parameters (\\(\\alpha\\), \\(\\beta\\)) using the coef().\n\ncoef(sheep_model)\n\n(Intercept)      Weight \n -2.1197077   0.1817796"
  },
  {
    "objectID": "2.X_binomial_GLM.html#parameters",
    "href": "2.X_binomial_GLM.html#parameters",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.5  Parameters",
    "text": "5.5  Parameters\n\n\n5.5.1 Theory\nWe introduced the model parameters of a Binomial GLM in the model theory section above: \\(\\alpha\\) = the intercept; \\(\\beta_i\\) = the slope of the model line (steepness/gradient).\n\nBut what do these parameters really mean?\nTo fully understand the parameters and what they mean, we have to note that there is a non-linear relationship between the explanatory and response variable on the scale of the observed data.\nTo interpret the parameters, we have to recall the linear predictor and the link function.\nThe linear predictor is \\(\\eta = \\color{orange}\\alpha + \\color{blue}{\\beta_i}X_i\\). The \\(\\eta\\) in this case is the log-odds of the probability of success (\\(p\\)).\\(p\\) is what we are trying to estimate.\n\nThat is:\n\\[\nlog\\bigg(\\frac{p}{1-p}\\bigg) = \\eta = \\color{orange}\\alpha + \\color{blue}{\\beta}X_i.\n\\]\nYou might recognise the first part of this formula from the introduction of the logit link function above, it is the logit link. Note that on the scale of the link, the model line will be straight. However, on the response scale will be curved.\nTo relate the linear predictor back to the response scale of the data and \\(p\\). It is necessary to take the inverse of the link function like using the below equation:\n\\[\np = \\frac{1}{1 + e^{- \\eta}} = \\frac{1}{1 + e^{-(\\color{orange}\\alpha + \\color{blue}{\\beta}X_i)}}.\n\\]\nTherefore, it is possible to interpret the parameters on the response scale or on the link scale. We will discuss both options here.\n\nParameters on the logit scale\nOn the logit scale, the response will be the log odds of \\(Y\\).\nTo get to the log odds there are a few steps.\n\nWe need the probability of success: \\(\\frac{1}{(1+10)}\\) = \\(0.09\\)\nNext we use that probability to find the odds: \\(\\frac{0.09}{(1-0.09)} = 0.0989\\)\nTo get to the log odds, we take the log of 2: \\(log(\\frac{0.09}{(1-0.09)}) = -2.31\\)\n\nStep 3 should look familiar. It is the same as the link function in the Binomial GLM.\n\n\\(\\alpha\\), the intercept\nThis is the parameter that gives the value of the log odds of \\(Y\\) when \\(X = 0\\).\n\\(\\beta\\), the slope\nThis gives the amount of change in the log odds of \\(Y\\) as the value of \\(X\\) changes by one unit.\n\n\n\n\nFigure 5.3: Example of a Binomial GLM model line on the logit scale. Intercept in orange and slope in blue\n\n\n\n\n\nParameters on the response scale\nOn the response scale, the response will be \\(Y\\), which is a probability of success (e.g. survival, presence etc).\n\\(\\alpha\\), the intercept\nTo find the expected value of \\(Y\\) when \\(X = 0\\). You need to convert the estimate of \\(\\alpha\\) from the logit scale back to the response scale using the equation for the inverse of the logit link: e.g.\n\\[\np = \\frac{1}{1+e^{-(\\alpha)}}\n\\]\nThis can be done in R.\n\n# estimate of the intercept on logit scale (log odds of y)\n\ncoef(glm_model_object)[1]\n\n(Intercept) \n  -1.590833 \n\n# convert to response scale (a probability of success)\n\n1/(1 + exp(-(coef(glm_model_object)[1])))\n\n(Intercept) \n  0.1692667 \n\n\n\n\\(\\beta\\), the slope\nOn the response scale the slope parameter has a somewhat different meaning. On the logit scale, the slope captured a linear relationship. However, on the response scale, the relationship between \\(X\\) and \\(Y\\) is not linear. As a result, the gradient of the model line will be different for different \\(X\\) values (see Figure 5.4).\n\n\n\n\nFigure 5.4: Example of a Binomial GLM model line on the scale of the response data. Intercept in orange and slope in blue\n\n\n\n\n\nThe estimate of the \\(\\beta\\) coefficient on the logit scale, will tell you about the strength and direction of the relationship between \\(X\\) and \\(Y\\). This is the case even though this relationship will not be linear on the response scale.\nTo see the change in slope of the model line on the response scale you can predict values of \\(Y\\) on the response scale and either plot the relationship (like above in Figure 5.4) or simply look at the change between two \\(X\\) values.\ne.g.\n\n# predict log odds of Y when X = 2 or X = 3\n# use a linear equation for this\n\nodds_y_x2 <- coef(glm_model_object)[1] + (coef(glm_model_object)[2]*2)\nodds_y_x3 <- coef(glm_model_object)[1] + (coef(glm_model_object)[2]*3)\n\n# estimate of probability of success when X = 2\n# take inverse of the logit link\n\nprob_X2 <- 1/(1 + exp(-odds_y_x2))\n\n# estimate of probability of success when X = 3\n\nprob_X3 <- 1/(1 + exp(-odds_y_x3))\n\n# slope from X = 2 to X = 3 on response scale\n\nprob_X3 - prob_X2\n\n(Intercept) \n 0.03841184 \n\n\nIf you were to repeat the example above for \\(X\\) = 10 and \\(X\\) = 11, you would not get the same slope on the response scale. Even though it is the same on the logit scale.\n\n\n5.5.2 Worked example\nIn the previous section, we fit a Binomial GLM using the glm() function and looked at the estimates of some parameters using the coef() function. In this section, we will use the model theory to interpret what those parameters mean.\n\n5.5.2.1 The intercept\n\nFor our sheep data model, the estimate of the intercept is:\n\ncoef(sheep_model)[1]\n\n(Intercept) \n  -2.119708 \n\n\nThis is the estimate of the log odds of survival for a sheep which has a body weight of 0 kg. The intercept estimate is a log odds of -2.1197077 of survival for a sheep that weighs 0 kg.\nTo get the probability of survival for a sheep with a body weight of 0 kg we need to convert these estimates to the response scale using the code below:\n\n1/(1+exp(-coef(sheep_model)[1]))\n\n(Intercept) \n   0.107196 \n\n\nIn other words, the survival probability of a sheep is 0.107196 when their weight is 0 kg.\nIn this example, the intercept is not very interesting, as it does not make a lot of biological sense to know the expected survival probability of sheep when their weight is 0 kg. A sheep born at anytime will weigh more than 0 kg.\n\n5.5.2.2 The slope\n\nThe estimate of the slope of the relationship between body weight and survival probability is interesting to us since it can tell us the direction and the strength of the effect of body weight on survival of the sheep.\n\ncoef(sheep_model)[2]\n\n   Weight \n0.1817796 \n\n\nIn this case, our model estimates that the log odds of the survival of the sheep increases by 0.1817796 when the weight of the sheep increases by 1 kg. This shows a positive relationship between body weight and survival probability.\nTo see what this effect looks like on the response scale, it is easiest to plot the results using predictions on the response scale (response scale). This is what we do below.\n\n5.5.2.3 Plotting the Results\nAs well as looking at the maximum likelihood estimates of the parameters from the Binomial GLM, we can also plot the results. This is especially useful for interpreting the results on the response data scale.\nTo do this, we use the ggplot() with geom_line() and the predict() function.\nTo make the first plot, we will only need to use two arguments:\n\n\nobject = your model object\n\ntype = “link”, which means predict on the link scale or “response”, which means predict on the response scale.\n\nWe will make predictions on both the link and response scale so that we can compare the results.\n\nsheep_data <- mutate(sheep_data, \n                     predictions_link = predict(sheep_model, \n                                            type = \"link\"),\n                     predictions_response = predict(sheep_model, \n                                            type = \"response\"))\n\nOnce we have created predictions of \\(Y\\) from the model object, we can plot these using geom_line() as in the code below.\n\nlink <- ggplot(sheep_data, aes(x=Weight, y=predictions_link))+\n  geom_line(aes(y=predictions_link), colour = \"blue\")+\n  labs(x = \"Weight (kg)\", y = \"Log Odds of Survival\")\n\nresponse <- ggplot(sheep_data, aes(x=Weight, y=Survival))+\n  geom_jitter(colour = \"grey70\", size = 2,\n              height = 0.05)+\n  geom_line(aes(y=predictions_response), colour = \"blue\")+\n  labs(x = \"Weight (kg)\", y =\"Survival Probability\")\n\nlink + response + plot_layout(nrow = 1)\n\n\n\nFigure 5.5: a) Plot of fitted GLM line on the logit scale b) Plot of jittered raw data and fitted GLM line for the soay sheep data on the response scale\n\n\n\n\n\nIn the next section, we will look at how to add uncertainty to these plots and our interpretation."
  },
  {
    "objectID": "2.X_binomial_GLM.html#quantify-uncertainty",
    "href": "2.X_binomial_GLM.html#quantify-uncertainty",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.6  Quantify uncertainty",
    "text": "5.6  Quantify uncertainty\n\n\n5.6.1 Theory\nAs was discussed for linear models, statistics does not give a single correct answer. When we estimate the parameters in our statistical model, there will be many plausible parameters that could have produced our observed data. In these cases, some of the parameters will be more likely than the others to have generated the observed data.\nThe Binomial GLM is no exception. We will have to consider and present the uncertainty in the parameters we estimate.\nThe glm()function uses maximum likelihood estimation for the parameter estimation. Therefore, our consideration of uncertainty for these models are discussed here. We will therefore quantify uncertainty using standard errors, confidence intervals and prediction intervals which should be familiar to you but head to the uncertainty pages if you need a recap.\nJust as with linear models there are two different types of uncertainty we will look at uncertainty in the model line of parameters \\(\\alpha\\) and \\(\\beta\\) and uncertainty in a prediction of \\(Y\\).\n\nUncertainty in the estimates of \\(\\alpha\\) and \\(\\beta\\)\nTo find the standard errors for the estimates of \\(\\alpha\\) and \\(\\beta\\) we can use summary() function. This takes the model object from the glm() as its argument. It outputs a big table with lots of information. The first line gives the formula used for the model object. The second line shows the summary of the residuals of the model and the standard errors are shown in the second column of the third part, Coefficients:.\n\nsummary(glm_model_object)\n\n\nCall:\nglm(formula = response ~ explanatory, family = binomial(link = \"logit\"), \n    data = your_data)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.98905  -1.04140   0.00328   1.01222   1.75292  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.59083    0.52309  -3.041  0.00236 ** \nexplanatory  0.20329    0.06106   3.329  0.00087 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 138.63  on 99  degrees of freedom\nResidual deviance: 124.79  on 98  degrees of freedom\nAIC: 128.79\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nBy taking the summary() of the example model, we can see the standard error of the intercept (\\(\\alpha\\)) is 0.52, and the standard error for the slope (\\(\\beta\\)) is 0.06.\nWe also observe that the standard error is smaller than the estimated effects. Actually, to indicate a clear direction of the effect, the standard error should be less than half the size of the estimated coefficient. This would ensure that 95% confidence intervals for the effect (see below) do not span 0.\n\nConfidence intervals\nFor interpretation of the uncertainty, it can be easier to use the standard error to calculate confidence intervals. Confidence intervals indicate the range of plausible values for a parameter. They represent an interval, that if you were to collect a sample and run the analysis, then repeat that many many times AND each time draw a confidence interval, on average 95% of the time, the true population value of the parameter would be found in within the confidence interval.\n\nTo calculate a confidence interval from a standard error you need to use the formulas (this is exactly the same as for linear models):\n\\[\n\\begin{aligned}\nUpperCI = estimate + (1.96 SE) \\\\\nLowerCI = estimate - (1.96 SE) \\\\\n\\end{aligned}\n\\]\nRemember that the estimates of the coefficients are for the effect of \\(X\\) on the log odds of \\(Y\\) (i.e. on the link scale). Therefore any measures of uncertainty are also on the link scale. After estimating the upper and lower confidence intervals of these parameters, it might be useful to convert them to the response scale to understand their effect. This is especially true for the intercept (\\(\\alpha\\)).\n\nUsing the confint() function it is possible to display the 95% confidence intervals for the intercept and slope.\n\nconfint(glm_model_object)\n\n                  2.5 %     97.5 %\n(Intercept) -2.68608847 -0.6222264\nexplanatory  0.09118142  0.3320830\n\n\n\nPlotting uncertainty in \\(\\alpha\\) and \\(\\beta\\)\nThe above section has shown how you can quantify uncertainty in the line parameters of a Binomial GLM as numbers. But often in science, it is clearer to show these things visually.\nWe can add the confidence intervals to Figure 5.3 showing our GLM fitted line. This can be done either on the link scale or the response scale.\nTo do this, we need to generate new predictions with the predict() function. We also need to calculate the upper and lower confidence interval bounds using the standard error.\nThis is a little different to using predict() for a linear model object. For GLMs there are some different arguments. The key arguments are:\n\n\ntype. This argument can take values “link” (gives predictions on the link scale), “response” (gives predictions on the response scale) or “terms” (gives a matrix of the fitted values of each term in the model formula on the link scale).\n\nse.fit. This argument can be TRUE or FALSE and indicates whether the standard error for the prediction should be given in addition to the mean prediction. The standard error will be on the scale of the mean prediction i.e. either link scale or response dependent on which type was specified.\n\n\nThe interval argument that was used for linear model objects to specify a prediction or a confidence interval does not work for predictions on a GLM object. Therefore, the standard errors presented are for a 95% confidence interval.\n\n# First create the new data to predict for \n# This example generates 100 values of the explanatory variable from min to max\n\nnewdata <- data.frame(explanatory = seq(min(example_data$explanatory),\n                                        max(example_data$explanatory),\n                                        length.out = 100))\n\n# Then add predictions to the newdata for the link and response scale\n# REMEMBER the confidence intervals too, you can access these by taking the \n# $se.fit of the results of `predict`, $fit is the mean prediction\n\npredictions <- newdata %>% mutate(predictions_link = predict(glm_model_object, \n                                                         newdata = newdata, \n                                                         type=\"link\", \n                                                         se.fit=TRUE)$fit,\n                              SE_link = predict(glm_model_object, \n                                                         newdata = newdata, \n                                                         type=\"link\", \n                                                         se.fit=TRUE)$se.fit,\n                              predictions_response = predict(glm_model_object, \n                                                         newdata = newdata, \n                                                         type=\"response\", se.fit=TRUE)$fit,\n                              SE_response = predict(glm_model_object, \n                                                         newdata = newdata, \n                                                         type=\"response\",\n                                                         se.fit=TRUE)$se.fit) %>%\n                as_tibble()\n\n\n\npredictions\n\n# A tibble: 100 × 5\n   explanatory predictions_link SE_link predictions_response SE_response\n         <dbl>            <dbl>   <dbl>                <dbl>       <dbl>\n 1       -4.12            -2.43   0.759               0.0811      0.0566\n 2       -3.88            -2.38   0.745               0.0848      0.0578\n 3       -3.64            -2.33   0.731               0.0887      0.0591\n 4       -3.40            -2.28   0.717               0.0927      0.0603\n 5       -3.16            -2.23   0.703               0.0968      0.0615\n 6       -2.92            -2.18   0.690               0.101       0.0627\n 7       -2.68            -2.14   0.676               0.106       0.0639\n 8       -2.44            -2.09   0.662               0.110       0.0650\n 9       -2.20            -2.04   0.648               0.115       0.0661\n10       -1.96            -1.99   0.634               0.120       0.0671\n# … with 90 more rows\n\n\n\nYou should notice that all predictions on the response scale around bounded between 0 and 1, but this is not the case on the link scale.\n\nThen you can plot these. Remember these are confidence intervals not prediction intervals. The predict function will not give prediction intervals for a GLM. In fact, it is not always an easy or sensible thing to create in this context, especially for a Binomial GLM. When the mean prediction is close to 0 or 1, the prediction interval can easily fill the whole possible value space (i.e. span from 0 right to 1), which is not very logical and is hard to interpret.\nTo get the upper and lower bounds of the confidence interval from a GLM using predict() you need to calculate the bounds yourself. You need to add or subtract 1.96 times the standard error from the mean prediction.\n\npredictions <- predictions %>% mutate(upper_ci_link = predictions_link + (2*SE_link),\n                                      lower_ci_link = predictions_link - (2*SE_link),\n                                      upper_ci_response = predictions_response + (2*SE_response),\n                                      lower_ci_response = predictions_response - (2*SE_response))\n\n# plot predictions on the link scale \n\nexample_predictions_link <- ggplot(data = predictions, \n                                 aes(x = explanatory, \n                                     y = predictions_link))+\n  geom_line(color=\"blue\")+\n  geom_ribbon(aes(ymin = lower_ci_link, \n                  ymax = upper_ci_link), \n              alpha = 0.5)+\n  labs(title = \"A. Predictions on link scale\",\n       y = \"Log odds of response\",\n       x = \"Explanatory\")\n\n# For this plot, the base can be the response data\nexample_predictions_response <- ggplot() +\n  geom_jitter(data = example_data, \n              aes(x = explanatory, y = response), \n              colour = \"grey\", size = 2, height = 0.01) +\n  geom_ribbon(data = predictions,\n              aes(x = explanatory,\n                  ymin = lower_ci_response, \n                  ymax = upper_ci_response), \n              alpha = 0.5) +\n  geom_line(data = predictions, \n            aes(x = explanatory, y = predictions_response), \n            colour = \"blue\") +\n  labs(title = \"B. Predictions on response scale\",\n       y = \"Probability\",\n       x = \"Explanatory\")\n\nexample_predictions_link + example_predictions_response\n\n\n\nFigure 5.6: Examples of plots of fitted GLM line and 95% confidence intervals (grey shaded area) on the link scale (A) and on the response scale (B)\n\n\n\n\n\n5.6.2 Worked example\nAt the end of the last section, we created of our sheep model and looked at the estimated model line. Now we will add uncertainty to that plot.\nFirst, we should look at the confidence intervals of our parameter estimates.\n\nround(confint(sheep_model),2)\n\n            2.5 % 97.5 %\n(Intercept) -2.63  -1.62\nWeight       0.15   0.21\n\n\nThe confidence interval has been rounded to two decimal places to make it easier to read.\nTo add these intervals to the plot, we need to make new predictions including the upper and lower bounds of the prediction interval. We will do this on the link scale and the response response scale.\n\n# first make some new data to predict for\nnewdata <- data.frame(Weight = seq(min(sheep_data$Weight),\n               max(sheep_data$Weight),\n               length.out = 100))\n\nsheep_predictions <- newdata %>% \n  mutate(predictions_link = predict(sheep_model,\n                                    newdata,\n                                    type=\"link\", \n                                    se.fit = TRUE)$fit,\n            # the next lines add the lower and upper ci bounds\n            lower_ci_link = predict(sheep_model,\n                                    newdata,\n                                    type=\"link\", \n                                    se.fit = TRUE)$fit - \n                                    (1.96*predict(sheep_model,\n                                    newdata,\n                                    type=\"link\", \n                                    se.fit = TRUE)$se.fit),\n            upper_ci_link = predict(sheep_model, \n                                    newdata,\n                                    type=\"link\", \n                                    se.fit = TRUE)$fit + \n                                    (1.96*predict(sheep_model,\n                                    newdata,\n                                    type=\"link\", \n                                    se.fit = TRUE)$se.fit),\n            # then predict on the response scale\n            predictions_response = predict(sheep_model,\n                                    newdata,\n                                    type=\"response\", \n                                    se.fit = TRUE)$fit,\n            # and add the confidence interval bounds\n            lower_ci_response = predict(sheep_model,\n                                    newdata, \n                                    type=\"response\", \n                                    se.fit = TRUE)$fit - \n                                    (1.96*predict(sheep_model,\n                                    newdata,\n                                    type=\"response\", \n                                    se.fit = TRUE)$se.fit),\n            upper_ci_response = predict(sheep_model,\n                                    newdata, \n                                    type=\"response\", \n                                    se.fit = TRUE)$fit + \n                                    (1.96*predict(sheep_model,\n                                    newdata,\n                                    type=\"response\", \n                                    se.fit = TRUE)$se.fit))\n\n\nOnce we have created predictions of \\(Y\\) from the model object, we can plot them using geom_line() and geom_ribbon() as in the code below.\n\n# Plot of Confidence Intervals on the link scale\n\nsheep_predictions_link <- ggplot(data = sheep_predictions, \n                                 aes(x = Weight, \n                                     y = predictions_link))+\n  geom_line(color=\"blue\")+\n  geom_ribbon(aes(ymin = lower_ci_link, \n                  ymax = upper_ci_link), \n              alpha = 0.5)+\n  labs(title = \"A. Predictions on link scale\",\n       y = \"Log odds of survival\",\n       x = \"Body weight (kg)\")\n\n# For this plot, the base can be the response data\nsheep_predictions_response <- ggplot() +\n  geom_jitter(data = sheep_data, \n              aes(x = Weight, y = Survival), \n              colour = \"grey\", size = 2, height = 0.01) +\n  geom_ribbon(data = sheep_predictions,\n              aes(x = Weight,\n                  ymin = lower_ci_response, \n                  ymax = upper_ci_response), \n              alpha = 0.5) +\n  geom_line(data = sheep_predictions, \n            aes(x = Weight, y = predictions_response), \n            colour = \"blue\") +\n  labs(title = \"B. Predictions on response scale\",\n       y = \"Probability of survival\",\n       x = \"Body weight (kg)\")\n\n\nsheep_predictions_link + sheep_predictions_response\n\n\n\nFigure 5.7: A. plot of the fitted GLM line on the link scale including 95% confidence interval (grey), B. plot of the fitted GLM line on the response scale including 95% confidence interval (grey)\n\n\n\n\nIt can be observed from the figure above that the confidence intervals for the predictions around \\(1\\) are very narrower. This means that as we get closer to the true classification (0 or 1), we are able to estimate them with much certainty."
  },
  {
    "objectID": "2.X_binomial_GLM.html#model-checking",
    "href": "2.X_binomial_GLM.html#model-checking",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.7  Model checking",
    "text": "5.7  Model checking\n\n\n5.7.1 Theory\nUntil this point, we have run a Binomial GLM, got parameter estimates and quantified uncertainty. Next, we will look at how to know if the model is any good. To do this, we need to check if the assumptions for a Binomial GLM are met for our data.\n\nTo check the assumptions of a Binomial GLM, we will follow the same procedure as for GLMs more broadly. For a reminder of this, go back to the Introduction to GLMs page.\n\nThe first step is to:\nPlot the model predictions and the data together\nFrom this plot, it is possible to test:\n\nthat the fitted model line is capturing the relationship between x and y on the response scale\n\n\nTo do this, we can re-plot the example plot from the section above.\n\nexample_predictions_response +\n    labs(title = \"Model predictions and data on response scale\")\n\n\n\nFigure 5.8: plot of the fitted GLM line on the response scale including 95% confidence interval (grey)\n\n\n\n\nIf you look carefully at Figure 5.8 you can see that there are more data points that are 0 for the response for negative values of the explanatory variable. As the values of the explanatory variable increase, we find progressively more 1 values for the response. Therefore, we would expect a model line that that an intercept of close to 0 on the response scale and then shows a positive relationship between x and y, reaching an asymptote (levelling off) at a response value of 1 at the extreme end of the observed values of the explanatory variable (around 20). This is exactly what the fitted model line does! Therefore, in this case, it is possible to see that the model fits the data quite well.\n\nNote that if you had proportional data or those from multiple trials that the data points might be distributed around the fitted line.\nThen it would be possible to also test:\n\nwhether the data points are evenly distributed around the fitted line\n\n\nggplot(aes(x = explanatory, y = successes/(successes + failures)), \n       data = example_data2)+\n  geom_point(shape = 16)+\n  geom_smooth(method=stats::glm, method.args = list(family=\"binomial\"), \n              se=TRUE)\n\n\n\nFigure 5.9: plot of the fitted GLM line on the response scale with proportional response, including 95% confidence interval (grey)\n\n\n\n\n\nIn this example, the fit is much worse. Although there are an even number of data points above and below the fitted model line, they are very widely spread away from it. The model line does not seem to be explaining the data well, that is partly because there is so little data (only 10 data points). But hopefully shows what a less well fitting model looks like.\n \nThe second step for checking model assumptions is:\n\nOverdispersion\nChecking for overdispersion tests if these assumptions are met:\n\nCorrect variance function is used\nDispersion parameter is constant\n\nIn a Binomial GLM it is assumed that the variance is controlled by the mean. But this is not always true. It is something we need to check as part of the model checking process.\n\nTo check for overdispersion in GLMs we need to calculate the deviance ratio. This is done by taking the ratio of residual deviance and residual degrees of freedom.\nThe assumption is that the deviance = 1 for Binomial GLMs. Values higher than 2 indicates that the residuals likely have more dispersion than expected. But there is no fixed threshold for when overdispersion is occurring, each researcher has to decide on their own how high a deviance ratio is a problem.\n\nThe deviance values are found in summary() at the bottom of the table\n\nsummary(glm_model_object)\n\n\nCall:\nglm(formula = response ~ explanatory, family = binomial(link = \"logit\"), \n    data = your_data)\n\nDeviance Residuals: \n     Min        1Q    Median        3Q       Max  \n-1.98905  -1.04140   0.00328   1.01222   1.75292  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.59083    0.52309  -3.041  0.00236 ** \nexplanatory  0.20329    0.06106   3.329  0.00087 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 138.63  on 99  degrees of freedom\nResidual deviance: 124.79  on 98  degrees of freedom\nAIC: 128.79\n\nNumber of Fisher Scoring iterations: 4\n\n\n\nFor the example above the Deviance ratio = 124.79/98 = 1.2733673.\nThis value is a bit above 1, but much lower than 2, so the dispersion assumption seems to be met in the example.\n\n\n5.7.2 Worked example\n\nUsing the theory covered in the previous section, we can now check our sheepModel to ensure that it meets the assumptions of a Binomial GLM.\n\nFirst, we will look again at the plot of the model predictions and the data together.\n\n\nsheep_predictions_response +\n  labs(title = \"Model predictions on response scale\")\n\n\n\nFigure 5.10: Plot of the fitted GLM line on the response scale including 95% confidence interval (grey)\n\n\n\n\n\nThe fit of this model is perhaps a little harder than the example in the theory section. This is partly caused because there is more data, so it overlaps a lot.\n\nggplot() +\n  geom_jitter(data = sheep_data, \n              aes(x = Weight, y = Survival), \n              colour = \"grey70\", size = 2, height = 0.1) +\n  geom_ribbon(data = sheep_predictions,\n              aes(x = Weight,\n                  ymin = lower_ci_response, \n                  ymax = upper_ci_response), \n              alpha = 0.5) +\n  geom_line(data = sheep_predictions, \n            aes(x = Weight, y = predictions_response), \n            colour = \"blue\") +\n  labs(title = \"Model predictions on response scale\",\n       y = \"Probability of survival\",\n       x = \"Body weight (kg)\")\n\n\n\nFigure 5.11: Plot of the fitted GLM line on the response scale including 95% confidence interval (grey)\n\n\n\n\n\nIf we increase the jitter of the points from 0.01 to 0.1, it becomes a bit easier to see the pattern. Now it is possible to see there are many more data points with a response value of 1, than there are data points with a response value of 0. There are especially few response values of 0 (death) for sheep with a body weight above 25kg. Very few of these big sheep die.\nSo, we would expect a model line to fit well, if it captures small sheep having a lower survival change than big sheep. It seems that the model does capture the data quite well in this case.\n\nNext, we should check overdispersion.\n\nsummary(sheep_model)\n\n\nCall:\nglm(formula = Survival ~ Weight, family = binomial(link = \"logit\"), \n    data = sheep_data)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-2.7799   0.2793   0.4854   0.7191   1.6256  \n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -2.11971    0.25498  -8.313   <2e-16 ***\nWeight       0.18178    0.01434  12.680   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1445.6  on 1327  degrees of freedom\nResidual deviance: 1251.5  on 1326  degrees of freedom\nAIC: 1255.5\n\nNumber of Fisher Scoring iterations: 4\n\n\nThe deviance ratio for the sheep model is:\n1251.5/1326 = 0.943816.\nThis is actually slightly below the expected dispersion of 1, but it is pretty close. So, it seems the dispersion assumption is met for the sheep model.\n\nIn the next section we will interpret our results."
  },
  {
    "objectID": "2.X_binomial_GLM.html#draw-conclusions",
    "href": "2.X_binomial_GLM.html#draw-conclusions",
    "title": "\n5  Binomial generalized linear models\n",
    "section": "\n5.8  Draw conclusions",
    "text": "5.8  Draw conclusions\n\n5.8.1 Theory\n\nIn the previous sections you learned how to run a Binomial GLM, what the parameters of the model mean, how to quantify uncertainty in the parameters, and how to check the assumptions of the model. Now, we can bring everything together to draw some conclusions.\n\nThere are several components required in drawing a conclusion:\n\nstatement of the maximum likelihood estimate of the parameters of interest (including strength and direction).\nstatement of the uncertainty in the estimate\nlink the results to biology and the question asked\nDiscussion of next directions\n\n\n\n5.8.2 Worked example\n\nThis is the final section of our analysis of the data on survival of sheep. We will now bring together all of the results we have obtained and draw a conclusion following the same format as the in the theory section.\nA reminder, we were asking: Does weight influence survival of Soay sheep?\n\nThe maximum likelihood estimate of the relationship between weight and survival probability is 0.1817796. In other words, for every 1 kg increase in body weight, the log-odds of the survival of the sheep increases by 0.18.\nOn the response scale this increase is non-linear and is better shown with a graph.\n\nsheep_predictions_response +\n  labs(title = \"Model predictions on response scale\")\n\n\n\nFigure 5.12: Plot of the fitted GLM line on the response scale including 95% confidence interval (grey)\n\n\n\n\n\nHere it is clearer to see the increase in survival probability with body weight. The increase in survival is steepest for smaller sheep, levelling off after around 25kg at a 0.95 probability of survival in a given year for these big sheep.\n\nWhen we look at the uncertainty in this estimate, we see the 95% confidence interval is 0.15, 0.21. The confidence interval limits are same sign, meaning that 0 is not included as a plausible value for the strength of the relationship. Therefore, we can conclude that weight has seems to have a positive impact on the survival of sheep.\n\nIn model checking, all the assumptions of the Binomial GLMs were met. The model was not overdispersed, the data are Binomial (coming from single trials) and the fitted model line captured the pattern of the data well.\nIt should be noted that there is also data on Age in the Soay sheep dataset. It is reasonable to assume that Age and Body weight have some relationship. Older sheep are likely to be bigger than new lambs. Therefore, it might be good to also include Age in the model possibly conducting model selection to decide if this variable is needed.\n\n\n\n\n\n\nWhat’s next?\n\n\n\n\n\nPoisson Generalized linear models for analyses when your response variable is not normally distributed.\n\n\n\n\n\n\n\n\n\nFurther reading\n\n\n\n\n\n\n\n\n\n\nContributors\n\nKwaku Peprah Adjei (lead)\nEmily G. Simmonds\nBob O’Hara"
  }
]