<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-0.9.592">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Statistics in R - 9&nbsp; Maximum likelihood estimation”</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./2.X_binomial_GLM.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">
<span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Maximum likelihood estimation”</span>
</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Statistics in R</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/biostats-r/biostats" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
<li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
    </ul>
<a href="" class="quarto-color-scheme-toggle sidebar-tool" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Statistics in R</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Introduction</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0.1_introduction_to_stats.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Introduction to statistics</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./0.2_types_of_data.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Types of data</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Descriptive statistics</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./1.0_descriptive_statistics.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Descriptive Statistics</span></a>
  </div>
</li>
    </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
    <div class="sidebar-item-container"> 
        <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">Regression models</a>
      <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true">
        <i class="bi bi-chevron-right ms-2"></i>
      </a>
    </div>
    <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.1_simple_linear_regression.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Simple linear Regression</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.2_anova.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Anova</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.X_introduction_to_GLMs.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Introduction to generalised linear models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.X_binomial_GLM.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Binomial generalized linear models</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./2.X_mle.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Maximum likelihood estimation”</span></a>
  </div>
</li>
    </ul>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#before-you-start" id="toc-before-you-start" class="nav-link active" data-scroll-target="#before-you-start"> <span class="header-section-number">9.0.1</span> Before you start</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"> <span class="header-section-number">9.1</span> Introduction</a></li>
  <li><a href="#what-is-a-likelihood" id="toc-what-is-a-likelihood" class="nav-link" data-scroll-target="#what-is-a-likelihood"> <span class="header-section-number">9.2</span> What is a likelihood?</a></li>
  <li>
<a href="#why-do-we-maximize-it" id="toc-why-do-we-maximize-it" class="nav-link" data-scroll-target="#why-do-we-maximize-it"> <span class="header-section-number">9.3</span> Why do we maximize it?</a>
  <ul class="collapse">
<li><a href="#why-log-likelihood" id="toc-why-log-likelihood" class="nav-link" data-scroll-target="#why-log-likelihood"> <span class="header-section-number">9.3.1</span> Why log likelihood?</a></li>
  <li><a href="#finding-the-maximum" id="toc-finding-the-maximum" class="nav-link" data-scroll-target="#finding-the-maximum"> <span class="header-section-number">9.3.2</span> Finding the maximum</a></li>
  </ul>
</li>
  <li>
<a href="#worked-examples" id="toc-worked-examples" class="nav-link" data-scroll-target="#worked-examples"> <span class="header-section-number">9.4</span> Worked examples</a>
  <ul class="collapse">
<li><a href="#example-1" id="toc-example-1" class="nav-link" data-scroll-target="#example-1"> <span class="header-section-number">9.4.1</span> Example 1</a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title d-none d-lg-block">
<span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Maximum likelihood estimation”</span>
</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i></button></div></div>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><section id="before-you-start" class="level3 facta toc-ignore" data-number="9.0.1"><h3 class="facta toc-ignore anchored" data-number="9.0.1" data-anchor-id="before-you-start">
<span class="header-section-number">9.0.1</span> Before you start</h3>
<p>You should be familiar with basic statistical theory, basics of R, and probability distributions. You should be able to explain the meaning of: a population, a sample, a parameter, and statistical inference. If you can’t, head <a href="">here</a> first.</p>
<p></p>
</section><section id="introduction" class="level2" data-number="9.1"><h2 data-number="9.1" class="anchored" data-anchor-id="introduction">
<span class="header-section-number">9.1</span> Introduction</h2>
<p>In this section, we will discuss what maximum likelihood estimation is and look at why and how we use it in statistical modeling.</p>
<p><span style="color:blue">Could use something like the globe example to set this up including the shiny app. Maybe we can think of a different binary example that’s easy to understand?</span></p>
<p><span style="color:blue">I suggest as well as the example, that we spend a bit of time here setting the background estimating parameters. I will try and make a separate page on samples, populations, and statistical inference. So, you should be able to reference that rather than explain everything from scratch.</span></p>
</section><section id="what-is-a-likelihood" class="level2" data-number="9.2"><h2 data-number="9.2" class="anchored" data-anchor-id="what-is-a-likelihood">
<span class="header-section-number">9.2</span> What is a likelihood?</h2>
<p>The <strong>likelihood</strong> is a fundamental concept in statistics. It is defined as: ‘the probability of obtaining the observed data, given a particular parameter value.’ It is an equation that mathematically represents how the data were generated. We base the form of this equation on assumptions we make about the processes causing our observations. The likelihood assumes that the data are random and the parameters are fixed.</p>
<p></p>
<p><span style="color:blue">It would be nice to then have a short and simple example here e.g.&nbsp;how we assume data with two outcomes are generated following a binomial distribution. So, some of the equations from further down could come up here to show what a likelihood is as an equation.</span></p>
</section><section id="why-do-we-maximize-it" class="level2" data-number="9.3"><h2 data-number="9.3" class="anchored" data-anchor-id="why-do-we-maximize-it">
<span class="header-section-number">9.3</span> Why do we maximize it?</h2>
<p><span style="color:blue">In this section, I would illustrate how you can calculate parameters of a distribution like the Binomial or Normal or Poisson. Maybe keep the same example as above? I would then ask how confident the students<br>
would be that they have the ‘best’ answer for the population parameter from their sample. Give an example of sampling again and show that the estimate changes. Talk about estimator and estimand. Basically, it is about finding the parameter values that make the observed data most likely (as you explain nicely below)</span></p>
<p></p>
<p>Maximum likelihood estimation (MLE) is a technique used for estimating the parameters for a given distribution, using some observed data. Hence, MLE allows you to estimate population parameters from sample data such that the probability (likelihood) of obtaining the observed data is maximized.</p>
<p></p>
<p>Let’s suppose that a population is following a normal distribution but its mean and variance are unknown. MLE can be used to estimate them from a sample of the population. It looks for values of the mean and variance so that the observation is the most likely to occur.</p>
<p></p>
<p><span style="color:blue">The below is a nice example. I would not mention ‘guessing’ as really we are using a fixed mathematical process. I think it is simpler to keep one example all through and then give the code and equations for other distributions at the end e.g.&nbsp;use Binomial throughout then have Poisson and Normal at the end?</span></p>
<p>Let’s Suppose we have data points from a normal distribution. The data points are shown in the figure 2 below (the R code that was used to generate the image is provided as well). To get an intuition of MLE,we suggest different sets of normal distribution parameters (mean and variance), we plot the curves corresponding to each set and we try to guess which of them would maximize the probability of observing the data. In other words, we want to find the values of mean and variance that result in the curve that best fits the data. </p>
<div class="cell">
<div class="cell-output-display">
<p><img src="2.X_mle_files/figure-html/unnamed-chunk-2-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Figure 2: Example of data points (blue dots) and fits from different normal distribution curves generated from different sets of parameter values (f ∼ N (10, 2.25), f1 ∼ N (10, 9), f2 ∼ N (10, 0.25) and f3∼ N (8, 2.25)). Created by Safa Chaabani</em></p>
<p></p>
<p>The distribution from which the data were generated is most probably f ~ N(10, 2.25), which is the purple curve in Figure 2.</p>
<p><span style="color:blue">The normal distribution is a tricky one here as there are two parameters so makes it more complex.</span></p>
<p><span style="color:blue">This is nice! I would perhaps move this to the end into the normal distribution section for the first paragraph and to the multiple data points section for the second. I think it might also benefit from a bit more explanation of certain parts. For example, describing the distribution as f can be a bit vague, I would maybe focus on a specific distribution instead. Obviously all of the f() etc is totally correct it just might not be as intuitive.</span></p>
<p><span style="color:blue">For this exact section I would show how the likelihood can be maximized.</span></p>
<p>Suppose that X1, X2, X3, …, Xn is a random sample from a distribution f with a parameter<span class="math inline">\(\theta\)</span>.</p>
<p><span style="color:blue">Places like here - I would add an example of what X would be</span></p>
<p>where <span class="math inline">\(f(x_i)\)</span> is a probability density of a particular value <span class="math inline">\((x_i)\)</span> sampled from a random population. A probability density is the curve corresponding to a given distribution. So values located in areas with higher probability will have higher probability density. For example, the “bell-shaped” curve associated to the Normal distribution is a probability density, whereas probability corresponds to the area under the curve for a given range of values.</p>
<p>If all the values in our sample are statistically independent (the probability of sampling a particular value does not depend on the rest of sampled values), the likelihood of observing the whole sample ( <span class="math inline">\(L\)</span>), called the likelihood function, is the product of the probability densities of the individual values.</p>
<p><span class="math display">\[
L = f(x1,x2,…,x n∣\theta)=f(x 1∣\theta)×f(x 2∣θ)×…×f(x n∣\theta)
\]</span></p>
<p></p>
<p>For example, <span class="math inline">\(f\)</span> could be of the family of normal distribution, which depends on parameters <span class="math inline">\(\sigma\)</span> (standard deviation) and <span class="math inline">\(\mu\)</span> (mean), and X1, X2, <span class="math inline">\(\ldots\)</span>, Xn would be observations from <span class="math inline">\(f\)</span>.</p>
<p>A maximum likelihood estimate <span class="math inline">\(\theta\)</span>,$ _{ML}$is a value of <span class="math inline">\(\theta\)</span> that maximizes the likelihood function. </p>
<section id="why-log-likelihood" class="level3" data-number="9.3.1"><h3 data-number="9.3.1" class="anchored" data-anchor-id="why-log-likelihood">
<span class="header-section-number">9.3.1</span> Why log likelihood?</h3>
<p>*Probability densities are often smaller than 1, the value of <span class="math inline">\(L\)</span> can become very small if we have big sample size. For example the likelihood of 500 values sampled from a standard Normal distribution is very small:</p>
<div class="cell">
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2019</span><span class="op">)</span>
<span class="va">sample</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">500</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">sample</span><span class="op">)</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 2.005517e-309</code></pre>
</div>
</div>
<p>*If the variance of the distribution is small it is possible to get probability densities higher than one. Consequently, the likelihood function will have very large values. For example, for a Normal distribution with standard deviation of 0.01 we get:</p>
<div class="cell">
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="va">sample2</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">100</span>, sd <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">sample2</span>, sd <span class="op">=</span> <span class="fl">0.01</span><span class="op">)</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 1.660806e+137</code></pre>
</div>
</div>
<p>These are problems because computers have limited capacity and cannot store very large or very small numbers. So, if we use bigger sample sizes, we will get 0 or Inf instead of the actual values of the likelihood function. Let’s try the same for 1000 values sampled from a standard Normal distribution instead of 500:</p>
<div class="cell">
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">2019</span><span class="op">)</span>
<span class="va">sample</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">1000</span><span class="op">)</span>
<span class="fu"><a href="https://rdrr.io/r/base/prod.html">prod</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">sample</span><span class="op">)</span><span class="op">)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0</code></pre>
</div>
</div>
<p></p>
<p>Therefore, we cannot work directly with the likelihood function.</p>
<p>Often, the average log-likelihood function is easier to work with. It has a nice property, which is that the logarithm of a product of values is the sum of the logarithms of those values: </p>
<p><span class="math display">\[
\hat{\ell} = \frac{1}{n}\log L = \frac{1}{n}\sum_{i=1}^n\log f(x_i|\theta)
\]</span> </p>
</section><section id="finding-the-maximum" class="level3" data-number="9.3.2"><h3 data-number="9.3.2" class="anchored" data-anchor-id="finding-the-maximum">
<span class="header-section-number">9.3.2</span> Finding the maximum</h3>
<p><span style="color:blue">I think the optimization processes part might be a bit too much detail.</span></p>
<p><span style="color:blue">In this section, I would refer back to the example earlier where they found it hard to know if they had the maximum. I’d then show how for a simple problem, you can use equations. But for more complex situations we use R. Do you know the default optimization in R? Perhaps only mention that one?</span></p>
<p>To find the maximum of the log likelihood function <span class="math inline">\(\hat{\ell}\)</span>, we can:</p>
<p><em>Take first derivative of</em> <span class="math inline">\(\hat{\ell}\)</span> and equate it to 0. Take second derivative of <span class="math inline">\(\hat{\ell}\)</span> and confirm that it is negative. </p>
<p>So, basically, this is an optimization process, in which a good optimization algorithm needs to converge to a local minimum from an arbitrary starting point and needs to do it, preferably, as quickly as possible. Many optimization techniques are commonly used to maximize likelihood (Newton’s method, Fisher scoring, steepest descent, Nelder-Mead type (simplex) approaches,BFGS…).</p>
<p>However,these techniques are non-linear optimizers. It means they will minimize the function and not maximize it. Therefore, the convention is to minimize the negative log-likelihood function instead.</p>
<p>When the model is assumed to be Gaussian, the MLE estimates are equivalent to the ordinary least squares method.</p>
<p><span style="color:blue">It would be good to include a bit more about this, maybe as a drop down.</span></p>
<p></p>
</section></section><section id="worked-examples" class="level2" data-number="9.4"><h2 data-number="9.4" class="anchored" data-anchor-id="worked-examples">
<span class="header-section-number">9.4</span> Worked examples</h2>
<p><span style="color:blue">I think that one example can be integrated throughout and the others could come at the end under the heading of their distribution. It would be great if the examples could be biological too.</span></p>
<section id="example-1" class="level3" data-number="9.4.1"><h3 data-number="9.4.1" class="anchored" data-anchor-id="example-1">
<span class="header-section-number">9.4.1</span> Example 1</h3>
<p></p>
<p>We will use a dataset of the number of visitors of a museum per day for 300 days. We want to predict the number of visitors per day.</p>
<p>Here we will use the modeling technique that we have learnt above using R.</p>
<p>Let’s first have a look at the distribution of visitors:</p>
<div class="cell">
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r code-with-copy"><code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://ggplot2.tidyverse.org">ggplot2</a></span><span class="op">)</span>

<span class="va">data3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/utils/read.table.html">read.csv</a></span><span class="op">(</span><span class="st">"./Files/visitors.csv"</span>,header <span class="op">=</span> <span class="cn">TRUE</span>, sep<span class="op">=</span><span class="st">";"</span><span class="op">)</span>

<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">data3</span><span class="op">)</span> <span class="op">+</span> 
     <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>
                   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">visitors</span>,
                       y<span class="op">=</span><span class="va">..density..</span>
                <span class="op">)</span>, binwidth <span class="op">=</span> <span class="fl">1</span>,colour<span class="op">=</span> <span class="st">"black"</span>, fill <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">13</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">visitors</span>,
                     y<span class="op">=</span><span class="va">..density..</span><span class="op">)</span>,colour<span class="op">=</span> <span class="st">"red"</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title<span class="op">=</span><span class="st">"Figure 3"</span>, subtitle<span class="op">=</span><span class="st">"Number of visitors per day"</span>,
       caption <span class="op">=</span> <span class="st">"Data by Safa Chaabani"</span><span class="op">)</span> </code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<p><img src="2.X_mle_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid" width="672"></p>
</div>
</div>
<p><em>Figure 3: Example of data showing the number of visitors of a museum per day for about 300 days. Data by Safa Chaabani</em></p>
<p>This looks like an exponential distribution. Since it is count data of the number of visitors, we can use Poisson distribution.</p>
<p>Knowing that x = (x1, x2, . . . , xn) are the observations of the number of visitors which we suppose are from a Poisson distribution with unknown parameter <span class="math inline">\(\lambda\)</span>.</p>
<p>We can write the likelihood function as:</p>
<p><span class="math display">\[
L = \dfrac{\lambda^{\sum\limits^n_{i=1}x_i} e^{-n\lambda}}{x_1!x_2! \cdots x_n!}
\]</span></p>


<!-- -->

</section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
    } else {
      disableStylesheet(alternateStylesheets);
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } 
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  const viewSource = window.document.getElementById('quarto-view-source') ||
                     window.document.getElementById('quarto-code-tools-source');
  if (viewSource) {
    const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
    viewSource.addEventListener("click", function(e) {
      if (sourceUrl) {
        // rstudio viewer pane
        if (/\bcapabilities=\b/.test(window.location)) {
          window.open(sourceUrl);
        } else {
          window.location.href = sourceUrl;
        }
      } else {
        const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
        modal.show();
      }
      return false;
    });
  }
  function toggleCodeHandler(show) {
    return function(e) {
      const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
      for (let i=0; i<detailsSrc.length; i++) {
        const details = detailsSrc[i].parentElement;
        if (show) {
          details.open = true;
        } else {
          details.removeAttribute("open");
        }
      }
      const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
      const fromCls = show ? "hidden" : "unhidden";
      const toCls = show ? "unhidden" : "hidden";
      for (let i=0; i<cellCodeDivs.length; i++) {
        const codeDiv = cellCodeDivs[i];
        if (codeDiv.classList.contains(fromCls)) {
          codeDiv.classList.remove(fromCls);
          codeDiv.classList.add(toCls);
        } 
      }
      return false;
    }
  }
  const hideAllCode = window.document.getElementById("quarto-hide-all-code");
  if (hideAllCode) {
    hideAllCode.addEventListener("click", toggleCodeHandler(false));
  }
  const showAllCode = window.document.getElementById("quarto-show-all-code");
  if (showAllCode) {
    showAllCode.addEventListener("click", toggleCodeHandler(true));
  }
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./2.X_binomial_GLM.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Binomial generalized linear models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb8" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu"># Maximum likelihood estimation"</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup, eval=TRUE, include=FALSE}</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="co"># add all packages that need loading</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co"># source figure settings</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#source("../StatisticsInR/Files/biostats_theme.R")</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co"># set warning to be off for all chunks</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>knitr<span class="sc">::</span>opts_chunk<span class="sc">$</span><span class="fu">set</span>(<span class="at">warning =</span> <span class="cn">FALSE</span>, <span class="at">message =</span> <span class="cn">FALSE</span>, <span class="at">echo =</span> <span class="cn">TRUE</span>)</span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="in">```{r setup-data, include=FALSE, echo=FALSE}</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co"># import data for the example</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>datafile <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="st">"./Files/destr_example.csv"</span>)</span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="fu">### Before you start {.facta .toc-ignore}</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>You should be familiar with basic statistical theory, basics of R, and probability distributions. You should be able to explain the meaning of: a population, a sample, a parameter, and statistical inference. If you can't, head <span class="co">[</span><span class="ot">here</span><span class="co">]()</span> first.</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="fu">## Introduction</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>In this section, we will discuss what maximum likelihood estimation is and look at why and how we use it in statistical modeling.</span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> Could use something like the globe example to set this up including the shiny app. Maybe we can think of a different binary example that's easy to understand? </span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> I suggest as well as the example, that we spend a bit of time here setting the background estimating parameters. I will try and make a separate page on samples, populations, and statistical inference. So, you should be able to reference that rather than explain everything from scratch. </span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a><span class="fu">## What is a likelihood?</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a>The **likelihood** is a fundamental concept in statistics. It is defined as: 'the probability of obtaining the observed data, given a particular parameter value.' It is an equation that mathematically represents how the data were generated. We base the form of this equation on assumptions we make about the processes causing our observations. The likelihood assumes that the data are random and the parameters are fixed.</span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> It would be nice to then have a short and simple example here e.g. how we assume data with two outcomes are generated following a binomial distribution. So, some of the equations from further down could come up here to show what a likelihood is as an equation.</span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why do we maximize it?</span></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a>[ In this section, I would illustrate how you can calculate parameters of a distribution like the Binomial or Normal or Poisson. Maybe keep the same example as above? I would then ask how confident the students\</span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a>would be that they have the 'best' answer for the population parameter from their sample. Give an example of sampling again and show that the estimate changes. Talk about estimator and estimand. Basically, it is about finding the parameter values that make the observed data most likely (as you explain nicely below) ]{style="color:blue"}</span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a>Maximum likelihood estimation (MLE) is a technique used for estimating the parameters for a given distribution, using some observed data. Hence, MLE allows you to estimate population parameters from sample data such that the probability (likelihood) of obtaining the observed data is maximized.</span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a>Let's suppose that a population is following a normal distribution but its mean and variance are unknown. MLE can be used to estimate them from a sample of the population. It looks for values of the mean and variance so that the observation is the most likely to occur.</span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> The below is a nice example. I would not mention 'guessing' as really we are using a fixed mathematical process. I think it is simpler to keep one example all through and then give the code and equations for other distributions at the end e.g. use Binomial throughout then have Poisson and Normal at the end? </span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a>Let's Suppose we have data points from a normal distribution. The data points are shown in the figure 2 below (the R code that was used to generate the image is provided as well). To get an intuition of MLE,we suggest different sets of normal distribution parameters (mean and variance), we plot the curves corresponding to each set and we try to guess which of them would maximize the probability of observing the data. In other words, we want to find the values of mean and variance that result in the curve that best fits the data. <span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo=FALSE}</span></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a>numb<span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="dv">10</span>)</span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a>numb1<span class="ot">&lt;-</span><span class="fu">c</span>(<span class="fl">7.5</span>,<span class="fl">8.5</span>,<span class="fl">8.8</span>,<span class="fl">9.3</span>,<span class="fl">9.5</span>,<span class="fl">9.6</span>,<span class="fl">9.7</span>,<span class="fl">9.8</span>,<span class="fl">10.2</span>,<span class="fl">11.8</span>)</span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a>data1<span class="ot">&lt;-</span><span class="fu">as.data.frame</span> (<span class="fu">cbind</span>(numb1,numb))</span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a>p<span class="ot">&lt;-</span><span class="fu">ggplot</span>(data1, <span class="fu">aes</span>(<span class="at">x=</span>numb1, <span class="at">y=</span>numb))<span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">shape =</span> <span class="dv">21</span>, <span class="at">colour =</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"skyblue1"</span>, <span class="at">size =</span> <span class="dv">5</span>)</span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a>  p<span class="sc">+</span><span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="fl">2.25</span>),<span class="fu">aes</span>(<span class="at">col=</span><span class="st">"purple"</span>),<span class="at">size=</span><span class="dv">1</span>) <span class="sc">+</span> </span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a> <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm , <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="dv">9</span>),<span class="fu">aes</span>(<span class="at">col=</span><span class="st">"chartreuse3"</span>),<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">10</span>, <span class="at">sd =</span> <span class="fl">0.25</span>), <span class="fu">aes</span>(<span class="at">col=</span><span class="st">"darkorange2"</span>),<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span></span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a>  <span class="fu">stat_function</span>(<span class="at">fun =</span> dnorm, <span class="at">args =</span> <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">8</span>, <span class="at">sd =</span> <span class="fl">2.25</span>),<span class="fu">aes</span>(<span class="at">colour=</span><span class="st">"blue"</span>),<span class="at">size=</span><span class="dv">1</span>)<span class="sc">+</span><span class="fu">ylab</span>(<span class="st">"Density"</span>) <span class="sc">+</span></span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_x_continuous</span>( <span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">5</span>,<span class="dv">16</span>)) <span class="sc">+</span></span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme_bw</span>()<span class="sc">+</span></span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_color_identity</span>(</span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a>                       <span class="at">name=</span><span class="st">"Probability density "</span>,</span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a>                       <span class="at">breaks=</span><span class="fu">c</span>(<span class="st">"purple"</span>, <span class="st">"chartreuse3"</span>, <span class="st">"darkorange2"</span>,<span class="st">"blue"</span>),</span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a>                       <span class="at">labels=</span><span class="fu">c</span>(<span class="st">"f∼ N (10, 2.25)"</span>, <span class="st">"f1∼ N (10, 9)"</span>, <span class="st">"f2∼ N (10, 0.25)"</span>,<span class="st">"f3∼ N (8, 2.25)"</span>), <span class="at">guide=</span><span class="st">"legend"</span>)<span class="sc">+</span> <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">"Figure 2"</span>, <span class="at">caption =</span> <span class="st">"Data by Safa Chaabani"</span>)</span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a>*Figure 2: Example of data points (blue dots) and fits from different normal distribution curves generated from different sets of parameter values (f ∼ N (10, 2.25), f1 ∼ N (10, 9), f2 ∼ N (10, 0.25) and f3∼ N (8, 2.25)). Created by Safa Chaabani*</span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a>The distribution from which the data were generated is most probably f \~ N(10, 2.25), which is the purple curve in Figure 2.</span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> The normal distribution is a tricky one here as there are two parameters so makes it more complex. </span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> This is nice! I would perhaps move this to the end into the normal distribution section for the first paragraph and to the multiple data points section for the second. I think it might also benefit from a bit more explanation of certain parts. For example, describing the distribution as f can be a bit vague, I would maybe focus on a specific distribution instead. Obviously all of the f() etc is totally correct it just might not be as intuitive.</span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> For this exact section I would show how the likelihood can be maximized.</span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a>Suppose that X1, X2, X3, ..., Xn is a random sample from a distribution f with a parameter$\theta$.</span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> Places like here - I would add an example of what X would be </span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a>where $f(x_i)$ is a probability density of a particular value $(x_i)$ sampled from a random population. A probability density is the curve corresponding to a given distribution. So values located in areas with higher probability will have higher probability density. For example, the "bell-shaped" curve associated to the Normal distribution is a probability density, whereas probability corresponds to the area under the curve for a given range of values.</span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a>If all the values in our sample are statistically independent (the probability of sampling a particular value does not depend on the rest of sampled values), the likelihood of observing the whole sample ( $L$), called the likelihood function, is the product of the probability densities of the individual values.</span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a>L = f(x1,x2,…,x n∣\theta)=f(x 1∣\theta)×f(x 2∣θ)×…×f(x n∣\theta)</span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a>For example, $f$ could be of the family of normal distribution, which depends on parameters $\sigma$ (standard deviation) and $\mu$ (mean), and X1, X2, $\ldots$, Xn would be observations from $f$.</span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a>A maximum likelihood estimate $\theta$,\$ \hat{\Theta}<span class="sc">\_</span>{ML}\$is a value of $\theta$ that maximizes the likelihood function. <span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-116"><a href="#cb8-116" aria-hidden="true" tabindex="-1"></a><span class="fu">### Why log likelihood?</span></span>
<span id="cb8-117"><a href="#cb8-117" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-118"><a href="#cb8-118" aria-hidden="true" tabindex="-1"></a><span class="sc">\*</span>Probability densities are often smaller than 1, the value of $L$ can become very small if we have big sample size. For example the likelihood of 500 values sampled from a standard Normal distribution is very small:</span>
<span id="cb8-119"><a href="#cb8-119" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-120"><a href="#cb8-120" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo=TRUE}</span></span>
<span id="cb8-121"><a href="#cb8-121" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2019</span>)</span>
<span id="cb8-122"><a href="#cb8-122" aria-hidden="true" tabindex="-1"></a>sample <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">500</span>)</span>
<span id="cb8-123"><a href="#cb8-123" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(sample))</span>
<span id="cb8-124"><a href="#cb8-124" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-125"><a href="#cb8-125" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-126"><a href="#cb8-126" aria-hidden="true" tabindex="-1"></a><span class="sc">\*</span>If the variance of the distribution is small it is possible to get probability densities higher than one. Consequently, the likelihood function will have very large values. For example, for a Normal distribution with standard deviation of 0.01 we get:</span>
<span id="cb8-127"><a href="#cb8-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-128"><a href="#cb8-128" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include=TRUE, echo=T}</span></span>
<span id="cb8-129"><a href="#cb8-129" aria-hidden="true" tabindex="-1"></a>sample2 <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">100</span>, <span class="at">sd =</span> <span class="fl">0.01</span>)</span>
<span id="cb8-130"><a href="#cb8-130" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(sample2, <span class="at">sd =</span> <span class="fl">0.01</span>))</span>
<span id="cb8-131"><a href="#cb8-131" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-132"><a href="#cb8-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-133"><a href="#cb8-133" aria-hidden="true" tabindex="-1"></a>These are problems because computers have limited capacity and cannot store very large or very small numbers. So, if we use bigger sample sizes, we will get 0 or Inf instead of the actual values of the likelihood function. Let's try the same for 1000 values sampled from a standard Normal distribution instead of 500:</span>
<span id="cb8-134"><a href="#cb8-134" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-135"><a href="#cb8-135" aria-hidden="true" tabindex="-1"></a><span class="in">```{r, include=TRUE, echo=T}</span></span>
<span id="cb8-136"><a href="#cb8-136" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">2019</span>)</span>
<span id="cb8-137"><a href="#cb8-137" aria-hidden="true" tabindex="-1"></a>sample <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>)</span>
<span id="cb8-138"><a href="#cb8-138" aria-hidden="true" tabindex="-1"></a><span class="fu">prod</span>(<span class="fu">dnorm</span>(sample))</span>
<span id="cb8-139"><a href="#cb8-139" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-140"><a href="#cb8-140" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-141"><a href="#cb8-141" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-142"><a href="#cb8-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-143"><a href="#cb8-143" aria-hidden="true" tabindex="-1"></a>Therefore, we cannot work directly with the likelihood function.</span>
<span id="cb8-144"><a href="#cb8-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-145"><a href="#cb8-145" aria-hidden="true" tabindex="-1"></a>Often, the average log-likelihood function is easier to work with. It has a nice property, which is that the logarithm of a product of values is the sum of the logarithms of those values: <span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-146"><a href="#cb8-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-147"><a href="#cb8-147" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-148"><a href="#cb8-148" aria-hidden="true" tabindex="-1"></a>\hat{\ell} = \frac{1}{n}\log L = \frac{1}{n}\sum_{i=1}^n\log f(x_i|\theta)</span>
<span id="cb8-149"><a href="#cb8-149" aria-hidden="true" tabindex="-1"></a>$$ <span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-150"><a href="#cb8-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-151"><a href="#cb8-151" aria-hidden="true" tabindex="-1"></a><span class="fu">### Finding the maximum</span></span>
<span id="cb8-152"><a href="#cb8-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-153"><a href="#cb8-153" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> I think the optimization processes part might be a bit too much detail.</span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-154"><a href="#cb8-154" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-155"><a href="#cb8-155" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> In this section, I would refer back to the example earlier where they found it hard to know if they had the maximum. I'd then show how for a simple problem, you can use equations. But for more complex situations we use R. Do you know the default optimization in R? Perhaps only mention that one?</span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-156"><a href="#cb8-156" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-157"><a href="#cb8-157" aria-hidden="true" tabindex="-1"></a>To find the maximum of the log likelihood function $\hat{\ell}$, we can:</span>
<span id="cb8-158"><a href="#cb8-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-159"><a href="#cb8-159" aria-hidden="true" tabindex="-1"></a>*Take first derivative of* $\hat{\ell}$ and equate it to 0. Take second derivative of $\hat{\ell}$ and confirm that it is negative. <span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-160"><a href="#cb8-160" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-161"><a href="#cb8-161" aria-hidden="true" tabindex="-1"></a>So, basically, this is an optimization process, in which a good optimization algorithm needs to converge to a local minimum from an arbitrary starting point and needs to do it, preferably, as quickly as possible. Many optimization techniques are commonly used to maximize likelihood (Newton's method, Fisher scoring, steepest descent, Nelder-Mead type (simplex) approaches,BFGS...).</span>
<span id="cb8-162"><a href="#cb8-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-163"><a href="#cb8-163" aria-hidden="true" tabindex="-1"></a>However,these techniques are non-linear optimizers. It means they will minimize the function and not maximize it. Therefore, the convention is to minimize the negative log-likelihood function instead.</span>
<span id="cb8-164"><a href="#cb8-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-165"><a href="#cb8-165" aria-hidden="true" tabindex="-1"></a>When the model is assumed to be Gaussian, the MLE estimates are equivalent to the ordinary least squares method.</span>
<span id="cb8-166"><a href="#cb8-166" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-167"><a href="#cb8-167" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> It would be good to include a bit more about this, maybe as a drop down. </span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-168"><a href="#cb8-168" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-169"><a href="#cb8-169" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-170"><a href="#cb8-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-171"><a href="#cb8-171" aria-hidden="true" tabindex="-1"></a><span class="fu">## Worked examples</span></span>
<span id="cb8-172"><a href="#cb8-172" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-173"><a href="#cb8-173" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot"> I think that one example can be integrated throughout and the others could come at the end under the heading of their distribution. It would be great if the examples could be biological too. </span><span class="co">]</span>{style="color:blue"}</span>
<span id="cb8-174"><a href="#cb8-174" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-175"><a href="#cb8-175" aria-hidden="true" tabindex="-1"></a><span class="fu">### Example 1</span></span>
<span id="cb8-176"><a href="#cb8-176" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-177"><a href="#cb8-177" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/br&gt;</span></span>
<span id="cb8-178"><a href="#cb8-178" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-179"><a href="#cb8-179" aria-hidden="true" tabindex="-1"></a>We will use a dataset of the number of visitors of a museum per day for 300 days. We want to predict the number of visitors per day.</span>
<span id="cb8-180"><a href="#cb8-180" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-181"><a href="#cb8-181" aria-hidden="true" tabindex="-1"></a>Here we will use the modeling technique that we have learnt above using R.</span>
<span id="cb8-182"><a href="#cb8-182" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-183"><a href="#cb8-183" aria-hidden="true" tabindex="-1"></a>Let's first have a look at the distribution of visitors:</span>
<span id="cb8-184"><a href="#cb8-184" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-185"><a href="#cb8-185" aria-hidden="true" tabindex="-1"></a><span class="in">```{r echo=TRUE}</span></span>
<span id="cb8-186"><a href="#cb8-186" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb8-187"><a href="#cb8-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-188"><a href="#cb8-188" aria-hidden="true" tabindex="-1"></a>data3 <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"./Files/visitors.csv"</span>,<span class="at">header =</span> <span class="cn">TRUE</span>, <span class="at">sep=</span><span class="st">";"</span>)</span>
<span id="cb8-189"><a href="#cb8-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-190"><a href="#cb8-190" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(data3) <span class="sc">+</span> </span>
<span id="cb8-191"><a href="#cb8-191" aria-hidden="true" tabindex="-1"></a>     <span class="fu">geom_histogram</span>(</span>
<span id="cb8-192"><a href="#cb8-192" aria-hidden="true" tabindex="-1"></a>                   <span class="fu">aes</span>(<span class="at">x=</span>visitors,</span>
<span id="cb8-193"><a href="#cb8-193" aria-hidden="true" tabindex="-1"></a>                       <span class="at">y=</span>..density..</span>
<span id="cb8-194"><a href="#cb8-194" aria-hidden="true" tabindex="-1"></a>                ), <span class="at">binwidth =</span> <span class="dv">1</span>,<span class="at">colour=</span> <span class="st">"black"</span>, <span class="at">fill =</span> <span class="st">"white"</span>) <span class="sc">+</span>  <span class="fu">scale_x_continuous</span>(<span class="at">breaks =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="dv">13</span>, <span class="dv">1</span>))<span class="sc">+</span></span>
<span id="cb8-195"><a href="#cb8-195" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_density</span>(<span class="fu">aes</span>(<span class="at">x=</span>visitors,</span>
<span id="cb8-196"><a href="#cb8-196" aria-hidden="true" tabindex="-1"></a>                     <span class="at">y=</span>..density..),<span class="at">colour=</span> <span class="st">"red"</span>)<span class="sc">+</span></span>
<span id="cb8-197"><a href="#cb8-197" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title=</span><span class="st">"Figure 3"</span>, <span class="at">subtitle=</span><span class="st">"Number of visitors per day"</span>,</span>
<span id="cb8-198"><a href="#cb8-198" aria-hidden="true" tabindex="-1"></a>       <span class="at">caption =</span> <span class="st">"Data by Safa Chaabani"</span>) </span>
<span id="cb8-199"><a href="#cb8-199" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-200"><a href="#cb8-200" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb8-201"><a href="#cb8-201" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-202"><a href="#cb8-202" aria-hidden="true" tabindex="-1"></a>*Figure 3: Example of data showing the number of visitors of a museum per day for about 300 days. Data by Safa Chaabani*</span>
<span id="cb8-203"><a href="#cb8-203" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-204"><a href="#cb8-204" aria-hidden="true" tabindex="-1"></a>This looks like an exponential distribution. Since it is count data of the number of visitors, we can use Poisson distribution.</span>
<span id="cb8-205"><a href="#cb8-205" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-206"><a href="#cb8-206" aria-hidden="true" tabindex="-1"></a>Knowing that x = (x1, x2, . . . , xn) are the observations of the number of visitors which we suppose are from a Poisson distribution with unknown parameter $\lambda$.</span>
<span id="cb8-207"><a href="#cb8-207" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-208"><a href="#cb8-208" aria-hidden="true" tabindex="-1"></a>We can write the likelihood function as:</span>
<span id="cb8-209"><a href="#cb8-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-210"><a href="#cb8-210" aria-hidden="true" tabindex="-1"></a>$$</span>
<span id="cb8-211"><a href="#cb8-211" aria-hidden="true" tabindex="-1"></a>L = \dfrac{\lambda^{\sum\limits^n_{i=1}x_i} e^{-n\lambda}}{x_1!x_2! \cdots x_n!}</span>
<span id="cb8-212"><a href="#cb8-212" aria-hidden="true" tabindex="-1"></a>$$</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->



</body></html>