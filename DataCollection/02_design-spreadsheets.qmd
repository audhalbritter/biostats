---
bibliography: bibliography.bib
---

``` {r setup, include=FALSE}

library(knitr)
library(lubridate)

```

# Design spreadsheets

## Rectangular spreadsheet

Spreadsheets should be rectangular (@fig-tidy-data).

Best practice is to make spreadsheets completely rectangular.
They should not have empty cells, rows or columns, titles or double headers.

It is however common that some of these things happen.
Leaving a row blank or adding a title to a table is very often done.
It's not best practice, but also not a big problem for the downstream processing.
Contrary, having two headers with different information is more difficult to process later.

Sometimes, two datasets are combined in one spreadsheet.
For example, table @fig-separate-files shows an example of pollinator observation data, which included observations about wind.
On the right as a separate table in the same document, shows the scale for wind.
It's logical that one would want to have the two tables in the same file, when entering the data. 
But this will be more complicated than needed when importing the data.
So, we recommend to keep these two tables in separate spreadsheets.

```{r}
#| label: separate-files
#| echo: false
#| out-width: "90%"
#| fig-cap: "Two in one."

include_graphics("./pics/separate-files.png")

```

Add example on many small tables in one document!!!


## Long or wide format

Datasets can be long or wide and there is often a debate which of these formats are better.
We do not have a strong opinion on this.
As long as the general rules (see above and below) are followed, this does not matter very much.
Many analysis require a long format, but for others (e.g. ordinations) a wide format is needed.
This means that data often needs to be reshaped from long to wide and vice versa.
And this is not very difficult (see reshape section).

Make spreadsheets that makes data collection easy.
For example, make one sheet per plot, avoid having multiple datasheets where you have to flip forth and back if possible.
More importantly, when you digitize the data, the digital version should reflect the paper version.
It's not recommended that you change the format, just to have a long format.
This can easily lead to errors.


## Single value per cell

Tidy spreadsheets follow the following rules:

- each variable should be one specific column,
- each observation should be one specific row,
- each cell at the intersection of a row and a column contains a single value.

Importantly, put only one value per cell (@fig-tidy-data).

```{r}
#| label: tidy-data
#| echo: false
#| out-width: "90%"
#| fig-cap: "A rectangular and tidy dataset with one value per cell."

include_graphics("./pics/tidy-data.png")

```

Sometimes values are entered with their units, such as 42 g in one cell.
It is better to separate the value and the unit into two columns.

Another common mistake is to add notes to a column.
For example if a value is 0 because it is below the detection value, you could write 0 (below threshold).
We recommend to only write the number in the first column and add notes on the value in a separate column called notes.


## Data dictionary

A dataset on it's own is often useless, because it can be difficult to understand what data each column contains.
Therefore, it is best practise that a **data dictionary** goes with every dataset.
A data dictionary is a separate file or table that describes the data and explains what each variable means.

This is useful if you want to share your data with collaborators, if somebody else is doing the data analysis for you, or even for your future self in a few years time.
You might not remember exactly what each column means, the units, and how it was measured.

A data dictionary should contain:

- Variable names
- Explanation of the variable
- Unit
- Range/expected min/max



## Consistency

Consistency is key.
There are many ways of designing a spreadsheet, and there is not always a right or wrong.
Find what works for you and stick to it.

Be consistent for **categorical variables**, for example use the same spelling and not variations like: *female*, *Female*, *F*.
Latin species names is a common problem and where typos happen very easily (@fig-typos).

```{r}
#| label: typos
#| echo: false
#| out-width: "50%"
#| fig-cap: "Inconsistency in species names"

include_graphics("./pics/typos.png")

```

If you have multiple files or datasets from the same experiment, be consistent with **variable names** and do not use variations like: *site*, *location*, *siteID*.
This will make it more difficult to join datasets downstream.

Be consistent with **missing values**. Do not use a mix of leaving the cell blank, NA and making notes like *value missing*.
Also see section below for more details on missing values.

Be consistent with **file names**.

Be consistent with **dates**.
Dates are particularly tricky and get some special attention here (see below).
Preferably, use the ISO standard yyyy-mm-dd, for example `r today()`.

Be consistent in your **notes**.
We recommend to have a column with notes, which can be used to write down notes about the data or a specific value.
For example, why a observation is missing, or something that was unusual during data collection etc.
But again, be consistent when making these notes, because it will be easier to make use of the notes downstream. Using different versions for the same information like *gone*, *missing*, *vanished* will make it difficult to quantify how many times a specific problem occured.

Avoid space in cells before " female" or after "female ".


## Meaningful naming

Use good and meaningful names.
What do we mean by this?
Variable names should be easy to use in downstream data analysis.
In addition, variable names should be meaningful which means that the name should explain the variable to some extent.

Avoid spaces in names, and rather use underscore (_) or hyphen (-).
There are different styles (see @fig-cases) and there are debates about which one is preferable.
The truth is, it does not really matter, choose one and stick with it.

```{r}
#| label: cases
#| echo: false
#| out-width: "90%"
#| fig-cap: "Different styles for naming objects. Credit: Allison Horst."

include_graphics("./pics/cases.jpg")

```

Do not use special characters other than underscore and hyphen in names.
For example: +, %, &, /, ?, !, $, ,, #, @.
Note that letters that might be common for you, for example å, æ and ø, are not so common in other countries and data analysis programs do not deal very well with them.
Instead of *nedbør* use *nedbor*.
This will make you life a lot easier.

Use concise and meaningful names (@fig.final-final).
The name should be short, but long enough to give a meaning.
For example *community_composition_2022.csv*.


```{r}
#| label: final-final
#| echo: false
#| out-width: "70%"
#| fig-cap: "Final doc by PhDcomics.com"

include_graphics("./pics/final.png")

```

If you want to know more about this, we have created a tutorial on [naming conventions](https://github.com/biostats-r/biostats.tutorials).


## Standards

Use global data standards when available.

One example are **geographic locations** such as coordinates.
They can be written in many different ways:

- Decimal degrees: 60.39299 5.32415
- DMS: 60°23'34.76" N 5°19'26.94" E
- UTM: 32V 297477.30699364 6700830.0640155

We recommend to use decimal degree (ISO 6709).
For example the coordinates for Bergen (Norway) are 60.39299 °N and 5.32415 °E.

Another example are **dates**, that can also be written in many different ways: 

- 3.1.2022
- 03/01/2200
- 01-03-2022
- etc.

This can lead to confusion, especially when the placement of the month and day are switched (@fig-dates).

We therefore strongly recommend to use the global standard ISO 8601 [@houston1993iso] for dates, YYYY-MM-DD, such as `r today()`.

```{r}
#| label: dates
#| echo: false
#| out-width: "90%"
#| fig-cap: "Missunderstandings when not usig date standards. Credit: https://xkcd.com"

include_graphics("./pics/dates.png")

```

Another issue with dates is, that programs like Excel can turn values into dates.
For example names like "Oct-4", which is a name of a gene, will be turned into a date.
Be aware of such problems and check your dataset for dates that are not supposed to be dates.

How can you avoid such mistakes?
You can avoid names that are turned into dates, or actively prevent it by adding a underscore or another character in front of such names.
This can later be removed.
Another way would be to force a column in excel to be a date or to be text.


## Missing data

We already mentioned to be consistent with missing data.
We also recommend to use NA for missing data.
Often missing data is left blank, and R will automatically fill in NAs.
This is fine, but there is no way of distinguishing between missing data and a value that was forgotten.

Also note that missing data and zero are often not the same.
Therefore, we recommend to distinguish between missing data (NA) and zero, which can mean not present.


## Point or comma as decimal separator

For the decimal separator it is common to use a point or a comma.
There is no general agreement on which one to use, and there are different practises in different countries.
For example in Norway, the comma is the standard setting in Excel.

Again, it does not matter what you use, but use it consistently.
We have guidelines for how to import datasets with different formats (see import chapter).

Importantly, don't fight Excel!!!!


## No manipulation or calculations

We strongly recommend to use datasheets only for data entry and storage.
During data entry, the content of the spreadsheet can still be changed to reflect the paper version of the data or to make it consistent.
But at some point we suggest to stop data manipulation by hand.
From that point, data manipulation is done by code.

This is because any manipulation done by hand in Excel, cannot be reversed (at least once the document is saved and closed).
Also, if you do a lot of manipulation in Excel, you won't remember what has been done. Standard excel does not have track change to allow you to go back to older versions.
In contrast, if data manipulation is done code-based, all manipulation can be changed and reversed.

For example, if you delete a column in Excel, save the document and leave the program.
And the next day you realize that this was a mistake, it is not possible to retrieve this column.
However if you leave the data file untouched, and do the manipulation in R, you can import the data again, run the code and just delete the command that was wrong.

We also do not recommend that you make calculations or summaries in your spreadsheet.
Better practice is to use a data analysis tool like R for this, because it is reproducible.


## No formatting

It's common to format tables, by for example using colours, or bold font.
That is fine, as long as the formatting is not containing any information.
For example colouring missing data.
For that make a new column with notes that data is missing.

Data analysis programs do not understand highlighted cells or bold text and such information will simply be ignored and is therefore lost.


## Data validation tools

Data validation is a way to reduce errors in the data and can be built in when collecting or digitizing data.

For example you can:

- set ranges for valid numbers (e.g. only positive, range between two numbers)
- only allow whole numbers or decimals
- add a drop down menus for categorical data
- define the length of text (e.g. only 8 characters)
- define data types (e.g. to avoid conversion to dates)


## Proof reading

Proof reading is an essential step once the dataset is digitized.
...

## Backup and storage

**Back up** your data in an unconnected data repository to avoid data loss.
There are many options for this and they often have private or closed repositories, which means that you do not automatically need to share the data.

Take pictures of paper versions of your data and store them in a save place.
This can be useful for proof reading.

**Save** your data as plain text formats, with comma or tab deliminator.
We recommend csv files, which is a nonproprietary format.
This means that  it does not require any special software, but can be opened in any spreadsheet program.

We recommend that you save two copies of your data (@fig-workflow).
A raw non-manipulated version, and a clean version  of the data.
Both can be stored in the same place, but indicate in the file name which version it is.
Also provide the code for the data cleaning somewhere (e.g. GitHub).
This is a transparent way of data cleaning and makes it possible to apply other data manipulation if needed.

```{r}
#| label: workflow
#| echo: false
#| out-width: "90%"
#| fig-cap: "Reproducible workflow."

include_graphics("./pics/rep_workflow_FunCaB.jpg")

```


## Version control

automatic data validation
